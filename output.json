Epoch 0: 0%|          | 0/3125 [
    00: 00<?, ?it/s
] ----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [
        -0.0282,
        0.0069,
        0.0170,  ...,
        -0.0136,
        -0.0117,
        0.0036
    ],
    [
        -0.0286,
        0.0068,
        0.0159,  ...,
        -0.0131,
        -0.0121,
        0.0026
    ],
    [
        -0.0289,
        0.0072,
        0.0158,  ...,
        -0.0137,
        -0.0126,
        0.0037
    ],
        ...,
    [
        -0.0282,
        0.0056,
        0.0158,  ...,
        -0.0146,
        -0.0117,
        0.0041
    ],
    [
        -0.0290,
        0.0060,
        0.0164,  ...,
        -0.0136,
        -0.0120,
        0.0032
    ],
    [
        -0.0276,
        0.0065,
        0.0160,  ...,
        -0.0133,
        -0.0120,
        0.0034
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0958,
        0.2086,
        -0.1677
    ],
    [
        0.3203,
        -0.2461,
        0.2450,  ...,
        -0.0958,
        0.2086,
        -0.1677
    ],
    [
        0.3203,
        -0.2461,
        0.2450,  ...,
        -0.0958,
        0.2086,
        -0.1677
    ],
        ...,
    [
        0.3203,
        -0.2461,
        0.2450,  ...,
        -0.0958,
        0.2086,
        -0.1677
    ],
    [
        0.3203,
        -0.2461,
        0.2450,  ...,
        -0.0958,
        0.2086,
        -0.1677
    ],
    [
        0.3203,
        -0.2461,
        0.2450,  ...,
        -0.0958,
        0.2086,
        -0.1677
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -162.0847,
    -164.1527,
    -164.4204,
    -161.0882,
    -164.0800,
    -163.1498,
    -164.2942,
    -162.1640,
    -163.6129,
    -161.8133,
    -161.1306,
    -164.3936,
    -161.5432,
    -162.7110,
    -161.1713,
    -163.7358
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -162.0847,
    -164.1527,
    -164.4204,
    -161.0882,
    -164.0801,
    -163.1498,
    -164.2942,
    -162.1640,
    -163.6129,
    -161.8132,
    -161.1306,
    -164.3936,
    -161.5432,
    -162.7110,
    -161.1713,
    -163.7358
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.1442, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0244,
        0.0075,
        0.0067,  ...,
        -0.0187,
        -0.0108,
        0.0022
    ],
    [
        -0.0254,
        0.0088,
        0.0062,  ...,
        -0.0189,
        -0.0136,
        0.0008
    ],
    [
        -0.0259,
        0.0112,
        0.0087,  ...,
        -0.0192,
        -0.0127,
        0.0021
    ],
        ...,
    [
        -0.0250,
        0.0088,
        0.0077,  ...,
        -0.0169,
        -0.0113,
        0.0008
    ],
    [
        -0.0257,
        0.0077,
        0.0068,  ...,
        -0.0190,
        -0.0137,
        0.0025
    ],
    [
        -0.0252,
        0.0088,
        0.0081,  ...,
        -0.0190,
        -0.0140,
        0.0011
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0282,
            0.0069,
            0.0170,  ...,
            -0.0136,
            -0.0117,
            0.0036
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0286,
            0.0068,
            0.0159,  ...,
            -0.0131,
            -0.0121,
            0.0026
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0289,
            0.0072,
            0.0158,  ...,
            -0.0137,
            -0.0126,
            0.0037
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1015,
        0.2065,
        -0.1700
    ],
    [
        0.3241,
        -0.2456,
        0.2347,  ...,
        -0.1015,
        0.2065,
        -0.1700
    ],
    [
        0.3241,
        -0.2456,
        0.2347,  ...,
        -0.1015,
        0.2065,
        -0.1700
    ],
        ...,
    [
        0.3241,
        -0.2456,
        0.2347,  ...,
        -0.1015,
        0.2065,
        -0.1700
    ],
    [
        0.3241,
        -0.2456,
        0.2347,  ...,
        -0.1015,
        0.2065,
        -0.1700
    ],
    [
        0.3241,
        -0.2456,
        0.2347,  ...,
        -0.1015,
        0.2065,
        -0.1700
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -162.4069,
    -164.4876,
    -164.7527,
    -161.4160,
    -164.4127,
    -163.4752,
    -164.6121,
    -162.4891,
    -163.9374,
    -162.1388,
    -161.4541,
    -164.7197,
    -161.8545,
    -163.0352,
    -161.5045,
    -164.0659
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -162.4069,
    -164.4876,
    -164.7527,
    -161.4160,
    -164.4127,
    -163.4752,
    -164.6121,
    -162.4891,
    -163.9374,
    -162.1388,
    -161.4541,
    -164.7197,
    -161.8545,
    -163.0352,
    -161.5045,
    -164.0659
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.1409, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0215,
        0.0127,
        -0.0057,  ...,
        -0.0264,
        -0.0147,
        -0.0057
    ],
    [
        -0.0226,
        0.0127,
        -0.0047,  ...,
        -0.0276,
        -0.0191,
        -0.0070
    ],
    [
        -0.0226,
        0.0144,
        -0.0033,  ...,
        -0.0275,
        -0.0162,
        -0.0061
    ],
        ...,
    [
        -0.0222,
        0.0133,
        -0.0051,  ...,
        -0.0260,
        -0.0168,
        -0.0071
    ],
    [
        -0.0219,
        0.0103,
        -0.0054,  ...,
        -0.0261,
        -0.0191,
        -0.0047
    ],
    [
        -0.0212,
        0.0130,
        -0.0042,  ...,
        -0.0272,
        -0.0192,
        -0.0061
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0244,
            0.0075,
            0.0067,  ...,
            -0.0187,
            -0.0108,
            0.0022
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0254,
            0.0088,
            0.0062,  ...,
            -0.0189,
            -0.0136,
            0.0008
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0259,
            0.0112,
            0.0087,  ...,
            -0.0192,
            -0.0127,
            0.0021
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1097,
        0.2014,
        -0.1772
    ],
    [
        0.3270,
        -0.2404,
        0.2223,  ...,
        -0.1097,
        0.2014,
        -0.1772
    ],
    [
        0.3270,
        -0.2404,
        0.2223,  ...,
        -0.1097,
        0.2014,
        -0.1772
    ],
        ...,
    [
        0.3270,
        -0.2404,
        0.2223,  ...,
        -0.1097,
        0.2014,
        -0.1772
    ],
    [
        0.3270,
        -0.2404,
        0.2223,  ...,
        -0.1097,
        0.2014,
        -0.1772
    ],
    [
        0.3270,
        -0.2404,
        0.2223,  ...,
        -0.1097,
        0.2014,
        -0.1772
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -161.7009,
    -163.7774,
    -164.0202,
    -160.7317,
    -163.6900,
    -162.7556,
    -163.8871,
    -161.7989,
    -163.2342,
    -161.4578,
    -160.7574,
    -163.9913,
    -161.1574,
    -162.3484,
    -160.8094,
    -163.3486
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -161.7009,
    -163.7774,
    -164.0202,
    -160.7317,
    -163.6900,
    -162.7556,
    -163.8871,
    -161.7989,
    -163.2342,
    -161.4578,
    -160.7574,
    -163.9913,
    -161.1574,
    -162.3484,
    -160.8094,
    -163.3486
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.1480, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0216,
        0.0214,
        -0.0137,  ...,
        -0.0322,
        -0.0258,
        -0.0069
    ],
    [
        -0.0225,
        0.0220,
        -0.0133,  ...,
        -0.0327,
        -0.0283,
        -0.0079
    ],
    [
        -0.0241,
        0.0234,
        -0.0118,  ...,
        -0.0314,
        -0.0248,
        -0.0059
    ],
        ...,
    [
        -0.0216,
        0.0210,
        -0.0129,  ...,
        -0.0313,
        -0.0269,
        -0.0078
    ],
    [
        -0.0228,
        0.0194,
        -0.0135,  ...,
        -0.0308,
        -0.0284,
        -0.0057
    ],
    [
        -0.0233,
        0.0216,
        -0.0111,  ...,
        -0.0335,
        -0.0285,
        -0.0058
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0215,
            0.0127,
            -0.0057,  ...,
            -0.0264,
            -0.0147,
            -0.0057
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0226,
            0.0127,
            -0.0047,  ...,
            -0.0276,
            -0.0191,
            -0.0070
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0226,
            0.0144,
            -0.0033,  ...,
            -0.0275,
            -0.0162,
            -0.0061
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1160,
        0.1921,
        -0.1769
    ],
    [
        0.3269,
        -0.2316,
        0.2143,  ...,
        -0.1160,
        0.1921,
        -0.1769
    ],
    [
        0.3269,
        -0.2316,
        0.2143,  ...,
        -0.1160,
        0.1921,
        -0.1769
    ],
        ...,
    [
        0.3269,
        -0.2316,
        0.2143,  ...,
        -0.1160,
        0.1921,
        -0.1769
    ],
    [
        0.3269,
        -0.2316,
        0.2143,  ...,
        -0.1160,
        0.1921,
        -0.1769
    ],
    [
        0.3269,
        -0.2316,
        0.2143,  ...,
        -0.1160,
        0.1921,
        -0.1769
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -157.7939,
    -159.8262,
    -160.0544,
    -156.8562,
    -159.7356,
    -158.8141,
    -159.9211,
    -157.8924,
    -159.3100,
    -157.5775,
    -156.8762,
    -160.0210,
    -157.2785,
    -158.4565,
    -156.9262,
    -159.4121
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -157.7939,
    -159.8262,
    -160.0543,
    -156.8562,
    -159.7356,
    -158.8141,
    -159.9211,
    -157.8924,
    -159.3100,
    -157.5776,
    -156.8762,
    -160.0210,
    -157.2785,
    -158.4565,
    -156.9262,
    -159.4121
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.1872, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0255,
        0.0348,
        -0.0190,  ...,
        -0.0328,
        -0.0345,
        -0.0048
    ],
    [
        -0.0257,
        0.0348,
        -0.0182,  ...,
        -0.0338,
        -0.0371,
        -0.0051
    ],
    [
        -0.0274,
        0.0372,
        -0.0170,  ...,
        -0.0318,
        -0.0324,
        -0.0031
    ],
        ...,
    [
        -0.0258,
        0.0342,
        -0.0181,  ...,
        -0.0322,
        -0.0356,
        -0.0052
    ],
    [
        -0.0267,
        0.0328,
        -0.0183,  ...,
        -0.0308,
        -0.0365,
        -0.0033
    ],
    [
        -0.0270,
        0.0344,
        -0.0153,  ...,
        -0.0348,
        -0.0368,
        -0.0019
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0216,
            0.0214,
            -0.0137,  ...,
            -0.0322,
            -0.0258,
            -0.0069
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0225,
            0.0220,
            -0.0133,  ...,
            -0.0327,
            -0.0283,
            -0.0079
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0241,
            0.0234,
            -0.0118,  ...,
            -0.0314,
            -0.0248,
            -0.0059
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1173,
        0.1838,
        -0.1730
    ],
    [
        0.3230,
        -0.2183,
        0.2091,  ...,
        -0.1173,
        0.1838,
        -0.1730
    ],
    [
        0.3230,
        -0.2183,
        0.2091,  ...,
        -0.1173,
        0.1838,
        -0.1730
    ],
        ...,
    [
        0.3230,
        -0.2183,
        0.2091,  ...,
        -0.1173,
        0.1838,
        -0.1730
    ],
    [
        0.3230,
        -0.2183,
        0.2091,  ...,
        -0.1173,
        0.1838,
        -0.1730
    ],
    [
        0.3230,
        -0.2183,
        0.2091,  ...,
        -0.1173,
        0.1838,
        -0.1730
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -152.7314,
    -154.6932,
    -154.9108,
    -151.8178,
    -154.6066,
    -153.6963,
    -154.7761,
    -152.8150,
    -154.2105,
    -152.5281,
    -151.8327,
    -154.8687,
    -152.2318,
    -153.3944,
    -151.8855,
    -154.3004
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -152.7314,
    -154.6932,
    -154.9108,
    -151.8178,
    -154.6066,
    -153.6963,
    -154.7761,
    -152.8150,
    -154.2105,
    -152.5281,
    -151.8327,
    -154.8687,
    -152.2318,
    -153.3944,
    -151.8855,
    -154.3004
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.2381, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0279,
        0.0487,
        -0.0242,  ...,
        -0.0325,
        -0.0438,
        -0.0021
    ],
    [
        -0.0279,
        0.0482,
        -0.0228,  ...,
        -0.0336,
        -0.0455,
        -0.0020
    ],
    [
        -0.0302,
        0.0508,
        -0.0225,  ...,
        -0.0315,
        -0.0411,
        0.0001
    ],
        ...,
    [
        -0.0289,
        0.0474,
        -0.0227,  ...,
        -0.0322,
        -0.0446,
        -0.0022
    ],
    [
        -0.0295,
        0.0466,
        -0.0229,  ...,
        -0.0305,
        -0.0451,
        -0.0003
    ],
    [
        -0.0290,
        0.0481,
        -0.0203,  ...,
        -0.0348,
        -0.0452,
        0.0012
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0255,
            0.0348,
            -0.0190,  ...,
            -0.0328,
            -0.0345,
            -0.0048
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0257,
            0.0348,
            -0.0182,  ...,
            -0.0338,
            -0.0371,
            -0.0051
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0274,
            0.0372,
            -0.0170,  ...,
            -0.0318,
            -0.0324,
            -0.0031
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1173,
        0.1754,
        -0.1699
    ],
    [
        0.3206,
        -0.2044,
        0.2039,  ...,
        -0.1173,
        0.1754,
        -0.1699
    ],
    [
        0.3206,
        -0.2044,
        0.2039,  ...,
        -0.1173,
        0.1754,
        -0.1699
    ],
        ...,
    [
        0.3206,
        -0.2044,
        0.2039,  ...,
        -0.1173,
        0.1754,
        -0.1699
    ],
    [
        0.3206,
        -0.2044,
        0.2039,  ...,
        -0.1173,
        0.1754,
        -0.1699
    ],
    [
        0.3206,
        -0.2044,
        0.2039,  ...,
        -0.1173,
        0.1754,
        -0.1699
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -147.1348,
    -149.0209,
    -149.2247,
    -146.2512,
    -148.9361,
    -148.0449,
    -149.0883,
    -147.2113,
    -148.5713,
    -146.9417,
    -146.2525,
    -149.1746,
    -146.6527,
    -147.7970,
    -146.3087,
    -148.6500
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -147.1348,
    -149.0209,
    -149.2247,
    -146.2512,
    -148.9361,
    -148.0449,
    -149.0883,
    -147.2113,
    -148.5713,
    -146.9417,
    -146.2524,
    -149.1746,
    -146.6527,
    -147.7970,
    -146.3087,
    -148.6500
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.2944, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0298,
        0.0620,
        -0.0296,  ...,
        -0.0319,
        -0.0532,
        0.0018
    ],
    [
        -0.0298,
        0.0617,
        -0.0279,  ...,
        -0.0328,
        -0.0547,
        0.0016
    ],
    [
        -0.0323,
        0.0641,
        -0.0275,  ...,
        -0.0308,
        -0.0502,
        0.0043
    ],
        ...,
    [
        -0.0314,
        0.0606,
        -0.0279,  ...,
        -0.0319,
        -0.0538,
        0.0014
    ],
    [
        -0.0314,
        0.0603,
        -0.0279,  ...,
        -0.0299,
        -0.0541,
        0.0036
    ],
    [
        -0.0314,
        0.0619,
        -0.0257,  ...,
        -0.0339,
        -0.0545,
        0.0054
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -2.7909e-02,
            4.8671e-02,
            -2.4175e-02,  ...,
            -3.2547e-02,
            -4.3798e-02,
            -2.1087e-03
        ],
        [
            -2.1075e-01,
            1.8486e-01,
            -1.1182e-01,  ...,
            9.3930e-02,
            -2.4299e-01,
            3.1084e-01
        ],
        [
            -2.3041e-01,
            1.7322e-01,
            -6.5837e-02,  ...,
            9.7578e-02,
            -2.1997e-01,
            2.7647e-01
        ],
         ...,
        [
            -2.1273e-01,
            1.6687e-01,
            -1.8198e-02,  ...,
            2.4089e-02,
            -2.2370e-01,
            1.5885e-01
        ],
        [
            -2.3094e-01,
            1.6743e-01,
            -6.6865e-02,  ...,
            3.6087e-02,
            -2.7589e-01,
            2.4595e-01
        ],
        [
            -1.8372e-01,
            1.7723e-01,
            2.7710e-02,  ...,
            8.2514e-02,
            -2.2057e-01,
            1.7110e-01
        ]
    ],
    [
        [
            -3.4847e-01,
            2.5307e-01,
            -2.2806e-01,  ...,
            1.8325e-01,
            -2.9585e-01,
            4.2928e-01
        ],
        [
            -2.7944e-02,
            4.8155e-02,
            -2.2825e-02,  ...,
            -3.3571e-02,
            -4.5530e-02,
            -2.0084e-03
        ],
        [
            -2.3041e-01,
            1.7322e-01,
            -6.5837e-02,  ...,
            9.7578e-02,
            -2.1997e-01,
            2.7647e-01
        ],
         ...,
        [
            -2.1273e-01,
            1.6687e-01,
            -1.8198e-02,  ...,
            2.4089e-02,
            -2.2370e-01,
            1.5885e-01
        ],
        [
            -2.3094e-01,
            1.6743e-01,
            -6.6865e-02,  ...,
            3.6087e-02,
            -2.7589e-01,
            2.4595e-01
        ],
        [
            -1.8372e-01,
            1.7723e-01,
            2.7710e-02,  ...,
            8.2514e-02,
            -2.2057e-01,
            1.7110e-01
        ]
    ],
    [
        [
            -3.4847e-01,
            2.5307e-01,
            -2.2806e-01,  ...,
            1.8325e-01,
            -2.9585e-01,
            4.2928e-01
        ],
        [
            -2.1075e-01,
            1.8486e-01,
            -1.1182e-01,  ...,
            9.3930e-02,
            -2.4299e-01,
            3.1084e-01
        ],
        [
            -3.0242e-02,
            5.0795e-02,
            -2.2522e-02,  ...,
            -3.1525e-02,
            -4.1126e-02,
            1.4349e-04
        ],
         ...,
        [
            -2.1273e-01,
            1.6687e-01,
            -1.8198e-02,  ...,
            2.4089e-02,
            -2.2370e-01,
            1.5885e-01
        ],
        [
            -2.3094e-01,
            1.6743e-01,
            -6.6865e-02,  ...,
            3.6087e-02,
            -2.7589e-01,
            2.4595e-01
        ],
        [
            -1.8372e-01,
            1.7723e-01,
            2.7710e-02,  ...,
            8.2514e-02,
            -2.2057e-01,
            1.7110e-01
        ]
    ],

        ...,
    [
        [
            -3.4847e-01,
            2.5307e-01,
            -2.2806e-01,  ...,
            1.8325e-01,
            -2.9585e-01,
            4.2928e-01
        ],
        [
            -2.1075e-01,
            1.8486e-01,
            -1.1182e-01,  ...,
            9.3930e-02,
            -2.4299e-01,
            3.1084e-01
        ],
        [
            -2.3041e-01,
            1.7322e-01,
            -6.5837e-02,  ...,
            9.7578e-02,
            -2.1997e-01,
            2.7647e-01
        ],
         ...,
        [
            -2.1273e-01,
            1.6687e-01,
            -1.8198e-02,  ...,
            2.4089e-02,
            -2.2370e-01,
            1.5885e-01
        ],
        [
            -2.3094e-01,
            1.6743e-01,
            -6.6865e-02,  ...,
            3.6087e-02,
            -2.7589e-01,
            2.4595e-01
        ],
        [
            -1.8372e-01,
            1.7723e-01,
            2.7710e-02,  ...,
            8.2514e-02,
            -2.2057e-01,
            1.7110e-01
        ]
    ],
    [
        [
            -3.4847e-01,
            2.5307e-01,
            -2.2806e-01,  ...,
            1.8325e-01,
            -2.9585e-01,
            4.2928e-01
        ],
        [
            -2.1075e-01,
            1.8486e-01,
            -1.1182e-01,  ...,
            9.3930e-02,
            -2.4299e-01,
            3.1084e-01
        ],
        [
            -2.3041e-01,
            1.7322e-01,
            -6.5837e-02,  ...,
            9.7578e-02,
            -2.1997e-01,
            2.7647e-01
        ],
         ...,
        [
            -2.1273e-01,
            1.6687e-01,
            -1.8198e-02,  ...,
            2.4089e-02,
            -2.2370e-01,
            1.5885e-01
        ],
        [
            -2.3094e-01,
            1.6743e-01,
            -6.6865e-02,  ...,
            3.6087e-02,
            -2.7589e-01,
            2.4595e-01
        ],
        [
            -1.8372e-01,
            1.7723e-01,
            2.7710e-02,  ...,
            8.2514e-02,
            -2.2057e-01,
            1.7110e-01
        ]
    ],
    [
        [
            -3.4847e-01,
            2.5307e-01,
            -2.2806e-01,  ...,
            1.8325e-01,
            -2.9585e-01,
            4.2928e-01
        ],
        [
            -2.1075e-01,
            1.8486e-01,
            -1.1182e-01,  ...,
            9.3930e-02,
            -2.4299e-01,
            3.1084e-01
        ],
        [
            -2.3041e-01,
            1.7322e-01,
            -6.5837e-02,  ...,
            9.7578e-02,
            -2.1997e-01,
            2.7647e-01
        ],
         ...,
        [
            -2.1273e-01,
            1.6687e-01,
            -1.8198e-02,  ...,
            2.4089e-02,
            -2.2370e-01,
            1.5885e-01
        ],
        [
            -2.3094e-01,
            1.6743e-01,
            -6.6865e-02,  ...,
            3.6087e-02,
            -2.7589e-01,
            2.4595e-01
        ],
        [
            -1.8372e-01,
            1.7723e-01,
            2.7710e-02,  ...,
            8.2514e-02,
            -2.2057e-01,
            1.7110e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1164,
        0.1661,
        -0.1657
    ],
    [
        0.3186,
        -0.1911,
        0.1985,  ...,
        -0.1164,
        0.1661,
        -0.1657
    ],
    [
        0.3186,
        -0.1911,
        0.1985,  ...,
        -0.1164,
        0.1661,
        -0.1657
    ],
        ...,
    [
        0.3186,
        -0.1911,
        0.1985,  ...,
        -0.1164,
        0.1661,
        -0.1657
    ],
    [
        0.3186,
        -0.1911,
        0.1985,  ...,
        -0.1164,
        0.1661,
        -0.1657
    ],
    [
        0.3186,
        -0.1911,
        0.1985,  ...,
        -0.1164,
        0.1661,
        -0.1657
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -141.5836,
    -143.3882,
    -143.5818,
    -140.7355,
    -143.3132,
    -142.4369,
    -143.4450,
    -141.6522,
    -142.9754,
    -141.4057,
    -140.7214,
    -143.5254,
    -141.1227,
    -142.2433,
    -140.7851,
    -143.0438
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -141.5836,
    -143.3883,
    -143.5817,
    -140.7355,
    -143.3132,
    -142.4369,
    -143.4450,
    -141.6522,
    -142.9754,
    -141.4057,
    -140.7214,
    -143.5254,
    -141.1227,
    -142.2433,
    -140.7851,
    -143.0438
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.3502, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0322,
        0.0752,
        -0.0340,  ...,
        -0.0310,
        -0.0626,
        0.0060
    ],
    [
        -0.0323,
        0.0750,
        -0.0326,  ...,
        -0.0320,
        -0.0635,
        0.0058
    ],
    [
        -0.0345,
        0.0773,
        -0.0319,  ...,
        -0.0302,
        -0.0595,
        0.0087
    ],
        ...,
    [
        -0.0337,
        0.0738,
        -0.0324,  ...,
        -0.0311,
        -0.0631,
        0.0052
    ],
    [
        -0.0338,
        0.0738,
        -0.0324,  ...,
        -0.0290,
        -0.0633,
        0.0079
    ],
    [
        -0.0341,
        0.0752,
        -0.0305,  ...,
        -0.0327,
        -0.0639,
        0.0092
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0298,
            0.0620,
            -0.0296,  ...,
            -0.0319,
            -0.0532,
            0.0018
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0298,
            0.0617,
            -0.0279,  ...,
            -0.0328,
            -0.0547,
            0.0016
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0323,
            0.0641,
            -0.0275,  ...,
            -0.0308,
            -0.0502,
            0.0043
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1152,
        0.1567,
        -0.1619
    ],
    [
        0.3162,
        -0.1778,
        0.1941,  ...,
        -0.1152,
        0.1567,
        -0.1619
    ],
    [
        0.3162,
        -0.1778,
        0.1941,  ...,
        -0.1152,
        0.1567,
        -0.1619
    ],
        ...,
    [
        0.3162,
        -0.1778,
        0.1941,  ...,
        -0.1152,
        0.1567,
        -0.1619
    ],
    [
        0.3162,
        -0.1778,
        0.1941,  ...,
        -0.1152,
        0.1567,
        -0.1619
    ],
    [
        0.3162,
        -0.1778,
        0.1941,  ...,
        -0.1152,
        0.1567,
        -0.1619
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -136.3302,
    -138.0556,
    -138.2348,
    -135.5164,
    -137.9879,
    -137.1254,
    -138.0979,
    -136.3917,
    -137.6772,
    -136.1665,
    -135.4907,
    -138.1748,
    -135.8896,
    -136.9903,
    -135.5629,
    -137.7349
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -136.3302,
    -138.0556,
    -138.2348,
    -135.5164,
    -137.9879,
    -137.1254,
    -138.0979,
    -136.3917,
    -137.6772,
    -136.1665,
    -135.4907,
    -138.1748,
    -135.8896,
    -136.9903,
    -135.5629,
    -137.7349
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.4030, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0345,
        0.0886,
        -0.0388,  ...,
        -0.0299,
        -0.0722,
        0.0089
    ],
    [
        -0.0344,
        0.0884,
        -0.0374,  ...,
        -0.0312,
        -0.0725,
        0.0088
    ],
    [
        -0.0366,
        0.0906,
        -0.0366,  ...,
        -0.0294,
        -0.0690,
        0.0120
    ],
        ...,
    [
        -0.0360,
        0.0871,
        -0.0372,  ...,
        -0.0300,
        -0.0726,
        0.0082
    ],
    [
        -0.0360,
        0.0872,
        -0.0371,  ...,
        -0.0278,
        -0.0726,
        0.0110
    ],
    [
        -0.0365,
        0.0886,
        -0.0354,  ...,
        -0.0313,
        -0.0735,
        0.0118
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0322,
            0.0752,
            -0.0340,  ...,
            -0.0310,
            -0.0626,
            0.0060
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0323,
            0.0750,
            -0.0326,  ...,
            -0.0320,
            -0.0635,
            0.0058
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0345,
            0.0773,
            -0.0319,  ...,
            -0.0302,
            -0.0595,
            0.0087
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1138,
        0.1471,
        -0.1593
    ],
    [
        0.3139,
        -0.1645,
        0.1892,  ...,
        -0.1138,
        0.1471,
        -0.1593
    ],
    [
        0.3139,
        -0.1645,
        0.1892,  ...,
        -0.1138,
        0.1471,
        -0.1593
    ],
        ...,
    [
        0.3139,
        -0.1645,
        0.1892,  ...,
        -0.1138,
        0.1471,
        -0.1593
    ],
    [
        0.3139,
        -0.1645,
        0.1892,  ...,
        -0.1138,
        0.1471,
        -0.1593
    ],
    [
        0.3139,
        -0.1645,
        0.1892,  ...,
        -0.1138,
        0.1471,
        -0.1593
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -131.4161,
    -133.0624,
    -133.2267,
    -130.6346,
    -133.0029,
    -132.1524,
    -133.0905,
    -131.4697,
    -132.7207,
    -131.2655,
    -130.5994,
    -133.1627,
    -130.9939,
    -132.0762,
    -130.6800,
    -132.7657
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -131.4161,
    -133.0624,
    -133.2267,
    -130.6346,
    -133.0029,
    -132.1524,
    -133.0905,
    -131.4697,
    -132.7207,
    -131.2655,
    -130.5994,
    -133.1627,
    -130.9939,
    -132.0762,
    -130.6800,
    -132.7658
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.4524, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0366,
        0.1018,
        -0.0437,  ...,
        -0.0285,
        -0.0819,
        0.0119
    ],
    [
        -0.0363,
        0.1018,
        -0.0422,  ...,
        -0.0299,
        -0.0821,
        0.0121
    ],
    [
        -0.0387,
        0.1040,
        -0.0412,  ...,
        -0.0278,
        -0.0787,
        0.0150
    ],
        ...,
    [
        -0.0381,
        0.1006,
        -0.0418,  ...,
        -0.0287,
        -0.0822,
        0.0113
    ],
    [
        -0.0380,
        0.1004,
        -0.0417,  ...,
        -0.0262,
        -0.0823,
        0.0140
    ],
    [
        -0.0386,
        0.1020,
        -0.0401,  ...,
        -0.0297,
        -0.0832,
        0.0149
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0345,
            0.0886,
            -0.0388,  ...,
            -0.0299,
            -0.0722,
            0.0089
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0344,
            0.0884,
            -0.0374,  ...,
            -0.0312,
            -0.0725,
            0.0088
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0366,
            0.0906,
            -0.0366,  ...,
            -0.0294,
            -0.0690,
            0.0120
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1122,
        0.1373,
        -0.1562
    ],
    [
        0.3118,
        -0.1513,
        0.1844,  ...,
        -0.1122,
        0.1373,
        -0.1562
    ],
    [
        0.3118,
        -0.1513,
        0.1844,  ...,
        -0.1122,
        0.1373,
        -0.1562
    ],
        ...,
    [
        0.3118,
        -0.1513,
        0.1844,  ...,
        -0.1122,
        0.1373,
        -0.1562
    ],
    [
        0.3118,
        -0.1513,
        0.1844,  ...,
        -0.1122,
        0.1373,
        -0.1562
    ],
    [
        0.3118,
        -0.1513,
        0.1844,  ...,
        -0.1122,
        0.1373,
        -0.1562
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -126.8562,
    -128.4242,
    -128.5732,
    -126.1078,
    -128.3722,
    -127.5353,
    -128.4378,
    -126.9040,
    -128.1183,
    -126.7197,
    -126.0622,
    -128.5056,
    -126.4521,
    -127.5155,
    -126.1520,
    -128.1493
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -126.8562,
    -128.4243,
    -128.5732,
    -126.1078,
    -128.3722,
    -127.5353,
    -128.4378,
    -126.9040,
    -128.1183,
    -126.7197,
    -126.0622,
    -128.5056,
    -126.4521,
    -127.5155,
    -126.1520,
    -128.1493
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.4983, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0386,
        0.1150,
        -0.0483,  ...,
        -0.0270,
        -0.0916,
        0.0153
    ],
    [
        -0.0378,
        0.1151,
        -0.0470,  ...,
        -0.0284,
        -0.0919,
        0.0155
    ],
    [
        -0.0405,
        0.1174,
        -0.0460,  ...,
        -0.0263,
        -0.0885,
        0.0183
    ],
        ...,
    [
        -0.0398,
        0.1140,
        -0.0465,  ...,
        -0.0272,
        -0.0919,
        0.0147
    ],
    [
        -0.0398,
        0.1136,
        -0.0462,  ...,
        -0.0247,
        -0.0920,
        0.0173
    ],
    [
        -0.0403,
        0.1156,
        -0.0448,  ...,
        -0.0282,
        -0.0931,
        0.0184
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0366,
            0.1018,
            -0.0437,  ...,
            -0.0285,
            -0.0819,
            0.0119
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0363,
            0.1018,
            -0.0422,  ...,
            -0.0299,
            -0.0821,
            0.0121
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0387,
            0.1040,
            -0.0412,  ...,
            -0.0278,
            -0.0787,
            0.0150
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1107,
        0.1274,
        -0.1527
    ],
    [
        0.3099,
        -0.1381,
        0.1798,  ...,
        -0.1107,
        0.1274,
        -0.1527
    ],
    [
        0.3099,
        -0.1381,
        0.1798,  ...,
        -0.1107,
        0.1274,
        -0.1527
    ],
        ...,
    [
        0.3099,
        -0.1381,
        0.1798,  ...,
        -0.1107,
        0.1274,
        -0.1527
    ],
    [
        0.3099,
        -0.1381,
        0.1798,  ...,
        -0.1107,
        0.1274,
        -0.1527
    ],
    [
        0.3099,
        -0.1381,
        0.1798,  ...,
        -0.1107,
        0.1274,
        -0.1527
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -122.6802,
    -124.1698,
    -124.3048,
    -121.9641,
    -124.1250,
    -123.3006,
    -124.1692,
    -122.7210,
    -123.9004,
    -122.5575,
    -121.9099,
    -124.2334,
    -122.2941,
    -123.3384,
    -122.0072,
    -123.9172
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -122.6802,
    -124.1698,
    -124.3048,
    -121.9641,
    -124.1250,
    -123.3006,
    -124.1692,
    -122.7210,
    -123.9004,
    -122.5575,
    -121.9099,
    -124.2334,
    -122.2941,
    -123.3384,
    -122.0072,
    -123.9172
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.5404, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0403,
        0.1284,
        -0.0529,  ...,
        -0.0255,
        -0.1013,
        0.0187
    ],
    [
        -0.0393,
        0.1285,
        -0.0517,  ...,
        -0.0269,
        -0.1016,
        0.0187
    ],
    [
        -0.0421,
        0.1310,
        -0.0508,  ...,
        -0.0247,
        -0.0982,
        0.0216
    ],
        ...,
    [
        -0.0415,
        0.1274,
        -0.0514,  ...,
        -0.0258,
        -0.1014,
        0.0182
    ],
    [
        -0.0416,
        0.1272,
        -0.0508,  ...,
        -0.0233,
        -0.1017,
        0.0206
    ],
    [
        -0.0420,
        0.1292,
        -0.0495,  ...,
        -0.0265,
        -0.1029,
        0.0220
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0386,
            0.1150,
            -0.0483,  ...,
            -0.0270,
            -0.0916,
            0.0153
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0378,
            0.1151,
            -0.0470,  ...,
            -0.0284,
            -0.0919,
            0.0155
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0405,
            0.1174,
            -0.0460,  ...,
            -0.0263,
            -0.0885,
            0.0183
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1090,
        0.1177,
        -0.1491
    ],
    [
        0.3082,
        -0.1246,
        0.1752,  ...,
        -0.1090,
        0.1177,
        -0.1491
    ],
    [
        0.3082,
        -0.1246,
        0.1752,  ...,
        -0.1090,
        0.1177,
        -0.1491
    ],
        ...,
    [
        0.3082,
        -0.1246,
        0.1752,  ...,
        -0.1090,
        0.1177,
        -0.1491
    ],
    [
        0.3082,
        -0.1246,
        0.1752,  ...,
        -0.1090,
        0.1177,
        -0.1491
    ],
    [
        0.3082,
        -0.1246,
        0.1752,  ...,
        -0.1090,
        0.1177,
        -0.1491
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -118.9066,
    -120.3178,
    -120.4392,
    -118.2247,
    -120.2811,
    -119.4693,
    -120.3034,
    -118.9401,
    -120.0853,
    -118.7986,
    -118.1612,
    -120.3638,
    -118.5388,
    -119.5645,
    -118.2656,
    -120.0882
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -118.9066,
    -120.3178,
    -120.4392,
    -118.2247,
    -120.2811,
    -119.4693,
    -120.3034,
    -118.9401,
    -120.0853,
    -118.7986,
    -118.1613,
    -120.3638,
    -118.5388,
    -119.5645,
    -118.2656,
    -120.0882
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.5784, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0419,
        0.1420,
        -0.0577,  ...,
        -0.0238,
        -0.1111,
        0.0221
    ],
    [
        -0.0408,
        0.1418,
        -0.0565,  ...,
        -0.0253,
        -0.1112,
        0.0219
    ],
    [
        -0.0435,
        0.1446,
        -0.0556,  ...,
        -0.0231,
        -0.1081,
        0.0248
    ],
        ...,
    [
        -0.0428,
        0.1409,
        -0.0563,  ...,
        -0.0242,
        -0.1109,
        0.0218
    ],
    [
        -0.0431,
        0.1407,
        -0.0557,  ...,
        -0.0218,
        -0.1115,
        0.0239
    ],
    [
        -0.0437,
        0.1427,
        -0.0543,  ...,
        -0.0248,
        -0.1127,
        0.0255
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0403,
            0.1284,
            -0.0529,  ...,
            -0.0255,
            -0.1013,
            0.0187
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0393,
            0.1285,
            -0.0517,  ...,
            -0.0269,
            -0.1016,
            0.0187
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0421,
            0.1310,
            -0.0508,  ...,
            -0.0247,
            -0.0982,
            0.0216
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1073,
        0.1078,
        -0.1456
    ],
    [
        0.3066,
        -0.1111,
        0.1704,  ...,
        -0.1073,
        0.1078,
        -0.1456
    ],
    [
        0.3066,
        -0.1111,
        0.1704,  ...,
        -0.1073,
        0.1078,
        -0.1456
    ],
        ...,
    [
        0.3066,
        -0.1111,
        0.1704,  ...,
        -0.1073,
        0.1078,
        -0.1456
    ],
    [
        0.3066,
        -0.1111,
        0.1704,  ...,
        -0.1073,
        0.1078,
        -0.1456
    ],
    [
        0.3066,
        -0.1111,
        0.1704,  ...,
        -0.1073,
        0.1078,
        -0.1456
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -115.5458,
    -116.8779,
    -116.9849,
    -114.8974,
    -116.8489,
    -116.0494,
    -116.8495,
    -115.5720,
    -116.6822,
    -115.4515,
    -114.8242,
    -116.9054,
    -115.1964,
    -116.2026,
    -114.9353,
    -116.6709
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -115.5458,
    -116.8779,
    -116.9849,
    -114.8974,
    -116.8489,
    -116.0494,
    -116.8495,
    -115.5720,
    -116.6822,
    -115.4515,
    -114.8242,
    -116.9054,
    -115.1964,
    -116.2026,
    -114.9353,
    -116.6709
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.6123, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0432,
        0.1552,
        -0.0624,  ...,
        -0.0220,
        -0.1207,
        0.0256
    ],
    [
        -0.0424,
        0.1550,
        -0.0611,  ...,
        -0.0234,
        -0.1207,
        0.0252
    ],
    [
        -0.0450,
        0.1579,
        -0.0604,  ...,
        -0.0213,
        -0.1178,
        0.0282
    ],
        ...,
    [
        -0.0442,
        0.1542,
        -0.0611,  ...,
        -0.0224,
        -0.1206,
        0.0252
    ],
    [
        -0.0447,
        0.1537,
        -0.0605,  ...,
        -0.0201,
        -0.1211,
        0.0271
    ],
    [
        -0.0451,
        0.1561,
        -0.0593,  ...,
        -0.0231,
        -0.1225,
        0.0289
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0419,
            0.1420,
            -0.0577,  ...,
            -0.0238,
            -0.1111,
            0.0221
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0408,
            0.1418,
            -0.0565,  ...,
            -0.0253,
            -0.1112,
            0.0219
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0435,
            0.1446,
            -0.0556,  ...,
            -0.0231,
            -0.1081,
            0.0248
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1056,
        0.0981,
        -0.1422
    ],
    [
        0.3053,
        -0.0979,
        0.1657,  ...,
        -0.1056,
        0.0981,
        -0.1422
    ],
    [
        0.3053,
        -0.0979,
        0.1657,  ...,
        -0.1056,
        0.0981,
        -0.1422
    ],
        ...,
    [
        0.3053,
        -0.0979,
        0.1657,  ...,
        -0.1056,
        0.0981,
        -0.1422
    ],
    [
        0.3053,
        -0.0979,
        0.1657,  ...,
        -0.1056,
        0.0981,
        -0.1422
    ],
    [
        0.3053,
        -0.0979,
        0.1657,  ...,
        -0.1056,
        0.0981,
        -0.1422
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -112.5978,
    -113.8523,
    -113.9429,
    -111.9839,
    -113.8293,
    -113.0437,
    -113.8086,
    -112.6165,
    -113.6923,
    -112.5175,
    -111.9002,
    -113.8595,
    -112.2668,
    -113.2537,
    -112.0199,
    -113.6663
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -112.5978,
    -113.8523,
    -113.9429,
    -111.9839,
    -113.8293,
    -113.0437,
    -113.8086,
    -112.6165,
    -113.6923,
    -112.5175,
    -111.9002,
    -113.8595,
    -112.2668,
    -113.2537,
    -112.0199,
    -113.6663
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.6421, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0448,
        0.1684,
        -0.0673,  ...,
        -0.0201,
        -0.1305,
        0.0291
    ],
    [
        -0.0440,
        0.1680,
        -0.0661,  ...,
        -0.0217,
        -0.1300,
        0.0285
    ],
    [
        -0.0465,
        0.1708,
        -0.0652,  ...,
        -0.0195,
        -0.1273,
        0.0315
    ],
        ...,
    [
        -0.0458,
        0.1673,
        -0.0659,  ...,
        -0.0207,
        -0.1300,
        0.0286
    ],
    [
        -0.0463,
        0.1667,
        -0.0653,  ...,
        -0.0186,
        -0.1305,
        0.0304
    ],
    [
        -0.0467,
        0.1694,
        -0.0641,  ...,
        -0.0213,
        -0.1320,
        0.0323
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0432,
            0.1552,
            -0.0624,  ...,
            -0.0220,
            -0.1207,
            0.0256
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0424,
            0.1550,
            -0.0611,  ...,
            -0.0234,
            -0.1207,
            0.0252
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0450,
            0.1579,
            -0.0604,  ...,
            -0.0213,
            -0.1178,
            0.0282
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1038,
        0.0886,
        -0.1388
    ],
    [
        0.3037,
        -0.0847,
        0.1608,  ...,
        -0.1038,
        0.0886,
        -0.1388
    ],
    [
        0.3037,
        -0.0847,
        0.1608,  ...,
        -0.1038,
        0.0886,
        -0.1388
    ],
        ...,
    [
        0.3037,
        -0.0847,
        0.1608,  ...,
        -0.1038,
        0.0886,
        -0.1388
    ],
    [
        0.3037,
        -0.0847,
        0.1608,  ...,
        -0.1038,
        0.0886,
        -0.1388
    ],
    [
        0.3037,
        -0.0847,
        0.1608,  ...,
        -0.1038,
        0.0886,
        -0.1388
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -110.0505,
    -111.2270,
    -111.3022,
    -109.4710,
    -111.2105,
    -110.4379,
    -111.1684,
    -110.0616,
    -111.1030,
    -109.9849,
    -109.3779,
    -111.2141,
    -109.7382,
    -110.7055,
    -109.5045,
    -111.0628
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -110.0505,
    -111.2270,
    -111.3022,
    -109.4710,
    -111.2105,
    -110.4379,
    -111.1684,
    -110.0616,
    -111.1030,
    -109.9849,
    -109.3779,
    -111.2141,
    -109.7382,
    -110.7054,
    -109.5045,
    -111.0628
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.6679, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0462,
        0.1813,
        -0.0720,  ...,
        -0.0184,
        -0.1399,
        0.0322
    ],
    [
        -0.0456,
        0.1810,
        -0.0710,  ...,
        -0.0200,
        -0.1393,
        0.0318
    ],
    [
        -0.0480,
        0.1838,
        -0.0700,  ...,
        -0.0180,
        -0.1367,
        0.0348
    ],
        ...,
    [
        -0.0473,
        0.1803,
        -0.0708,  ...,
        -0.0189,
        -0.1393,
        0.0320
    ],
    [
        -0.0478,
        0.1796,
        -0.0703,  ...,
        -0.0169,
        -0.1400,
        0.0338
    ],
    [
        -0.0480,
        0.1824,
        -0.0691,  ...,
        -0.0195,
        -0.1414,
        0.0357
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0448,
            0.1684,
            -0.0673,  ...,
            -0.0201,
            -0.1305,
            0.0291
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0440,
            0.1680,
            -0.0661,  ...,
            -0.0217,
            -0.1300,
            0.0285
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0465,
            0.1708,
            -0.0652,  ...,
            -0.0195,
            -0.1273,
            0.0315
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1020,
        0.0791,
        -0.1354
    ],
    [
        0.3022,
        -0.0718,
        0.1560,  ...,
        -0.1020,
        0.0791,
        -0.1354
    ],
    [
        0.3022,
        -0.0718,
        0.1560,  ...,
        -0.1020,
        0.0791,
        -0.1354
    ],
        ...,
    [
        0.3022,
        -0.0718,
        0.1560,  ...,
        -0.1020,
        0.0791,
        -0.1354
    ],
    [
        0.3022,
        -0.0718,
        0.1560,  ...,
        -0.1020,
        0.0791,
        -0.1354
    ],
    [
        0.3022,
        -0.0718,
        0.1560,  ...,
        -0.1020,
        0.0791,
        -0.1354
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -107.9189,
    -109.0167,
    -109.0762,
    -107.3732,
    -109.0068,
    -108.2477,
    -108.9430,
    -107.9230,
    -108.9292,
    -107.8673,
    -107.2716,
    -108.9846,
    -107.6258,
    -108.5730,
    -107.4047,
    -108.8748
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -107.9189,
    -109.0167,
    -109.0762,
    -107.3732,
    -109.0068,
    -108.2477,
    -108.9430,
    -107.9230,
    -108.9292,
    -107.8673,
    -107.2716,
    -108.9846,
    -107.6258,
    -108.5729,
    -107.4047,
    -108.8748
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.6895, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0478,
        0.1942,
        -0.0769,  ...,
        -0.0165,
        -0.1493,
        0.0356
    ],
    [
        -0.0471,
        0.1938,
        -0.0758,  ...,
        -0.0181,
        -0.1486,
        0.0354
    ],
    [
        -0.0495,
        0.1967,
        -0.0748,  ...,
        -0.0163,
        -0.1462,
        0.0381
    ],
        ...,
    [
        -0.0487,
        0.1932,
        -0.0758,  ...,
        -0.0171,
        -0.1488,
        0.0355
    ],
    [
        -0.0493,
        0.1924,
        -0.0751,  ...,
        -0.0150,
        -0.1493,
        0.0373
    ],
    [
        -0.0494,
        0.1953,
        -0.0741,  ...,
        -0.0178,
        -0.1509,
        0.0392
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0462,
            0.1813,
            -0.0720,  ...,
            -0.0184,
            -0.1399,
            0.0322
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0456,
            0.1810,
            -0.0710,  ...,
            -0.0200,
            -0.1393,
            0.0318
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0480,
            0.1838,
            -0.0700,  ...,
            -0.0180,
            -0.1367,
            0.0348
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1003,
        0.0697,
        -0.1319
    ],
    [
        0.3007,
        -0.0588,
        0.1512,  ...,
        -0.1003,
        0.0697,
        -0.1319
    ],
    [
        0.3007,
        -0.0588,
        0.1512,  ...,
        -0.1003,
        0.0697,
        -0.1319
    ],
        ...,
    [
        0.3007,
        -0.0588,
        0.1512,  ...,
        -0.1003,
        0.0697,
        -0.1319
    ],
    [
        0.3007,
        -0.0588,
        0.1512,  ...,
        -0.1003,
        0.0697,
        -0.1319
    ],
    [
        0.3007,
        -0.0588,
        0.1512,  ...,
        -0.1003,
        0.0697,
        -0.1319
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -106.2136,
    -107.2322,
    -107.2763,
    -105.7017,
    -107.2296,
    -106.4838,
    -107.1439,
    -106.2106,
    -107.1814,
    -106.1761,
    -105.5910,
    -107.1807,
    -105.9387,
    -106.8666,
    -105.7302,
    -107.1127
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -106.2136,
    -107.2322,
    -107.2763,
    -105.7017,
    -107.2297,
    -106.4838,
    -107.1439,
    -106.2106,
    -107.1814,
    -106.1761,
    -105.5910,
    -107.1807,
    -105.9387,
    -106.8666,
    -105.7302,
    -107.1127
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.7068, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0492,
        0.2071,
        -0.0817,  ...,
        -0.0147,
        -0.1587,
        0.0390
    ],
    [
        -0.0486,
        0.2068,
        -0.0807,  ...,
        -0.0163,
        -0.1579,
        0.0390
    ],
    [
        -0.0511,
        0.2096,
        -0.0798,  ...,
        -0.0146,
        -0.1555,
        0.0416
    ],
        ...,
    [
        -0.0502,
        0.2062,
        -0.0808,  ...,
        -0.0155,
        -0.1581,
        0.0390
    ],
    [
        -0.0509,
        0.2052,
        -0.0801,  ...,
        -0.0131,
        -0.1586,
        0.0407
    ],
    [
        -0.0509,
        0.2084,
        -0.0790,  ...,
        -0.0160,
        -0.1603,
        0.0427
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0478,
            0.1942,
            -0.0769,  ...,
            -0.0165,
            -0.1493,
            0.0356
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0471,
            0.1938,
            -0.0758,  ...,
            -0.0181,
            -0.1486,
            0.0354
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0495,
            0.1967,
            -0.0748,  ...,
            -0.0163,
            -0.1462,
            0.0381
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0985,
        0.0603,
        -0.1284
    ],
    [
        0.2992,
        -0.0460,
        0.1464,  ...,
        -0.0985,
        0.0603,
        -0.1284
    ],
    [
        0.2992,
        -0.0460,
        0.1464,  ...,
        -0.0985,
        0.0603,
        -0.1284
    ],
        ...,
    [
        0.2992,
        -0.0460,
        0.1464,  ...,
        -0.0985,
        0.0603,
        -0.1284
    ],
    [
        0.2992,
        -0.0460,
        0.1464,  ...,
        -0.0985,
        0.0603,
        -0.1284
    ],
    [
        0.2992,
        -0.0460,
        0.1464,  ...,
        -0.0985,
        0.0603,
        -0.1284
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -104.9376,
    -105.8775,
    -105.9064,
    -104.4598,
    -105.8820,
    -105.1496,
    -105.7748,
    -104.9281,
    -105.8632,
    -104.9145,
    -104.3403,
    -105.8070,
    -104.6818,
    -105.5904,
    -104.4849,
    -105.7803
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -104.9377,
    -105.8775,
    -105.9065,
    -104.4598,
    -105.8820,
    -105.1496,
    -105.7748,
    -104.9281,
    -105.8632,
    -104.9145,
    -104.3403,
    -105.8070,
    -104.6818,
    -105.5904,
    -104.4849,
    -105.7803
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.7199, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0507,
        0.2198,
        -0.0864,  ...,
        -0.0129,
        -0.1679,
        0.0424
    ],
    [
        -0.0501,
        0.2196,
        -0.0855,  ...,
        -0.0145,
        -0.1670,
        0.0424
    ],
    [
        -0.0526,
        0.2224,
        -0.0846,  ...,
        -0.0128,
        -0.1648,
        0.0451
    ],
        ...,
    [
        -0.0516,
        0.2190,
        -0.0857,  ...,
        -0.0136,
        -0.1671,
        0.0424
    ],
    [
        -0.0524,
        0.2181,
        -0.0850,  ...,
        -0.0113,
        -0.1678,
        0.0442
    ],
    [
        -0.0522,
        0.2215,
        -0.0840,  ...,
        -0.0142,
        -0.1697,
        0.0461
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0492,
            0.2071,
            -0.0817,  ...,
            -0.0147,
            -0.1587,
            0.0390
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0486,
            0.2068,
            -0.0807,  ...,
            -0.0163,
            -0.1579,
            0.0390
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0511,
            0.2096,
            -0.0798,  ...,
            -0.0146,
            -0.1555,
            0.0416
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0967,
        0.0508,
        -0.1250
    ],
    [
        0.2978,
        -0.0332,
        0.1416,  ...,
        -0.0967,
        0.0508,
        -0.1250
    ],
    [
        0.2978,
        -0.0332,
        0.1416,  ...,
        -0.0967,
        0.0508,
        -0.1250
    ],
        ...,
    [
        0.2978,
        -0.0332,
        0.1416,  ...,
        -0.0967,
        0.0508,
        -0.1250
    ],
    [
        0.2978,
        -0.0332,
        0.1416,  ...,
        -0.0967,
        0.0508,
        -0.1250
    ],
    [
        0.2978,
        -0.0332,
        0.1416,  ...,
        -0.0967,
        0.0508,
        -0.1250
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -104.0943,
    -104.9553,
    -104.9684,
    -103.6507,
    -104.9673,
    -104.2480,
    -104.8383,
    -104.0784,
    -104.9775,
    -104.0858,
    -103.5214,
    -104.8658,
    -103.8576,
    -104.7459,
    -103.6728,
    -104.8806
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -104.0943,
    -104.9553,
    -104.9684,
    -103.6507,
    -104.9673,
    -104.2480,
    -104.8383,
    -104.0784,
    -104.9775,
    -104.0858,
    -103.5214,
    -104.8658,
    -103.8576,
    -104.7459,
    -103.6728,
    -104.8806
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.7286, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0521,
        0.2328,
        -0.0913,  ...,
        -0.0110,
        -0.1771,
        0.0457
    ],
    [
        -0.0516,
        0.2324,
        -0.0903,  ...,
        -0.0124,
        -0.1761,
        0.0458
    ],
    [
        -0.0541,
        0.2352,
        -0.0896,  ...,
        -0.0109,
        -0.1739,
        0.0487
    ],
        ...,
    [
        -0.0531,
        0.2319,
        -0.0906,  ...,
        -0.0119,
        -0.1764,
        0.0458
    ],
    [
        -0.0538,
        0.2308,
        -0.0898,  ...,
        -0.0093,
        -0.1770,
        0.0477
    ],
    [
        -0.0536,
        0.2342,
        -0.0888,  ...,
        -0.0123,
        -0.1791,
        0.0496
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0507,
            0.2198,
            -0.0864,  ...,
            -0.0129,
            -0.1679,
            0.0424
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.0501,
            0.2196,
            -0.0855,  ...,
            -0.0145,
            -0.1670,
            0.0424
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.0526,
            0.2224,
            -0.0846,  ...,
            -0.0128,
            -0.1648,
            0.0451
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],

        ...,
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ],
    [
        [
            -0.3485,
            0.2531,
            -0.2281,  ...,
            0.1833,
            -0.2959,
            0.4293
        ],
        [
            -0.2107,
            0.1849,
            -0.1118,  ...,
            0.0939,
            -0.2430,
            0.3108
        ],
        [
            -0.2304,
            0.1732,
            -0.0658,  ...,
            0.0976,
            -0.2200,
            0.2765
        ],
         ...,
        [
            -0.2127,
            0.1669,
            -0.0182,  ...,
            0.0241,
            -0.2237,
            0.1588
        ],
        [
            -0.2309,
            0.1674,
            -0.0669,  ...,
            0.0361,
            -0.2759,
            0.2459
        ],
        [
            -0.1837,
            0.1772,
            0.0277,  ...,
            0.0825,
            -0.2206,
            0.1711
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0948,
        0.0415,
        -0.1215
    ],
    [
        0.2964,
        -0.0203,
        0.1367,  ...,
        -0.0948,
        0.0415,
        -0.1215
    ],
    [
        0.2964,
        -0.0203,
        0.1367,  ...,
        -0.0948,
        0.0415,
        -0.1215
    ],
        ...,
    [
        0.2964,
        -0.0203,
        0.1367,  ...,
        -0.0948,
        0.0415,
        -0.1215
    ],
    [
        0.2964,
        -0.0203,
        0.1367,  ...,
        -0.0948,
        0.0415,
        -0.1215
    ],
    [
        0.2964,
        -0.0203,
        0.1367,  ...,
        -0.0948,
        0.0415,
        -0.1215
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -103.6844,
    -104.4665,
    -104.4643,
    -103.2749,
    -104.4845,
    -103.7796,
    -104.3342,
    -103.6613,
    -104.5242,
    -103.6898,
    -103.1356,
    -104.3576,
    -103.4663,
    -104.3353,
    -103.2934,
    -104.4136
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -103.6844,
    -104.4665,
    -104.4643,
    -103.2749,
    -104.4845,
    -103.7796,
    -104.3342,
    -103.6613,
    -104.5241,
    -103.6898,
    -103.1356,
    -104.3576,
    -103.4663,
    -104.3353,
    -103.2934,
    -104.4136
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.7330, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [
                -20.1516,
                -19.6331,
                -19.2749,  ...,
                -19.1333,
                -20.6324,
                -19.9259
            ],
            [
                -19.0819,
                -19.8140,
                -20.2670,  ...,
                -19.8098,
                -19.0220,
                -20.4507
            ],
            [
                -20.6170,
                -19.8006,
                -20.2720,  ...,
                -20.4959,
                -19.3064,
                -20.1533
            ],
          ...,
            [
                -20.5215,
                -20.5116,
                -19.2242,  ...,
                -20.5627,
                -19.6782,
                -19.2545
            ],
            [
                -20.2949,
                -18.9732,
                -19.6699,  ...,
                -20.9297,
                -19.8555,
                -19.1649
            ],
            [
                -20.7399,
                -19.1194,
                -19.3425,  ...,
                -19.3221,
                -20.3322,
                -20.4154
            ]
        ],
        [
            [
                -20.0128,
                -19.0201,
                -20.1405,  ...,
                -19.0687,
                -19.0658,
                -19.1370
            ],
            [
                -20.1056,
                -19.7917,
                -19.0945,  ...,
                -19.7163,
                -20.2354,
                -19.5314
            ],
            [
                -20.1391,
                -19.2977,
                -19.7344,  ...,
                -19.3204,
                -20.9805,
                -19.4093
            ],
          ...,
            [
                -20.8783,
                -20.7130,
                -19.6121,  ...,
                -20.1998,
                -20.5134,
                -19.4467
            ],
            [
                -20.9958,
                -20.3894,
                -20.3040,  ...,
                -19.1613,
                -19.0829,
                -20.3062
            ],
            [
                -19.3058,
                -19.2296,
                -19.8130,  ...,
                -20.7822,
                -19.3265,
                -19.8442
            ]
        ],
        [
            [
                -19.1820,
                -20.4851,
                -20.2599,  ...,
                -20.0821,
                -20.2867,
                -19.8901
            ],
            [
                -20.5926,
                -19.4950,
                -20.6945,  ...,
                -20.9072,
                -19.8809,
                -19.7664
            ],
            [
                -20.7438,
                -20.4851,
                -20.3356,  ...,
                -18.9862,
                -20.3368,
                -20.6542
            ],
          ...,
            [
                -20.6653,
                -20.8009,
                -19.8611,  ...,
                -19.8574,
                -20.7626,
                -20.0762
            ],
            [
                -19.7117,
                -20.2797,
                -20.7478,  ...,
                -19.1209,
                -19.1601,
                -20.7393
            ],
            [
                -19.3580,
                -19.6850,
                -20.1050,  ...,
                -19.1481,
                -19.9702,
                -20.9195
            ]
        ]
    ],
    [
        [
            [
                -20.9526,
                -20.0355,
                -19.2116,  ...,
                -20.9663,
                -20.2340,
                -19.3266
            ],
            [
                -20.7531,
                -20.9918,
                -19.1175,  ...,
                -19.1382,
                -19.0674,
                -19.8430
            ],
            [
                -19.3523,
                -20.2532,
                -19.1869,  ...,
                -19.9880,
                -19.1945,
                -19.2874
            ],
          ...,
            [
                -19.8788,
                -20.8493,
                -19.6814,  ...,
                -19.0830,
                -20.1288,
                -19.4027
            ],
            [
                -19.3534,
                -20.6711,
                -19.3854,  ...,
                -19.2040,
                -19.0718,
                -18.9097
            ],
            [
                -19.2543,
                -19.0999,
                -19.6681,  ...,
                -19.8954,
                -20.4823,
                -20.5236
            ]
        ],
        [
            [
                -20.6230,
                -19.8069,
                -20.1681,  ...,
                -20.2414,
                -20.8153,
                -19.8016
            ],
            [
                -19.9724,
                -19.1302,
                -20.7888,  ...,
                -20.5470,
                -20.7612,
                -19.5840
            ],
            [
                -19.5766,
                -20.9441,
                -20.8867,  ...,
                -20.7676,
                -20.6522,
                -19.7925
            ],
          ...,
            [
                -20.1575,
                -20.8627,
                -19.0736,  ...,
                -19.9463,
                -20.4656,
                -19.2515
            ],
            [
                -19.8851,
                -18.9601,
                -20.6696,  ...,
                -19.7407,
                -20.7008,
                -20.6951
            ],
            [
                -20.5859,
                -20.2423,
                -20.2925,  ...,
                -19.4190,
                -20.2967,
                -19.9161
            ]
        ],
        [
            [
                -20.2710,
                -20.5088,
                -19.2138,  ...,
                -19.2651,
                -20.9929,
                -20.1101
            ],
            [
                -20.0775,
                -20.8565,
                -20.8182,  ...,
                -20.0840,
                -19.6283,
                -20.0859
            ],
            [
                -20.0018,
                -20.5942,
                -19.4544,  ...,
                -19.7634,
                -20.1398,
                -20.5234
            ],
          ...,
            [
                -19.1172,
                -19.0133,
                -20.4173,  ...,
                -20.6215,
                -19.8181,
                -20.3836
            ],
            [
                -20.5348,
                -19.6344,
                -20.9747,  ...,
                -19.6710,
                -20.7941,
                -20.9154
            ],
            [
                -19.9932,
                -20.5891,
                -20.4664,  ...,
                -19.9446,
                -19.5717,
                -19.9612
            ]
        ]
    ],
    [
        [
            [
                -19.9412,
                -19.2342,
                -21.0315,  ...,
                -19.6961,
                -18.9558,
                -20.9330
            ],
            [
                -20.8451,
                -20.0285,
                -19.3674,  ...,
                -19.4024,
                -19.2096,
                -20.7016
            ],
            [
                -19.8275,
                -19.5628,
                -20.6712,  ...,
                -20.4771,
                -19.0767,
                -19.9711
            ],
          ...,
            [
                -20.3755,
                -20.7107,
                -19.7152,  ...,
                -20.7691,
                -20.2403,
                -19.8186
            ],
            [
                -20.5924,
                -19.5448,
                -19.6926,  ...,
                -19.3025,
                -20.1377,
                -19.6718
            ],
            [
                -19.5707,
                -19.5690,
                -20.6330,  ...,
                -19.9085,
                -20.0797,
                -20.0106
            ]
        ],
        [
            [
                -20.5243,
                -19.2809,
                -19.2557,  ...,
                -19.3717,
                -20.8070,
                -19.3990
            ],
            [
                -19.6853,
                -20.2094,
                -19.0581,  ...,
                -20.8505,
                -19.2867,
                -19.6986
            ],
            [
                -20.5030,
                -19.9551,
                -19.1400,  ...,
                -20.4231,
                -20.1084,
                -20.2206
            ],
          ...,
            [
                -19.3276,
                -19.1641,
                -20.1233,  ...,
                -20.8113,
                -20.6713,
                -19.4568
            ],
            [
                -20.0540,
                -19.1687,
                -20.6172,  ...,
                -19.3586,
                -20.3946,
                -20.3714
            ],
            [
                -19.2688,
                -20.3877,
                -19.1753,  ...,
                -20.2505,
                -20.5299,
                -18.9993
            ]
        ],
        [
            [
                -20.9429,
                -19.5099,
                -19.4694,  ...,
                -19.8001,
                -19.4867,
                -19.1748
            ],
            [
                -20.3971,
                -20.7467,
                -20.6518,  ...,
                -19.1890,
                -20.9407,
                -19.8620
            ],
            [
                -20.8700,
                -19.4934,
                -19.2784,  ...,
                -19.7065,
                -20.7442,
                -20.7229
            ],
          ...,
            [
                -20.8386,
                -20.9825,
                -19.7041,  ...,
                -20.3103,
                -20.6208,
                -20.7456
            ],
            [
                -20.2441,
                -20.9119,
                -20.6384,  ...,
                -19.5014,
                -20.9765,
                -19.3152
            ],
            [
                -19.4704,
                -19.3563,
                -19.3195,  ...,
                -19.4631,
                -20.6487,
                -19.9467
            ]
        ]
    ],


        ...,
    [
        [
            [
                -20.8739,
                -19.2269,
                -19.9328,  ...,
                -20.8133,
                -18.9575,
                -19.0842
            ],
            [
                -20.7194,
                -19.4973,
                -19.5171,  ...,
                -19.5069,
                -19.5699,
                -19.0590
            ],
            [
                -19.2736,
                -19.4911,
                -21.0257,  ...,
                -20.7227,
                -19.3240,
                -20.7402
            ],
          ...,
            [
                -19.7423,
                -20.4953,
                -19.3142,  ...,
                -19.5207,
                -20.6078,
                -20.3172
            ],
            [
                -19.0370,
                -20.8009,
                -20.7117,  ...,
                -19.1119,
                -20.3011,
                -19.9205
            ],
            [
                -20.8441,
                -20.8250,
                -20.6912,  ...,
                -19.2404,
                -20.9300,
                -19.4827
            ]
        ],
        [
            [
                -19.3986,
                -19.9116,
                -19.8543,  ...,
                -19.9058,
                -20.8498,
                -19.9833
            ],
            [
                -19.6126,
                -19.4486,
                -20.4550,  ...,
                -20.1093,
                -19.8424,
                -19.2354
            ],
            [
                -20.5529,
                -18.9193,
                -20.1966,  ...,
                -19.0321,
                -20.0351,
                -19.9406
            ],
          ...,
            [
                -20.8539,
                -20.8702,
                -19.1810,  ...,
                -20.3714,
                -20.5900,
                -20.9993
            ],
            [
                -20.1623,
                -19.7722,
                -20.4683,  ...,
                -19.7426,
                -20.9482,
                -20.4305
            ],
            [
                -20.8532,
                -19.5113,
                -20.0744,  ...,
                -19.3625,
                -20.8216,
                -19.0432
            ]
        ],
        [
            [
                -20.9462,
                -20.6836,
                -20.0883,  ...,
                -19.4765,
                -19.2493,
                -19.0751
            ],
            [
                -20.3611,
                -20.3829,
                -20.0382,  ...,
                -19.2889,
                -19.4159,
                -20.8327
            ],
            [
                -20.0436,
                -20.5976,
                -20.6890,  ...,
                -19.2819,
                -20.1298,
                -20.6539
            ],
          ...,
            [
                -19.3329,
                -20.9553,
                -19.4168,  ...,
                -20.7988,
                -19.3981,
                -20.2587
            ],
            [
                -20.5787,
                -19.7185,
                -20.5415,  ...,
                -20.4825,
                -19.6462,
                -19.6780
            ],
            [
                -19.4481,
                -20.6551,
                -20.4363,  ...,
                -19.4030,
                -20.3959,
                -20.2549
            ]
        ]
    ],
    [
        [
            [
                -19.3359,
                -20.5394,
                -20.8821,  ...,
                -20.2289,
                -20.0598,
                -19.8427
            ],
            [
                -19.8328,
                -20.5036,
                -20.0254,  ...,
                -20.0562,
                -19.5910,
                -19.0896
            ],
            [
                -20.4256,
                -19.4866,
                -20.5966,  ...,
                -19.6489,
                -20.6814,
                -20.1112
            ],
          ...,
            [
                -20.4293,
                -19.7834,
                -20.5787,  ...,
                -20.9157,
                -19.1236,
                -20.0597
            ],
            [
                -20.4968,
                -19.1218,
                -19.7845,  ...,
                -20.6258,
                -19.0720,
                -19.4153
            ],
            [
                -19.7931,
                -19.7006,
                -19.2843,  ...,
                -19.6862,
                -19.8101,
                -20.0074
            ]
        ],
        [
            [
                -20.8328,
                -19.1666,
                -20.4254,  ...,
                -19.4823,
                -19.7341,
                -19.5443
            ],
            [
                -19.3925,
                -20.9671,
                -20.7709,  ...,
                -20.5577,
                -19.7709,
                -19.3989
            ],
            [
                -20.7863,
                -20.1524,
                -20.6050,  ...,
                -19.6292,
                -19.6378,
                -20.3503
            ],
          ...,
            [
                -19.3274,
                -20.4400,
                -19.4255,  ...,
                -20.5141,
                -20.9576,
                -20.8329
            ],
            [
                -19.3258,
                -20.5718,
                -20.5580,  ...,
                -19.6187,
                -20.5921,
                -20.3454
            ],
            [
                -18.9742,
                -20.5375,
                -19.7277,  ...,
                -19.8333,
                -20.4176,
                -20.2191
            ]
        ],
        [
            [
                -20.4261,
                -19.9005,
                -20.8369,  ...,
                -19.0906,
                -19.3243,
                -19.3015
            ],
            [
                -20.3346,
                -19.1218,
                -20.3409,  ...,
                -20.3761,
                -20.9393,
                -19.1945
            ],
            [
                -19.5472,
                -19.6818,
                -19.9071,  ...,
                -20.5995,
                -20.6570,
                -19.1521
            ],
          ...,
            [
                -20.2751,
                -19.1814,
                -19.9558,  ...,
                -20.3069,
                -19.8510,
                -19.8373
            ],
            [
                -20.6502,
                -19.0806,
                -20.7910,  ...,
                -19.1354,
                -20.5472,
                -20.5429
            ],
            [
                -19.3165,
                -19.4401,
                -20.2757,  ...,
                -19.1159,
                -20.5826,
                -20.3871
            ]
        ]
    ],
    [
        [
            [
                -20.1503,
                -19.4898,
                -20.8481,  ...,
                -19.4007,
                -20.5849,
                -19.9341
            ],
            [
                -20.3688,
                -20.4125,
                -20.1976,  ...,
                -19.7485,
                -20.2800,
                -19.7193
            ],
            [
                -20.8226,
                -20.5200,
                -20.1591,  ...,
                -19.7079,
                -20.2900,
                -20.3835
            ],
          ...,
            [
                -20.0594,
                -20.0905,
                -20.0735,  ...,
                -19.3926,
                -19.8525,
                -19.5153
            ],
            [
                -19.9089,
                -20.8408,
                -20.3142,  ...,
                -20.5334,
                -19.3789,
                -20.6172
            ],
            [
                -19.1511,
                -20.7499,
                -19.1142,  ...,
                -20.6843,
                -20.5616,
                -20.5751
            ]
        ],
        [
            [
                -20.9082,
                -19.7508,
                -20.9397,  ...,
                -20.8462,
                -20.8253,
                -20.8905
            ],
            [
                -20.0773,
                -20.9507,
                -20.3788,  ...,
                -19.6351,
                -19.0575,
                -20.9764
            ],
            [
                -20.7315,
                -20.9014,
                -19.7300,  ...,
                -20.4594,
                -19.9918,
                -19.4020
            ],
          ...,
            [
                -19.7927,
                -20.0677,
                -20.6108,  ...,
                -20.7567,
                -20.4570,
                -19.5231
            ],
            [
                -19.5344,
                -20.1087,
                -19.8677,  ...,
                -20.0186,
                -20.4343,
                -19.8548
            ],
            [
                -20.6481,
                -20.6703,
                -19.2945,  ...,
                -20.3099,
                -19.7312,
                -20.1663
            ]
        ],
        [
            [
                -20.5606,
                -20.6744,
                -20.7764,  ...,
                -19.9120,
                -20.9857,
                -19.3222
            ],
            [
                -19.3150,
                -20.8816,
                -19.9594,  ...,
                -19.6830,
                -20.5621,
                -19.8659
            ],
            [
                -19.8781,
                -20.2839,
                -19.3999,  ...,
                -20.4859,
                -19.3369,
                -20.0879
            ],
          ...,
            [
                -20.5662,
                -19.4339,
                -19.8312,  ...,
                -19.2389,
                -19.7598,
                -21.0712
            ],
            [
                -19.4732,
                -20.4579,
                -19.9418,  ...,
                -20.8344,
                -21.0535,
                -19.4537
            ],
            [
                -20.2413,
                -20.8355,
                -19.2483,  ...,
                -19.9395,
                -20.1654,
                -20.1663
            ]
        ]
    ]
],
       device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1092,
        -0.1021,
        0.0705
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1092,
        -0.1021,
        0.0705
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1092,
        -0.1021,
        0.0705
    ],
        ...,
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1092,
        -0.1021,
        0.0705
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1092,
        -0.1021,
        0.0705
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1092,
        -0.1021,
        0.0705
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
tensor([
    [
        -0.2671,
        0.1826,
        -0.1000,  ...,
        0.1967,
        -0.2507,
        0.3218
    ],
    [
        -0.2096,
        0.2624,
        -0.1083,  ...,
        0.1796,
        -0.2079,
        0.3352
    ],
    [
        -0.1899,
        0.2091,
        -0.1484,  ...,
        0.1777,
        -0.2350,
        0.2852
    ],
        ...,
    [
        -0.2345,
        0.2261,
        -0.1150,  ...,
        0.1911,
        -0.2094,
        0.3438
    ],
    [
        -0.3268,
        0.1778,
        -0.1177,  ...,
        0.2144,
        -0.2623,
        0.2660
    ],
    [
        -0.2842,
        0.2337,
        -0.0897,  ...,
        0.1340,
        -0.2949,
        0.2669
    ]
],
       device='cuda: 0', grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.0515,
        -0.0744,
        0.0958
    ],
    [
        0.0814,
        -0.0705,
        0.1281,  ...,
        0.0515,
        -0.0744,
        0.0958
    ],
    [
        0.0814,
        -0.0705,
        0.1281,  ...,
        0.0515,
        -0.0744,
        0.0958
    ],
        ...,
    [
        0.0814,
        -0.0705,
        0.1281,  ...,
        0.0515,
        -0.0744,
        0.0958
    ],
    [
        0.0814,
        -0.0705,
        0.1281,  ...,
        0.0515,
        -0.0744,
        0.0958
    ],
    [
        0.0814,
        -0.0705,
        0.1281,  ...,
        0.0515,
        -0.0744,
        0.0958
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(0.4579, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(-0.0040, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 1/3125 [
    00: 19<16: 59: 03,
    19.57s/it, loss=0.462, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [
        -0.0509,
        0.0102,
        0.0328,  ...,
        -0.0259,
        -0.0397,
        0.0132
    ],
    [
        -0.0520,
        0.0110,
        0.0348,  ...,
        -0.0269,
        -0.0400,
        0.0141
    ],
    [
        -0.1617,
        0.2339,
        -0.0920,  ...,
        -0.1202,
        -0.2496,
        -0.0147
    ],
        ...,
    [
        -0.0486,
        0.0091,
        0.0334,  ...,
        -0.0240,
        -0.0410,
        0.0158
    ],
    [
        -0.0505,
        0.0117,
        0.0340,  ...,
        -0.0244,
        -0.0391,
        0.0191
    ],
    [
        -0.0484,
        0.0100,
        0.0331,  ...,
        -0.0246,
        -0.0399,
        0.0125
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2091,
        0.1941,
        -0.3250
    ],
    [
        0.3466,
        -0.2674,
        0.1004,  ...,
        -0.2091,
        0.1941,
        -0.3250
    ],
    [
        0.3466,
        -0.2674,
        0.1004,  ...,
        -0.2091,
        0.1941,
        -0.3250
    ],
        ...,
    [
        0.3466,
        -0.2674,
        0.1004,  ...,
        -0.2091,
        0.1941,
        -0.3250
    ],
    [
        0.3466,
        -0.2674,
        0.1004,  ...,
        -0.2091,
        0.1941,
        -0.3250
    ],
    [
        0.3466,
        -0.2674,
        0.1004,  ...,
        -0.2091,
        0.1941,
        -0.3250
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -204.3736,
    -201.8614,
    -211.4657,
    -210.0861,
    -204.2577,
    -207.9771,
    -210.0302,
    -207.7915,
    -206.5662,
    -208.1539,
    -202.0175,
    -199.9359,
    -210.2584,
    -201.8063,
    -200.2105,
    -202.7697
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -204.3736,
    -201.8614,
    -211.4657,
    -210.0861,
    -204.2577,
    -207.9771,
    -210.0302,
    -207.7915,
    -206.5662,
    -208.1539,
    -202.0175,
    -199.9359,
    -210.2584,
    -201.8063,
    -200.2105,
    -202.7697
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7173, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0655,
        0.0117,
        0.0377,  ...,
        -0.0239,
        -0.0357,
        0.0217
    ],
    [
        -0.0657,
        0.0127,
        0.0386,  ...,
        -0.0247,
        -0.0366,
        0.0214
    ],
    [
        -0.1700,
        0.2479,
        -0.0965,  ...,
        -0.1229,
        -0.2647,
        -0.0143
    ],
        ...,
    [
        -0.0629,
        0.0116,
        0.0367,  ...,
        -0.0225,
        -0.0375,
        0.0214
    ],
    [
        -0.0648,
        0.0138,
        0.0367,  ...,
        -0.0237,
        -0.0356,
        0.0233
    ],
    [
        -0.0643,
        0.0118,
        0.0378,  ...,
        -0.0226,
        -0.0355,
        0.0211
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0509,
            0.0102,
            0.0328,  ...,
            -0.0259,
            -0.0397,
            0.0132
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0520,
            0.0110,
            0.0348,  ...,
            -0.0269,
            -0.0400,
            0.0141
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1617,
            0.2339,
            -0.0920,  ...,
            -0.1202,
            -0.2496,
            -0.0147
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2071,
        0.1985,
        -0.3164
    ],
    [
        0.3320,
        -0.2659,
        0.1054,  ...,
        -0.2071,
        0.1985,
        -0.3164
    ],
    [
        0.3320,
        -0.2659,
        0.1054,  ...,
        -0.2071,
        0.1985,
        -0.3164
    ],
        ...,
    [
        0.3320,
        -0.2659,
        0.1054,  ...,
        -0.2071,
        0.1985,
        -0.3164
    ],
    [
        0.3320,
        -0.2659,
        0.1054,  ...,
        -0.2071,
        0.1985,
        -0.3164
    ],
    [
        0.3320,
        -0.2659,
        0.1054,  ...,
        -0.2071,
        0.1985,
        -0.3164
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -202.6667,
    -200.1681,
    -209.7100,
    -208.3250,
    -202.5222,
    -206.2332,
    -208.2861,
    -206.0496,
    -204.8285,
    -206.3996,
    -200.3283,
    -198.2271,
    -208.5800,
    -200.0792,
    -198.4883,
    -201.0844
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -202.6667,
    -200.1681,
    -209.7100,
    -208.3250,
    -202.5222,
    -206.2332,
    -208.2861,
    -206.0496,
    -204.8285,
    -206.3996,
    -200.3283,
    -198.2271,
    -208.5800,
    -200.0791,
    -198.4883,
    -201.0844
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7346, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0660,
        0.0157,
        0.0362,  ...,
        -0.0211,
        -0.0346,
        0.0226
    ],
    [
        -0.0657,
        0.0161,
        0.0353,  ...,
        -0.0216,
        -0.0335,
        0.0221
    ],
    [
        -0.1784,
        0.2621,
        -0.1011,  ...,
        -0.1254,
        -0.2800,
        -0.0139
    ],
        ...,
    [
        -0.0653,
        0.0151,
        0.0354,  ...,
        -0.0212,
        -0.0338,
        0.0228
    ],
    [
        -0.0660,
        0.0141,
        0.0358,  ...,
        -0.0207,
        -0.0346,
        0.0228
    ],
    [
        -0.0657,
        0.0151,
        0.0349,  ...,
        -0.0204,
        -0.0325,
        0.0217
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0655,
            0.0117,
            0.0377,  ...,
            -0.0239,
            -0.0357,
            0.0217
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0657,
            0.0127,
            0.0386,  ...,
            -0.0247,
            -0.0366,
            0.0214
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1700,
            0.2479,
            -0.0965,  ...,
            -0.1229,
            -0.2647,
            -0.0143
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2049,
        0.2014,
        -0.3158
    ],
    [
        0.3316,
        -0.2619,
        0.1039,  ...,
        -0.2049,
        0.2014,
        -0.3158
    ],
    [
        0.3316,
        -0.2619,
        0.1039,  ...,
        -0.2049,
        0.2014,
        -0.3158
    ],
        ...,
    [
        0.3316,
        -0.2619,
        0.1039,  ...,
        -0.2049,
        0.2014,
        -0.3158
    ],
    [
        0.3316,
        -0.2619,
        0.1039,  ...,
        -0.2049,
        0.2014,
        -0.3158
    ],
    [
        0.3316,
        -0.2619,
        0.1039,  ...,
        -0.2049,
        0.2014,
        -0.3158
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -201.8210,
    -199.3112,
    -208.8371,
    -207.4564,
    -201.6794,
    -205.3876,
    -207.4165,
    -205.1852,
    -203.9734,
    -205.5284,
    -199.4791,
    -197.3678,
    -207.7852,
    -199.2261,
    -197.6312,
    -200.2190
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -201.8210,
    -199.3112,
    -208.8371,
    -207.4563,
    -201.6794,
    -205.3876,
    -207.4165,
    -205.1852,
    -203.9734,
    -205.5284,
    -199.4791,
    -197.3678,
    -207.7852,
    -199.2261,
    -197.6312,
    -200.2190
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7431, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0663,
        0.0128,
        0.0321,  ...,
        -0.0235,
        -0.0339,
        0.0198
    ],
    [
        -0.0669,
        0.0125,
        0.0322,  ...,
        -0.0241,
        -0.0347,
        0.0203
    ],
    [
        -0.1868,
        0.2761,
        -0.1055,  ...,
        -0.1278,
        -0.2951,
        -0.0136
    ],
        ...,
    [
        -0.0655,
        0.0130,
        0.0327,  ...,
        -0.0230,
        -0.0354,
        0.0212
    ],
    [
        -0.0653,
        0.0129,
        0.0337,  ...,
        -0.0244,
        -0.0352,
        0.0205
    ],
    [
        -0.0658,
        0.0135,
        0.0320,  ...,
        -0.0238,
        -0.0323,
        0.0196
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0660,
            0.0157,
            0.0362,  ...,
            -0.0211,
            -0.0346,
            0.0226
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0657,
            0.0161,
            0.0353,  ...,
            -0.0216,
            -0.0335,
            0.0221
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1784,
            0.2621,
            -0.1011,  ...,
            -0.1254,
            -0.2800,
            -0.0139
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2083,
        0.2017,
        -0.3179
    ],
    [
        0.3312,
        -0.2648,
        0.0997,  ...,
        -0.2083,
        0.2017,
        -0.3179
    ],
    [
        0.3312,
        -0.2648,
        0.0997,  ...,
        -0.2083,
        0.2017,
        -0.3179
    ],
        ...,
    [
        0.3312,
        -0.2648,
        0.0997,  ...,
        -0.2083,
        0.2017,
        -0.3179
    ],
    [
        0.3312,
        -0.2648,
        0.0997,  ...,
        -0.2083,
        0.2017,
        -0.3179
    ],
    [
        0.3312,
        -0.2648,
        0.0997,  ...,
        -0.2083,
        0.2017,
        -0.3179
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -202.4670,
    -199.9564,
    -209.5042,
    -208.1189,
    -202.3293,
    -206.0322,
    -208.0647,
    -205.8361,
    -204.6135,
    -206.1678,
    -200.1247,
    -198.0153,
    -208.5313,
    -199.8760,
    -198.2915,
    -200.8533
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -202.4670,
    -199.9564,
    -209.5042,
    -208.1189,
    -202.3293,
    -206.0322,
    -208.0647,
    -205.8361,
    -204.6136,
    -206.1678,
    -200.1247,
    -198.0153,
    -208.5313,
    -199.8761,
    -198.2915,
    -200.8533
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7366, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0607,
        0.0173,
        0.0252,  ...,
        -0.0293,
        -0.0311,
        0.0140
    ],
    [
        -0.0618,
        0.0156,
        0.0237,  ...,
        -0.0301,
        -0.0329,
        0.0154
    ],
    [
        -0.1953,
        0.2903,
        -0.1100,  ...,
        -0.1300,
        -0.3103,
        -0.0131
    ],
        ...,
    [
        -0.0632,
        0.0158,
        0.0255,  ...,
        -0.0295,
        -0.0331,
        0.0165
    ],
    [
        -0.0620,
        0.0161,
        0.0243,  ...,
        -0.0305,
        -0.0320,
        0.0162
    ],
    [
        -0.0622,
        0.0173,
        0.0234,  ...,
        -0.0309,
        -0.0308,
        0.0141
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0663,
            0.0128,
            0.0321,  ...,
            -0.0235,
            -0.0339,
            0.0198
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0669,
            0.0125,
            0.0322,  ...,
            -0.0241,
            -0.0347,
            0.0203
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1868,
            0.2761,
            -0.1055,  ...,
            -0.1278,
            -0.2951,
            -0.0136
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2154,
        0.2031,
        -0.3234
    ],
    [
        0.3368,
        -0.2603,
        0.0929,  ...,
        -0.2154,
        0.2031,
        -0.3234
    ],
    [
        0.3368,
        -0.2603,
        0.0929,  ...,
        -0.2154,
        0.2031,
        -0.3234
    ],
        ...,
    [
        0.3368,
        -0.2603,
        0.0929,  ...,
        -0.2154,
        0.2031,
        -0.3234
    ],
    [
        0.3368,
        -0.2603,
        0.0929,  ...,
        -0.2154,
        0.2031,
        -0.3234
    ],
    [
        0.3368,
        -0.2603,
        0.0929,  ...,
        -0.2154,
        0.2031,
        -0.3234
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -203.9195,
    -201.4281,
    -210.9967,
    -209.6004,
    -203.7838,
    -207.5126,
    -209.5490,
    -207.3150,
    -206.0813,
    -207.6426,
    -201.5899,
    -199.4586,
    -210.1016,
    -201.3288,
    -199.7498,
    -202.3298
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -203.9195,
    -201.4281,
    -210.9967,
    -209.6004,
    -203.7838,
    -207.5126,
    -209.5490,
    -207.3150,
    -206.0813,
    -207.6426,
    -201.5899,
    -199.4586,
    -210.1015,
    -201.3288,
    -199.7498,
    -202.3298
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7218, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0567,
        0.0237,
        0.0128,  ...,
        -0.0340,
        -0.0346,
        0.0024
    ],
    [
        -0.0587,
        0.0213,
        0.0130,  ...,
        -0.0352,
        -0.0349,
        0.0051
    ],
    [
        -0.2037,
        0.3045,
        -0.1143,  ...,
        -0.1325,
        -0.3255,
        -0.0127
    ],
        ...,
    [
        -0.0598,
        0.0216,
        0.0135,  ...,
        -0.0334,
        -0.0356,
        0.0057
    ],
    [
        -0.0585,
        0.0224,
        0.0125,  ...,
        -0.0359,
        -0.0352,
        0.0047
    ],
    [
        -0.0576,
        0.0239,
        0.0115,  ...,
        -0.0351,
        -0.0357,
        0.0020
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0607,
            0.0173,
            0.0252,  ...,
            -0.0293,
            -0.0311,
            0.0140
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0618,
            0.0156,
            0.0237,  ...,
            -0.0301,
            -0.0329,
            0.0154
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1953,
            0.2903,
            -0.1100,  ...,
            -0.1300,
            -0.3103,
            -0.0131
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2196,
        0.1983,
        -0.3356
    ],
    [
        0.3408,
        -0.2539,
        0.0804,  ...,
        -0.2196,
        0.1983,
        -0.3356
    ],
    [
        0.3408,
        -0.2539,
        0.0804,  ...,
        -0.2196,
        0.1983,
        -0.3356
    ],
        ...,
    [
        0.3408,
        -0.2539,
        0.0804,  ...,
        -0.2196,
        0.1983,
        -0.3356
    ],
    [
        0.3408,
        -0.2539,
        0.0804,  ...,
        -0.2196,
        0.1983,
        -0.3356
    ],
    [
        0.3408,
        -0.2539,
        0.0804,  ...,
        -0.2196,
        0.1983,
        -0.3356
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -203.2807,
    -200.7911,
    -210.2489,
    -208.9427,
    -203.1210,
    -206.8703,
    -208.8839,
    -206.6616,
    -205.4311,
    -206.9958,
    -200.9565,
    -198.8373,
    -209.4332,
    -200.6863,
    -199.1252,
    -201.7080
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -203.2807,
    -200.7911,
    -210.2489,
    -208.9427,
    -203.1210,
    -206.8703,
    -208.8839,
    -206.6616,
    -205.4311,
    -206.9958,
    -200.9565,
    -198.8373,
    -209.4332,
    -200.6863,
    -199.1252,
    -201.7080
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7283, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0601,
        0.0349,
        -0.0060,  ...,
        -0.0419,
        -0.0389,
        -0.0079
    ],
    [
        -0.0617,
        0.0317,
        -0.0051,  ...,
        -0.0429,
        -0.0395,
        -0.0055
    ],
    [
        -0.2124,
        0.3187,
        -0.1186,  ...,
        -0.1348,
        -0.3409,
        -0.0120
    ],
        ...,
    [
        -0.0623,
        0.0326,
        -0.0056,  ...,
        -0.0410,
        -0.0406,
        -0.0058
    ],
    [
        -0.0616,
        0.0323,
        -0.0052,  ...,
        -0.0414,
        -0.0393,
        -0.0067
    ],
    [
        -0.0607,
        0.0348,
        -0.0063,  ...,
        -0.0438,
        -0.0412,
        -0.0079
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0567,
            0.0237,
            0.0128,  ...,
            -0.0340,
            -0.0346,
            0.0024
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0587,
            0.0213,
            0.0130,  ...,
            -0.0352,
            -0.0349,
            0.0051
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2037,
            0.3045,
            -0.1143,  ...,
            -0.1325,
            -0.3255,
            -0.0127
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2284,
        0.1928,
        -0.3454
    ],
    [
        0.3375,
        -0.2427,
        0.0616,  ...,
        -0.2284,
        0.1928,
        -0.3454
    ],
    [
        0.3375,
        -0.2427,
        0.0616,  ...,
        -0.2284,
        0.1928,
        -0.3454
    ],
        ...,
    [
        0.3375,
        -0.2427,
        0.0616,  ...,
        -0.2284,
        0.1928,
        -0.3454
    ],
    [
        0.3375,
        -0.2427,
        0.0616,  ...,
        -0.2284,
        0.1928,
        -0.3454
    ],
    [
        0.3375,
        -0.2427,
        0.0616,  ...,
        -0.2284,
        0.1928,
        -0.3454
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -200.3676,
    -197.8986,
    -207.0854,
    -205.9733,
    -200.2047,
    -203.9244,
    -205.9011,
    -203.6950,
    -202.5021,
    -204.0496,
    -198.0727,
    -195.9587,
    -206.3486,
    -197.7901,
    -196.2585,
    -198.8082
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -200.3676,
    -197.8986,
    -207.0854,
    -205.9733,
    -200.2047,
    -203.9244,
    -205.9011,
    -203.6950,
    -202.5021,
    -204.0496,
    -198.0727,
    -195.9587,
    -206.3486,
    -197.7901,
    -196.2585,
    -198.8082
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.7577, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0644,
        0.0472,
        -0.0185,  ...,
        -0.0535,
        -0.0474,
        -0.0137
    ],
    [
        -0.0659,
        0.0444,
        -0.0180,  ...,
        -0.0543,
        -0.0476,
        -0.0109
    ],
    [
        -0.2207,
        0.3329,
        -0.1232,  ...,
        -0.1370,
        -0.3561,
        -0.0115
    ],
        ...,
    [
        -0.0649,
        0.0451,
        -0.0186,  ...,
        -0.0521,
        -0.0486,
        -0.0121
    ],
    [
        -0.0650,
        0.0453,
        -0.0184,  ...,
        -0.0523,
        -0.0467,
        -0.0123
    ],
    [
        -0.0657,
        0.0473,
        -0.0190,  ...,
        -0.0545,
        -0.0497,
        -0.0133
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0601,
            0.0349,
            -0.0060,  ...,
            -0.0419,
            -0.0389,
            -0.0079
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0617,
            0.0317,
            -0.0051,  ...,
            -0.0429,
            -0.0395,
            -0.0055
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2124,
            0.3187,
            -0.1186,  ...,
            -0.1348,
            -0.3409,
            -0.0120
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2391,
        0.1843,
        -0.3509
    ],
    [
        0.3331,
        -0.2304,
        0.0491,  ...,
        -0.2391,
        0.1843,
        -0.3509
    ],
    [
        0.3331,
        -0.2304,
        0.0491,  ...,
        -0.2391,
        0.1843,
        -0.3509
    ],
        ...,
    [
        0.3331,
        -0.2304,
        0.0491,  ...,
        -0.2391,
        0.1843,
        -0.3509
    ],
    [
        0.3331,
        -0.2304,
        0.0491,  ...,
        -0.2391,
        0.1843,
        -0.3509
    ],
    [
        0.3331,
        -0.2304,
        0.0491,  ...,
        -0.2391,
        0.1843,
        -0.3509
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -195.6434,
    -193.1992,
    -201.9847,
    -201.1411,
    -195.4652,
    -199.1393,
    -201.0556,
    -198.8982,
    -197.7251,
    -199.2499,
    -193.3796,
    -191.2819,
    -201.3265,
    -193.0786,
    -191.5944,
    -194.0990
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -195.6434,
    -193.1991,
    -201.9847,
    -201.1411,
    -195.4652,
    -199.1394,
    -201.0556,
    -198.8981,
    -197.7251,
    -199.2499,
    -193.3796,
    -191.2818,
    -201.3265,
    -193.0786,
    -191.5944,
    -194.0990
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.8056, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0680,
        0.0605,
        -0.0281,  ...,
        -0.0638,
        -0.0602,
        -0.0142
    ],
    [
        -0.0700,
        0.0586,
        -0.0276,  ...,
        -0.0640,
        -0.0601,
        -0.0114
    ],
    [
        -0.2294,
        0.3473,
        -0.1275,  ...,
        -0.1393,
        -0.3714,
        -0.0107
    ],
        ...,
    [
        -0.0688,
        0.0582,
        -0.0268,  ...,
        -0.0620,
        -0.0618,
        -0.0130
    ],
    [
        -0.0683,
        0.0595,
        -0.0278,  ...,
        -0.0637,
        -0.0602,
        -0.0129
    ],
    [
        -0.0706,
        0.0603,
        -0.0275,  ...,
        -0.0639,
        -0.0637,
        -0.0140
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0644,
            0.0472,
            -0.0185,  ...,
            -0.0535,
            -0.0474,
            -0.0137
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0659,
            0.0444,
            -0.0180,  ...,
            -0.0543,
            -0.0476,
            -0.0109
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2207,
            0.3329,
            -0.1232,  ...,
            -0.1370,
            -0.3561,
            -0.0115
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2485,
        0.1703,
        -0.3516
    ],
    [
        0.3296,
        -0.2171,
        0.0396,  ...,
        -0.2485,
        0.1703,
        -0.3516
    ],
    [
        0.3296,
        -0.2171,
        0.0396,  ...,
        -0.2485,
        0.1703,
        -0.3516
    ],
        ...,
    [
        0.3296,
        -0.2171,
        0.0396,  ...,
        -0.2485,
        0.1703,
        -0.3516
    ],
    [
        0.3296,
        -0.2171,
        0.0396,  ...,
        -0.2485,
        0.1703,
        -0.3516
    ],
    [
        0.3296,
        -0.2171,
        0.0396,  ...,
        -0.2485,
        0.1703,
        -0.3516
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -189.6366,
    -187.2309,
    -195.5079,
    -194.9994,
    -189.4533,
    -193.0516,
    -194.9023,
    -192.8060,
    -191.6532,
    -193.1511,
    -187.4139,
    -185.3516,
    -194.9283,
    -187.1004,
    -185.6659,
    -188.1187
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -189.6366,
    -187.2309,
    -195.5079,
    -194.9993,
    -189.4533,
    -193.0516,
    -194.9023,
    -192.8060,
    -191.6532,
    -193.1511,
    -187.4139,
    -185.3516,
    -194.9283,
    -187.1004,
    -185.6659,
    -188.1187
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.8663, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0739,
        0.0736,
        -0.0350,  ...,
        -0.0719,
        -0.0757,
        -0.0172
    ],
    [
        -0.0748,
        0.0716,
        -0.0349,  ...,
        -0.0725,
        -0.0762,
        -0.0143
    ],
    [
        -0.2379,
        0.3615,
        -0.1318,  ...,
        -0.1412,
        -0.3865,
        -0.0100
    ],
        ...,
    [
        -0.0731,
        0.0710,
        -0.0343,  ...,
        -0.0713,
        -0.0773,
        -0.0158
    ],
    [
        -0.0735,
        0.0729,
        -0.0350,  ...,
        -0.0732,
        -0.0756,
        -0.0164
    ],
    [
        -0.0761,
        0.0735,
        -0.0350,  ...,
        -0.0724,
        -0.0794,
        -0.0167
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0680,
            0.0605,
            -0.0281,  ...,
            -0.0638,
            -0.0602,
            -0.0142
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0700,
            0.0586,
            -0.0276,  ...,
            -0.0640,
            -0.0601,
            -0.0114
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2294,
            0.3473,
            -0.1275,  ...,
            -0.1393,
            -0.3714,
            -0.0107
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2569,
        0.1545,
        -0.3543
    ],
    [
        0.3236,
        -0.2040,
        0.0327,  ...,
        -0.2569,
        0.1545,
        -0.3543
    ],
    [
        0.3236,
        -0.2040,
        0.0327,  ...,
        -0.2569,
        0.1545,
        -0.3543
    ],
        ...,
    [
        0.3236,
        -0.2040,
        0.0327,  ...,
        -0.2569,
        0.1545,
        -0.3543
    ],
    [
        0.3236,
        -0.2040,
        0.0327,  ...,
        -0.2569,
        0.1545,
        -0.3543
    ],
    [
        0.3236,
        -0.2040,
        0.0327,  ...,
        -0.2569,
        0.1545,
        -0.3543
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -182.9304,
    -180.5706,
    -188.2495,
    -188.1212,
    -182.7385,
    -186.2391,
    -188.0224,
    -185.9897,
    -184.8672,
    -186.3329,
    -180.7554,
    -178.7313,
    -187.7487,
    -180.4144,
    -179.0419,
    -181.4361
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -182.9304,
    -180.5706,
    -188.2495,
    -188.1212,
    -182.7385,
    -186.2391,
    -188.0224,
    -185.9897,
    -184.8672,
    -186.3329,
    -180.7554,
    -178.7313,
    -187.7487,
    -180.4144,
    -179.0419,
    -181.4361
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.9343, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0806,
        0.0879,
        -0.0428,  ...,
        -0.0796,
        -0.0923,
        -0.0204
    ],
    [
        -0.0809,
        0.0853,
        -0.0427,  ...,
        -0.0806,
        -0.0930,
        -0.0178
    ],
    [
        -0.2466,
        0.3759,
        -0.1361,  ...,
        -0.1434,
        -0.4018,
        -0.0095
    ],
        ...,
    [
        -0.0789,
        0.0845,
        -0.0421,  ...,
        -0.0801,
        -0.0933,
        -0.0188
    ],
    [
        -0.0797,
        0.0862,
        -0.0427,  ...,
        -0.0816,
        -0.0916,
        -0.0200
    ],
    [
        -0.0824,
        0.0873,
        -0.0429,  ...,
        -0.0804,
        -0.0957,
        -0.0196
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0739,
            0.0736,
            -0.0350,  ...,
            -0.0719,
            -0.0757,
            -0.0172
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0748,
            0.0716,
            -0.0349,  ...,
            -0.0725,
            -0.0762,
            -0.0143
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2379,
            0.3615,
            -0.1318,  ...,
            -0.1412,
            -0.3865,
            -0.0100
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2649,
        0.1382,
        -0.3572
    ],
    [
        0.3170,
        -0.1897,
        0.0248,  ...,
        -0.2649,
        0.1382,
        -0.3572
    ],
    [
        0.3170,
        -0.1897,
        0.0248,  ...,
        -0.2649,
        0.1382,
        -0.3572
    ],
        ...,
    [
        0.3170,
        -0.1897,
        0.0248,  ...,
        -0.2649,
        0.1382,
        -0.3572
    ],
    [
        0.3170,
        -0.1897,
        0.0248,  ...,
        -0.2649,
        0.1382,
        -0.3572
    ],
    [
        0.3170,
        -0.1897,
        0.0248,  ...,
        -0.2649,
        0.1382,
        -0.3572
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -176.0718,
    -173.7609,
    -180.7970,
    -181.0792,
    -175.8741,
    -179.2711,
    -180.9812,
    -179.0147,
    -177.9310,
    -179.3580,
    -173.9416,
    -171.9652,
    -180.3748,
    -173.5858,
    -172.2697,
    -174.6021
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -176.0718,
    -173.7609,
    -180.7970,
    -181.0792,
    -175.8741,
    -179.2711,
    -180.9812,
    -179.0147,
    -177.9310,
    -179.3580,
    -173.9415,
    -171.9653,
    -180.3748,
    -173.5858,
    -172.2697,
    -174.6022
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.0038, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0878,
        0.1027,
        -0.0485,  ...,
        -0.0875,
        -0.1093,
        -0.0230
    ],
    [
        -0.0877,
        0.1002,
        -0.0483,  ...,
        -0.0884,
        -0.1094,
        -0.0205
    ],
    [
        -0.2550,
        0.3903,
        -0.1405,  ...,
        -0.1456,
        -0.4169,
        -0.0086
    ],
        ...,
    [
        -0.0862,
        0.0995,
        -0.0478,  ...,
        -0.0883,
        -0.1097,
        -0.0209
    ],
    [
        -0.0870,
        0.1007,
        -0.0479,  ...,
        -0.0897,
        -0.1081,
        -0.0227
    ],
    [
        -0.0895,
        0.1024,
        -0.0485,  ...,
        -0.0880,
        -0.1121,
        -0.0217
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0806,
            0.0879,
            -0.0428,  ...,
            -0.0796,
            -0.0923,
            -0.0204
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0809,
            0.0853,
            -0.0427,  ...,
            -0.0806,
            -0.0930,
            -0.0178
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2466,
            0.3759,
            -0.1361,  ...,
            -0.1434,
            -0.4018,
            -0.0095
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2725,
        0.1218,
        -0.3592
    ],
    [
        0.3098,
        -0.1749,
        0.0191,  ...,
        -0.2725,
        0.1218,
        -0.3592
    ],
    [
        0.3098,
        -0.1749,
        0.0191,  ...,
        -0.2725,
        0.1218,
        -0.3592
    ],
        ...,
    [
        0.3098,
        -0.1749,
        0.0191,  ...,
        -0.2725,
        0.1218,
        -0.3592
    ],
    [
        0.3098,
        -0.1749,
        0.0191,  ...,
        -0.2725,
        0.1218,
        -0.3592
    ],
    [
        0.3098,
        -0.1749,
        0.0191,  ...,
        -0.2725,
        0.1218,
        -0.3592
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -169.6155,
    -167.3551,
    -173.7297,
    -174.4331,
    -169.4086,
    -172.7067,
    -174.3397,
    -172.4411,
    -171.3934,
    -172.7852,
    -167.5360,
    -165.6085,
    -173.3875,
    -167.1683,
    -165.9109,
    -168.1733
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -169.6155,
    -167.3551,
    -173.7297,
    -174.4331,
    -169.4086,
    -172.7067,
    -174.3397,
    -172.4411,
    -171.3935,
    -172.7852,
    -167.5360,
    -165.6085,
    -173.3874,
    -167.1683,
    -165.9109,
    -168.1733
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.0693, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0958,
        0.1186,
        -0.0534,  ...,
        -0.0929,
        -0.1255,
        -0.0236
    ],
    [
        -0.0963,
        0.1160,
        -0.0538,  ...,
        -0.0939,
        -0.1250,
        -0.0209
    ],
    [
        -0.2634,
        0.4047,
        -0.1448,  ...,
        -0.1481,
        -0.4320,
        -0.0079
    ],
        ...,
    [
        -0.0949,
        0.1154,
        -0.0528,  ...,
        -0.0944,
        -0.1251,
        -0.0213
    ],
    [
        -0.0953,
        0.1162,
        -0.0532,  ...,
        -0.0954,
        -0.1235,
        -0.0231
    ],
    [
        -0.0976,
        0.1180,
        -0.0537,  ...,
        -0.0934,
        -0.1277,
        -0.0218
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0878,
            0.1027,
            -0.0485,  ...,
            -0.0875,
            -0.1093,
            -0.0230
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0877,
            0.1002,
            -0.0483,  ...,
            -0.0884,
            -0.1094,
            -0.0205
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2550,
            0.3903,
            -0.1405,  ...,
            -0.1456,
            -0.4169,
            -0.0086
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2779,
        0.1063,
        -0.3593
    ],
    [
        0.3017,
        -0.1590,
        0.0142,  ...,
        -0.2779,
        0.1063,
        -0.3593
    ],
    [
        0.3017,
        -0.1590,
        0.0142,  ...,
        -0.2779,
        0.1063,
        -0.3593
    ],
        ...,
    [
        0.3017,
        -0.1590,
        0.0142,  ...,
        -0.2779,
        0.1063,
        -0.3593
    ],
    [
        0.3017,
        -0.1590,
        0.0142,  ...,
        -0.2779,
        0.1063,
        -0.3593
    ],
    [
        0.3017,
        -0.1590,
        0.0142,  ...,
        -0.2779,
        0.1063,
        -0.3593
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -163.4532,
    -161.2424,
    -166.9320,
    -168.0735,
    -163.2350,
    -166.4282,
    -167.9803,
    -166.1558,
    -165.1443,
    -166.4963,
    -161.4244,
    -159.5445,
    -166.6679,
    -161.0453,
    -159.8472,
    -162.0375
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -163.4532,
    -161.2424,
    -166.9320,
    -168.0735,
    -163.2350,
    -166.4282,
    -167.9803,
    -166.1558,
    -165.1443,
    -166.4963,
    -161.4244,
    -159.5445,
    -166.6679,
    -161.0453,
    -159.8472,
    -162.0375
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.1319, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1045,
        0.1337,
        -0.0584,  ...,
        -0.0974,
        -0.1405,
        -0.0229
    ],
    [
        -0.1050,
        0.1310,
        -0.0588,  ...,
        -0.0980,
        -0.1401,
        -0.0205
    ],
    [
        -0.2720,
        0.4189,
        -0.1492,  ...,
        -0.1504,
        -0.4471,
        -0.0071
    ],
        ...,
    [
        -0.1037,
        0.1307,
        -0.0578,  ...,
        -0.0987,
        -0.1401,
        -0.0205
    ],
    [
        -0.1039,
        0.1317,
        -0.0585,  ...,
        -0.1000,
        -0.1386,
        -0.0224
    ],
    [
        -0.1061,
        0.1330,
        -0.0591,  ...,
        -0.0979,
        -0.1427,
        -0.0209
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0958,
            0.1186,
            -0.0534,  ...,
            -0.0929,
            -0.1255,
            -0.0236
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.0963,
            0.1160,
            -0.0538,  ...,
            -0.0939,
            -0.1250,
            -0.0209
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2634,
            0.4047,
            -0.1448,  ...,
            -0.1481,
            -0.4320,
            -0.0079
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2825,
        0.0913,
        -0.3584
    ],
    [
        0.2930,
        -0.1439,
        0.0093,  ...,
        -0.2825,
        0.0913,
        -0.3584
    ],
    [
        0.2930,
        -0.1439,
        0.0093,  ...,
        -0.2825,
        0.0913,
        -0.3584
    ],
        ...,
    [
        0.2930,
        -0.1439,
        0.0093,  ...,
        -0.2825,
        0.0913,
        -0.3584
    ],
    [
        0.2930,
        -0.1439,
        0.0093,  ...,
        -0.2825,
        0.0913,
        -0.3584
    ],
    [
        0.2930,
        -0.1439,
        0.0093,  ...,
        -0.2825,
        0.0913,
        -0.3584
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -157.8443,
    -155.6843,
    -160.6740,
    -162.2653,
    -157.6148,
    -160.7010,
    -162.1727,
    -160.4219,
    -159.4473,
    -160.7603,
    -155.8686,
    -154.0388,
    -160.4911,
    -155.4818,
    -154.3406,
    -156.4530
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -157.8443,
    -155.6843,
    -160.6740,
    -162.2653,
    -157.6148,
    -160.7010,
    -162.1727,
    -160.4219,
    -159.4473,
    -160.7603,
    -155.8686,
    -154.0388,
    -160.4911,
    -155.4818,
    -154.3406,
    -156.4530
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.1890, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1132,
        0.1490,
        -0.0636,  ...,
        -0.1012,
        -0.1554,
        -0.0215
    ],
    [
        -0.1137,
        0.1462,
        -0.0637,  ...,
        -0.1016,
        -0.1552,
        -0.0192
    ],
    [
        -0.2804,
        0.4332,
        -0.1536,  ...,
        -0.1527,
        -0.4622,
        -0.0061
    ],
        ...,
    [
        -0.1128,
        0.1458,
        -0.0627,  ...,
        -0.1025,
        -0.1550,
        -0.0192
    ],
    [
        -0.1127,
        0.1470,
        -0.0635,  ...,
        -0.1036,
        -0.1536,
        -0.0208
    ],
    [
        -0.1153,
        0.1481,
        -0.0642,  ...,
        -0.1018,
        -0.1578,
        -0.0196
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1045,
            0.1337,
            -0.0584,  ...,
            -0.0974,
            -0.1405,
            -0.0229
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.1050,
            0.1310,
            -0.0588,  ...,
            -0.0980,
            -0.1401,
            -0.0205
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2720,
            0.4189,
            -0.1492,  ...,
            -0.1504,
            -0.4471,
            -0.0071
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2864,
        0.0762,
        -0.3572
    ],
    [
        0.2843,
        -0.1286,
        0.0041,  ...,
        -0.2864,
        0.0762,
        -0.3572
    ],
    [
        0.2843,
        -0.1286,
        0.0041,  ...,
        -0.2864,
        0.0762,
        -0.3572
    ],
        ...,
    [
        0.2843,
        -0.1286,
        0.0041,  ...,
        -0.2864,
        0.0762,
        -0.3572
    ],
    [
        0.2843,
        -0.1286,
        0.0041,  ...,
        -0.2864,
        0.0762,
        -0.3572
    ],
    [
        0.2843,
        -0.1286,
        0.0041,  ...,
        -0.2864,
        0.0762,
        -0.3572
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -152.8337,
    -150.7248,
    -155.0038,
    -157.0506,
    -152.5894,
    -155.5677,
    -156.9583,
    -155.2825,
    -154.3476,
    -155.6173,
    -150.9094,
    -149.1277,
    -154.8971,
    -150.5139,
    -149.4319,
    -151.4651
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -152.8337,
    -150.7248,
    -155.0038,
    -157.0506,
    -152.5893,
    -155.5677,
    -156.9583,
    -155.2825,
    -154.3476,
    -155.6173,
    -150.9094,
    -149.1277,
    -154.8971,
    -150.5139,
    -149.4319,
    -151.4651
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.2402, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1222,
        0.1635,
        -0.0681,  ...,
        -0.1047,
        -0.1708,
        -0.0200
    ],
    [
        -0.1225,
        0.1610,
        -0.0684,  ...,
        -0.1049,
        -0.1706,
        -0.0180
    ],
    [
        -0.2888,
        0.4476,
        -0.1583,  ...,
        -0.1555,
        -0.4771,
        -0.0055
    ],
        ...,
    [
        -0.1216,
        0.1608,
        -0.0677,  ...,
        -0.1059,
        -0.1705,
        -0.0179
    ],
    [
        -0.1217,
        0.1618,
        -0.0684,  ...,
        -0.1070,
        -0.1692,
        -0.0192
    ],
    [
        -0.1244,
        0.1627,
        -0.0688,  ...,
        -0.1055,
        -0.1732,
        -0.0184
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1132,
            0.1490,
            -0.0636,  ...,
            -0.1012,
            -0.1554,
            -0.0215
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.1137,
            0.1462,
            -0.0637,  ...,
            -0.1016,
            -0.1552,
            -0.0192
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2804,
            0.4332,
            -0.1536,  ...,
            -0.1527,
            -0.4622,
            -0.0061
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2900,
        0.0608,
        -0.3559
    ],
    [
        0.2753,
        -0.1141,
        -0.0004,  ...,
        -0.2900,
        0.0608,
        -0.3559
    ],
    [
        0.2753,
        -0.1141,
        -0.0004,  ...,
        -0.2900,
        0.0608,
        -0.3559
    ],
        ...,
    [
        0.2753,
        -0.1141,
        -0.0004,  ...,
        -0.2900,
        0.0608,
        -0.3559
    ],
    [
        0.2753,
        -0.1141,
        -0.0004,  ...,
        -0.2900,
        0.0608,
        -0.3559
    ],
    [
        0.2753,
        -0.1141,
        -0.0004,  ...,
        -0.2900,
        0.0608,
        -0.3559
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -148.4387,
    -146.3837,
    -149.9413,
    -152.4524,
    -148.1828,
    -151.0497,
    -152.3601,
    -150.7604,
    -149.8662,
    -151.0905,
    -146.5694,
    -144.8368,
    -149.9147,
    -146.1678,
    -145.1411,
    -147.0966
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -148.4387,
    -146.3837,
    -149.9413,
    -152.4524,
    -148.1828,
    -151.0497,
    -152.3602,
    -150.7604,
    -149.8662,
    -151.0905,
    -146.5693,
    -144.8368,
    -149.9147,
    -146.1678,
    -145.1411,
    -147.0966
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.2852, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1305,
        0.1780,
        -0.0726,  ...,
        -0.1082,
        -0.1863,
        -0.0187
    ],
    [
        -0.1312,
        0.1753,
        -0.0733,  ...,
        -0.1081,
        -0.1863,
        -0.0170
    ],
    [
        -0.2972,
        0.4620,
        -0.1625,  ...,
        -0.1578,
        -0.4922,
        -0.0046
    ],
        ...,
    [
        -0.1302,
        0.1753,
        -0.0729,  ...,
        -0.1091,
        -0.1862,
        -0.0168
    ],
    [
        -0.1303,
        0.1763,
        -0.0734,  ...,
        -0.1102,
        -0.1848,
        -0.0181
    ],
    [
        -0.1331,
        0.1769,
        -0.0733,  ...,
        -0.1088,
        -0.1890,
        -0.0170
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1222,
            0.1635,
            -0.0681,  ...,
            -0.1047,
            -0.1708,
            -0.0200
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.1225,
            0.1610,
            -0.0684,  ...,
            -0.1049,
            -0.1706,
            -0.0180
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2888,
            0.4476,
            -0.1583,  ...,
            -0.1555,
            -0.4771,
            -0.0055
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2934,
        0.0450,
        -0.3545
    ],
    [
        0.2670,
        -0.0997,
        -0.0050,  ...,
        -0.2934,
        0.0450,
        -0.3545
    ],
    [
        0.2670,
        -0.0997,
        -0.0050,  ...,
        -0.2934,
        0.0450,
        -0.3545
    ],
        ...,
    [
        0.2670,
        -0.0997,
        -0.0050,  ...,
        -0.2934,
        0.0450,
        -0.3545
    ],
    [
        0.2670,
        -0.0997,
        -0.0050,  ...,
        -0.2934,
        0.0450,
        -0.3545
    ],
    [
        0.2670,
        -0.0997,
        -0.0050,  ...,
        -0.2934,
        0.0450,
        -0.3545
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -144.7131,
    -142.7117,
    -145.5433,
    -148.5206,
    -144.4470,
    -147.2018,
    -148.4302,
    -146.9070,
    -146.0519,
    -147.2331,
    -142.9004,
    -141.2187,
    -145.5957,
    -142.4901,
    -141.5216,
    -143.4005
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -144.7131,
    -142.7117,
    -145.5433,
    -148.5206,
    -144.4470,
    -147.2018,
    -148.4302,
    -146.9070,
    -146.0520,
    -147.2331,
    -142.9004,
    -141.2187,
    -145.5957,
    -142.4901,
    -141.5216,
    -143.4005
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.3235, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1388,
        0.1924,
        -0.0771,  ...,
        -0.1109,
        -0.2014,
        -0.0180
    ],
    [
        -0.1393,
        0.1897,
        -0.0779,  ...,
        -0.1110,
        -0.2017,
        -0.0163
    ],
    [
        -0.3054,
        0.4764,
        -0.1669,  ...,
        -0.1601,
        -0.5070,
        -0.0039
    ],
        ...,
    [
        -0.1386,
        0.1898,
        -0.0776,  ...,
        -0.1120,
        -0.2016,
        -0.0156
    ],
    [
        -0.1386,
        0.1907,
        -0.0781,  ...,
        -0.1130,
        -0.2002,
        -0.0172
    ],
    [
        -0.1411,
        0.1914,
        -0.0783,  ...,
        -0.1120,
        -0.2044,
        -0.0159
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1305,
            0.1780,
            -0.0726,  ...,
            -0.1082,
            -0.1863,
            -0.0187
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.1312,
            0.1753,
            -0.0733,  ...,
            -0.1081,
            -0.1863,
            -0.0170
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.2972,
            0.4620,
            -0.1625,  ...,
            -0.1578,
            -0.4922,
            -0.0046
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2966,
        0.0296,
        -0.3534
    ],
    [
        0.2587,
        -0.0852,
        -0.0094,  ...,
        -0.2966,
        0.0296,
        -0.3534
    ],
    [
        0.2587,
        -0.0852,
        -0.0094,  ...,
        -0.2966,
        0.0296,
        -0.3534
    ],
        ...,
    [
        0.2587,
        -0.0852,
        -0.0094,  ...,
        -0.2966,
        0.0296,
        -0.3534
    ],
    [
        0.2587,
        -0.0852,
        -0.0094,  ...,
        -0.2966,
        0.0296,
        -0.3534
    ],
    [
        0.2587,
        -0.0852,
        -0.0094,  ...,
        -0.2966,
        0.0296,
        -0.3534
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -141.7049,
    -139.7569,
    -141.8558,
    -145.3026,
    -141.4265,
    -144.0687,
    -145.2142,
    -143.7686,
    -142.9545,
    -144.0898,
    -139.9471,
    -138.3147,
    -141.9879,
    -139.5293,
    -138.6178,
    -140.4212
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -141.7049,
    -139.7569,
    -141.8558,
    -145.3026,
    -141.4265,
    -144.0687,
    -145.2142,
    -143.7686,
    -142.9545,
    -144.0898,
    -139.9471,
    -138.3147,
    -141.9879,
    -139.5293,
    -138.6178,
    -140.4212
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.3547, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1465,
        0.2066,
        -0.0816,  ...,
        -0.1138,
        -0.2165,
        -0.0170
    ],
    [
        -0.1472,
        0.2039,
        -0.0825,  ...,
        -0.1137,
        -0.2170,
        -0.0155
    ],
    [
        -0.3137,
        0.4908,
        -0.1714,  ...,
        -0.1628,
        -0.5219,
        -0.0031
    ],
        ...,
    [
        -0.1466,
        0.2041,
        -0.0823,  ...,
        -0.1149,
        -0.2170,
        -0.0149
    ],
    [
        -0.1464,
        0.2049,
        -0.0830,  ...,
        -0.1158,
        -0.2156,
        -0.0164
    ],
    [
        -0.1490,
        0.2056,
        -0.0832,  ...,
        -0.1150,
        -0.2201,
        -0.0151
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1388,
            0.1924,
            -0.0771,  ...,
            -0.1109,
            -0.2014,
            -0.0180
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.1393,
            0.1897,
            -0.0779,  ...,
            -0.1110,
            -0.2017,
            -0.0163
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.3054,
            0.4764,
            -0.1669,  ...,
            -0.1601,
            -0.5070,
            -0.0039
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2995,
        0.0139,
        -0.3527
    ],
    [
        0.2510,
        -0.0710,
        -0.0140,  ...,
        -0.2995,
        0.0139,
        -0.3527
    ],
    [
        0.2510,
        -0.0710,
        -0.0140,  ...,
        -0.2995,
        0.0139,
        -0.3527
    ],
        ...,
    [
        0.2510,
        -0.0710,
        -0.0140,  ...,
        -0.2995,
        0.0139,
        -0.3527
    ],
    [
        0.2510,
        -0.0710,
        -0.0140,  ...,
        -0.2995,
        0.0139,
        -0.3527
    ],
    [
        0.2510,
        -0.0710,
        -0.0140,  ...,
        -0.2995,
        0.0139,
        -0.3527
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -139.4451,
    -137.5519,
    -138.9129,
    -142.8320,
    -139.1558,
    -141.6840,
    -142.7464,
    -141.3774,
    -140.6050,
    -141.6944,
    -137.7411,
    -136.1624,
    -139.1242,
    -137.3156,
    -136.4658,
    -138.1898
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -139.4451,
    -137.5520,
    -138.9129,
    -142.8320,
    -139.1558,
    -141.6840,
    -142.7464,
    -141.3774,
    -140.6050,
    -141.6944,
    -137.7411,
    -136.1624,
    -139.1241,
    -137.3156,
    -136.4658,
    -138.1898
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.3784, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1543,
        0.2207,
        -0.0864,  ...,
        -0.1165,
        -0.2320,
        -0.0161
    ],
    [
        -0.1553,
        0.2179,
        -0.0873,  ...,
        -0.1165,
        -0.2329,
        -0.0149
    ],
    [
        -0.3222,
        0.5055,
        -0.1758,  ...,
        -0.1652,
        -0.5369,
        -0.0022
    ],
        ...,
    [
        -0.1548,
        0.2182,
        -0.0872,  ...,
        -0.1176,
        -0.2327,
        -0.0142
    ],
    [
        -0.1542,
        0.2191,
        -0.0879,  ...,
        -0.1187,
        -0.2311,
        -0.0157
    ],
    [
        -0.1569,
        0.2197,
        -0.0879,  ...,
        -0.1179,
        -0.2357,
        -0.0142
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1465,
            0.2066,
            -0.0816,  ...,
            -0.1138,
            -0.2165,
            -0.0170
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.1472,
            0.2039,
            -0.0825,  ...,
            -0.1137,
            -0.2170,
            -0.0155
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.3137,
            0.4908,
            -0.1714,  ...,
            -0.1628,
            -0.5219,
            -0.0031
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],

        ...,
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ],
    [
        [
            -0.3975,
            0.2776,
            -0.0676,  ...,
            0.0419,
            -0.3943,
            0.3907
        ],
        [
            -0.3887,
            0.3079,
            -0.0542,  ...,
            0.0225,
            -0.4829,
            0.3610
        ],
        [
            -0.1698,
            0.1667,
            -0.0434,  ...,
            0.0034,
            -0.4156,
            0.1462
        ],
         ...,
        [
            -0.3011,
            0.2146,
            -0.2662,  ...,
            0.2587,
            -0.3460,
            0.5270
        ],
        [
            -0.3234,
            0.1980,
            -0.0936,  ...,
            0.1473,
            -0.3047,
            0.2764
        ],
        [
            -0.2300,
            0.2091,
            -0.1094,  ...,
            0.1845,
            -0.2340,
            0.3375
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.3025,
        -0.0017,
        -0.3517
    ],
    [
        0.2432,
        -0.0569,
        -0.0188,  ...,
        -0.3025,
        -0.0017,
        -0.3517
    ],
    [
        0.2432,
        -0.0569,
        -0.0188,  ...,
        -0.3025,
        -0.0017,
        -0.3517
    ],
        ...,
    [
        0.2432,
        -0.0569,
        -0.0188,  ...,
        -0.3025,
        -0.0017,
        -0.3517
    ],
    [
        0.2432,
        -0.0569,
        -0.0188,  ...,
        -0.3025,
        -0.0017,
        -0.3517
    ],
    [
        0.2432,
        -0.0569,
        -0.0188,  ...,
        -0.3025,
        -0.0017,
        -0.3517
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -137.9678,
    -136.1306,
    -136.7510,
    -141.1441,
    -137.6668,
    -140.0808,
    -141.0619,
    -139.7693,
    -139.0397,
    -140.0826,
    -136.3188,
    -134.7945,
    -137.0401,
    -135.8859,
    -135.0970,
    -136.7432
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -137.9678,
    -136.1306,
    -136.7510,
    -141.1441,
    -137.6668,
    -140.0808,
    -141.0619,
    -139.7693,
    -139.0397,
    -140.0826,
    -136.3187,
    -134.7945,
    -137.0401,
    -135.8859,
    -135.0970,
    -136.7432
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-1.3943, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [
                -19.3100,
                -19.8644,
                -19.8369,  ...,
                -20.7096,
                -19.5979,
                -19.7959
            ],
            [
                -19.4981,
                -20.4680,
                -19.6593,  ...,
                -20.1509,
                -20.7409,
                -19.7159
            ],
            [
                -19.1603,
                -19.2303,
                -20.8771,  ...,
                -20.9628,
                -20.8894,
                -20.0504
            ],
          ...,
            [
                -20.8571,
                -19.4660,
                -19.7820,  ...,
                -19.2243,
                -20.3088,
                -19.4375
            ],
            [
                -20.4894,
                -20.6324,
                -20.4039,  ...,
                -20.8412,
                -19.4315,
                -19.4590
            ],
            [
                -20.3822,
                -19.2165,
                -19.6086,  ...,
                -20.0971,
                -19.4898,
                -19.4505
            ]
        ],
        [
            [
                -20.8901,
                -19.6896,
                -20.4708,  ...,
                -19.1566,
                -19.6848,
                -19.6693
            ],
            [
                -20.9499,
                -20.3057,
                -20.3204,  ...,
                -20.0178,
                -20.2982,
                -20.2328
            ],
            [
                -20.0149,
                -19.7839,
                -20.7507,  ...,
                -19.7194,
                -20.1541,
                -19.2220
            ],
          ...,
            [
                -19.3555,
                -20.0902,
                -19.2415,  ...,
                -19.0782,
                -19.6736,
                -20.8067
            ],
            [
                -19.3894,
                -20.8614,
                -18.9970,  ...,
                -20.8661,
                -20.4462,
                -19.3342
            ],
            [
                -19.1706,
                -19.7342,
                -20.7011,  ...,
                -19.6741,
                -20.1811,
                -20.5454
            ]
        ],
        [
            [
                -19.1132,
                -20.6705,
                -19.2090,  ...,
                -20.8058,
                -20.2360,
                -20.5340
            ],
            [
                -19.2577,
                -20.5834,
                -18.9565,  ...,
                -20.8396,
                -20.5129,
                -20.7964
            ],
            [
                -19.6375,
                -19.4500,
                -20.5435,  ...,
                -20.0784,
                -19.1997,
                -20.6490
            ],
          ...,
            [
                -19.8195,
                -19.5571,
                -20.1343,  ...,
                -19.2062,
                -20.7796,
                -19.6752
            ],
            [
                -19.9963,
                -19.7177,
                -20.4216,  ...,
                -19.7797,
                -20.5676,
                -20.9179
            ],
            [
                -20.5007,
                -20.8838,
                -20.5975,  ...,
                -19.5573,
                -19.0817,
                -20.4779
            ]
        ]
    ],
    [
        [
            [
                -20.1322,
                -20.8743,
                -20.0965,  ...,
                -20.7246,
                -19.6489,
                -19.2011
            ],
            [
                -19.9483,
                -20.2921,
                -19.4329,  ...,
                -20.8919,
                -19.4401,
                -19.4230
            ],
            [
                -19.9887,
                -20.8458,
                -20.2549,  ...,
                -20.3272,
                -19.7266,
                -19.9984
            ],
          ...,
            [
                -20.7370,
                -20.9554,
                -20.5705,  ...,
                -19.3417,
                -20.4553,
                -19.1651
            ],
            [
                -19.5576,
                -20.0010,
                -19.8811,  ...,
                -19.7912,
                -19.8791,
                -20.2254
            ],
            [
                -20.2291,
                -19.0211,
                -20.6954,  ...,
                -19.9751,
                -19.8168,
                -19.8346
            ]
        ],
        [
            [
                -20.4201,
                -20.0417,
                -19.3587,  ...,
                -19.6499,
                -20.5916,
                -20.5715
            ],
            [
                -20.5376,
                -19.8038,
                -19.2013,  ...,
                -20.8347,
                -20.8773,
                -19.8419
            ],
            [
                -20.8660,
                -19.2023,
                -19.6138,  ...,
                -19.3866,
                -20.4589,
                -20.3440
            ],
          ...,
            [
                -20.6314,
                -19.2592,
                -19.4055,  ...,
                -20.3035,
                -19.2075,
                -19.7617
            ],
            [
                -19.5765,
                -20.4315,
                -20.1508,  ...,
                -19.5158,
                -20.3691,
                -20.5202
            ],
            [
                -20.2150,
                -19.9100,
                -20.9471,  ...,
                -19.2250,
                -20.9061,
                -20.6205
            ]
        ],
        [
            [
                -19.2445,
                -19.6908,
                -19.7467,  ...,
                -20.6041,
                -19.0443,
                -19.3402
            ],
            [
                -20.9608,
                -20.2375,
                -19.6144,  ...,
                -20.9162,
                -20.2822,
                -19.4418
            ],
            [
                -20.4594,
                -19.1890,
                -20.2555,  ...,
                -19.5624,
                -19.2371,
                -19.1592
            ],
          ...,
            [
                -20.7905,
                -20.0770,
                -19.5432,  ...,
                -20.1344,
                -20.4260,
                -19.9960
            ],
            [
                -20.2602,
                -19.6606,
                -19.6673,  ...,
                -20.0713,
                -20.5631,
                -20.7617
            ],
            [
                -19.6262,
                -20.0760,
                -19.9367,  ...,
                -20.8238,
                -20.6095,
                -20.0460
            ]
        ]
    ],
    [
        [
            [
                -39.1842,
                -40.2156,
                -39.6197,  ...,
                -40.3006,
                -40.4201,
                -40.9444
            ],
            [
                -40.4611,
                -40.0645,
                -40.3117,  ...,
                -40.2929,
                -40.1171,
                -40.2862
            ],
            [
                -39.4014,
                -40.4764,
                -40.4666,  ...,
                -40.6463,
                -40.4894,
                -39.9874
            ],
          ...,
            [
                -40.5074,
                -40.1697,
                -39.5755,  ...,
                -39.9527,
                -40.1927,
                -39.4143
            ],
            [
                -39.8881,
                -40.0257,
                -39.1130,  ...,
                -40.0722,
                -40.3592,
                -40.6736
            ],
            [
                -40.6186,
                -40.5183,
                -40.8003,  ...,
                -39.1433,
                -40.3701,
                -39.5207
            ]
        ],
        [
            [
                -40.1838,
                -39.7368,
                -40.2178,  ...,
                -40.9439,
                -39.6890,
                -40.5764
            ],
            [
                -40.0136,
                -40.6535,
                -39.8184,  ...,
                -40.8095,
                -39.9714,
                -40.8400
            ],
            [
                -39.3170,
                -40.1740,
                -41.0081,  ...,
                -39.3919,
                -39.8332,
                -40.6833
            ],
          ...,
            [
                -39.4887,
                -39.6995,
                -40.5396,  ...,
                -39.5413,
                -40.7846,
                -38.9938
            ],
            [
                -39.2476,
                -40.9080,
                -39.2374,  ...,
                -40.4873,
                -40.3234,
                -40.2831
            ],
            [
                -40.1091,
                -39.3628,
                -41.1133,  ...,
                -40.6238,
                -39.6979,
                -40.9238
            ]
        ],
        [
            [
                -40.2567,
                -39.9235,
                -41.1180,  ...,
                -40.2994,
                -39.3166,
                -39.6802
            ],
            [
                -39.7788,
                -40.2480,
                -38.9844,  ...,
                -39.1412,
                -40.3201,
                -40.0719
            ],
            [
                -39.5759,
                -39.9110,
                -40.8986,  ...,
                -39.0478,
                -40.2346,
                -39.8637
            ],
          ...,
            [
                -39.2577,
                -39.7607,
                -40.7923,  ...,
                -40.2737,
                -39.7913,
                -40.6424
            ],
            [
                -39.5974,
                -40.7629,
                -39.4061,  ...,
                -40.4149,
                -40.2493,
                -40.9806
            ],
            [
                -40.7460,
                -39.4113,
                -39.9625,  ...,
                -39.1217,
                -40.0931,
                -39.9351
            ]
        ]
    ],


        ...,
    [
        [
            [
                -20.1141,
                -19.3970,
                -19.3120,  ...,
                -20.6167,
                -19.9129,
                -20.2386
            ],
            [
                -19.3875,
                -20.4843,
                -20.9012,  ...,
                -20.2925,
                -20.5175,
                -20.4405
            ],
            [
                -19.8451,
                -19.4938,
                -18.9927,  ...,
                -20.5562,
                -20.3896,
                -19.2270
            ],
          ...,
            [
                -20.7675,
                -19.3605,
                -20.6924,  ...,
                -20.8253,
                -19.2638,
                -20.5423
            ],
            [
                -20.6023,
                -19.4575,
                -19.6698,  ...,
                -19.1188,
                -20.3868,
                -20.1974
            ],
            [
                -19.6066,
                -19.2333,
                -19.3823,  ...,
                -20.1579,
                -19.6672,
                -20.0191
            ]
        ],
        [
            [
                -19.2854,
                -19.2799,
                -20.1473,  ...,
                -20.7787,
                -19.4235,
                -20.1601
            ],
            [
                -19.8052,
                -19.5849,
                -20.8107,  ...,
                -19.0742,
                -19.0381,
                -20.0818
            ],
            [
                -20.3550,
                -20.8120,
                -20.4475,  ...,
                -19.1506,
                -19.8994,
                -19.2981
            ],
          ...,
            [
                -20.3500,
                -19.6938,
                -20.9494,  ...,
                -19.9662,
                -20.3935,
                -20.0695
            ],
            [
                -19.5302,
                -19.5912,
                -20.7910,  ...,
                -19.0757,
                -19.4539,
                -19.4737
            ],
            [
                -19.9485,
                -20.3788,
                -20.3210,  ...,
                -19.5821,
                -19.0822,
                -20.2421
            ]
        ],
        [
            [
                -20.6904,
                -20.9074,
                -19.7946,  ...,
                -20.3013,
                -20.0117,
                -19.6245
            ],
            [
                -20.4184,
                -20.5466,
                -20.7138,  ...,
                -20.4937,
                -18.9515,
                -20.0935
            ],
            [
                -20.2693,
                -20.0606,
                -19.4495,  ...,
                -19.9627,
                -19.8978,
                -20.1754
            ],
          ...,
            [
                -20.2601,
                -19.7416,
                -19.6125,  ...,
                -19.1359,
                -19.8007,
                -20.6879
            ],
            [
                -20.4615,
                -18.9800,
                -20.1085,  ...,
                -20.1543,
                -19.8208,
                -19.5420
            ],
            [
                -19.4711,
                -20.6707,
                -20.2193,  ...,
                -20.5217,
                -19.3608,
                -19.6338
            ]
        ]
    ],
    [
        [
            [
                -19.0097,
                -19.3240,
                -20.5012,  ...,
                -20.1017,
                -19.6741,
                -20.4034
            ],
            [
                -20.9862,
                -20.9650,
                -20.4885,  ...,
                -20.2516,
                -19.5610,
                -19.5696
            ],
            [
                -20.2604,
                -20.5553,
                -20.2833,  ...,
                -19.8800,
                -20.0901,
                -19.3635
            ],
          ...,
            [
                -20.3403,
                -19.8443,
                -19.4682,  ...,
                -19.7896,
                -20.0303,
                -20.7711
            ],
            [
                -19.4576,
                -19.4992,
                -20.2558,  ...,
                -20.7855,
                -19.6069,
                -20.0433
            ],
            [
                -19.4060,
                -20.0414,
                -19.9401,  ...,
                -19.6218,
                -19.0656,
                -20.4760
            ]
        ],
        [
            [
                -19.1592,
                -20.9290,
                -19.4458,  ...,
                -20.3382,
                -19.9828,
                -20.3931
            ],
            [
                -19.3887,
                -19.2451,
                -20.6050,  ...,
                -19.8300,
                -19.1133,
                -19.2074
            ],
            [
                -20.5326,
                -19.4336,
                -20.9724,  ...,
                -19.3761,
                -20.5451,
                -20.5079
            ],
          ...,
            [
                -19.5788,
                -20.2216,
                -20.0583,  ...,
                -20.0858,
                -19.2036,
                -19.4831
            ],
            [
                -20.3805,
                -19.5956,
                -19.3309,  ...,
                -19.3800,
                -19.7279,
                -20.9289
            ],
            [
                -19.5940,
                -19.3273,
                -20.7823,  ...,
                -19.7736,
                -19.2674,
                -20.2216
            ]
        ],
        [
            [
                -20.6925,
                -20.1726,
                -19.9479,  ...,
                -20.6508,
                -19.4701,
                -20.9137
            ],
            [
                -19.1849,
                -20.6915,
                -20.5997,  ...,
                -19.0132,
                -20.0512,
                -19.4396
            ],
            [
                -20.6562,
                -20.1899,
                -20.5455,  ...,
                -19.2651,
                -20.8350,
                -20.6272
            ],
          ...,
            [
                -20.1725,
                -19.5195,
                -19.7779,  ...,
                -19.5401,
                -19.6626,
                -20.5528
            ],
            [
                -20.2046,
                -20.7742,
                -19.5165,  ...,
                -20.7297,
                -20.2834,
                -20.5290
            ],
            [
                -21.0212,
                -20.8968,
                -19.8478,  ...,
                -20.3808,
                -20.1713,
                -19.7766
            ]
        ]
    ],
    [
        [
            [
                -20.1866,
                -20.9337,
                -19.3711,  ...,
                -19.1664,
                -20.4264,
                -19.8899
            ],
            [
                -20.1580,
                -19.6016,
                -19.6628,  ...,
                -20.2160,
                -19.0622,
                -20.5753
            ],
            [
                -20.8298,
                -19.9356,
                -20.2695,  ...,
                -19.2864,
                -20.8987,
                -20.9457
            ],
          ...,
            [
                -20.8206,
                -19.4742,
                -20.0616,  ...,
                -20.3595,
                -19.4683,
                -19.6254
            ],
            [
                -19.8995,
                -19.5944,
                -19.8375,  ...,
                -20.6745,
                -20.1390,
                -20.5606
            ],
            [
                -20.4715,
                -19.4947,
                -19.4666,  ...,
                -19.1597,
                -20.8698,
                -19.5110
            ]
        ],
        [
            [
                -20.0584,
                -20.2167,
                -19.4704,  ...,
                -20.8053,
                -20.1453,
                -19.8303
            ],
            [
                -20.8973,
                -19.2332,
                -20.6231,  ...,
                -20.4820,
                -19.6660,
                -20.1610
            ],
            [
                -19.7932,
                -19.9968,
                -18.9892,  ...,
                -20.1692,
                -20.6271,
                -20.8477
            ],
          ...,
            [
                -20.6239,
                -19.8659,
                -20.7915,  ...,
                -20.7810,
                -19.2275,
                -20.2959
            ],
            [
                -19.2116,
                -20.8818,
                -20.4024,  ...,
                -19.4145,
                -19.1605,
                -20.5950
            ],
            [
                -20.1625,
                -19.5818,
                -20.7757,  ...,
                -19.6554,
                -19.6050,
                -19.1690
            ]
        ],
        [
            [
                -20.6393,
                -20.1188,
                -19.1023,  ...,
                -19.8101,
                -19.5297,
                -20.2229
            ],
            [
                -20.1325,
                -20.4622,
                -19.0132,  ...,
                -19.2112,
                -19.5204,
                -20.1073
            ],
            [
                -20.2488,
                -19.7750,
                -19.5426,  ...,
                -19.5987,
                -20.8373,
                -19.8021
            ],
          ...,
            [
                -19.2014,
                -20.1975,
                -19.3802,  ...,
                -20.1798,
                -20.5766,
                -20.0265
            ],
            [
                -19.5572,
                -20.3467,
                -20.5939,  ...,
                -19.2950,
                -19.4953,
                -20.8008
            ],
            [
                -19.2627,
                -19.0583,
                -20.7987,  ...,
                -20.6028,
                -19.8807,
                -19.4404
            ]
        ]
    ]
],
       device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1460,
        -0.1671,
        0.0035
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1460,
        -0.1671,
        0.0035
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1460,
        -0.1671,
        0.0035
    ],
        ...,
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1460,
        -0.1671,
        0.0035
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1460,
        -0.1671,
        0.0035
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1460,
        -0.1671,
        0.0035
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
tensor([
    [
        -0.2822,
        0.3037,
        -0.1099,  ...,
        0.0276,
        -0.5040,
        0.2847
    ],
    [
        -0.3634,
        0.3039,
        -0.0630,  ...,
        0.0737,
        -0.3840,
        0.3285
    ],
    [
        -0.3299,
        0.2889,
        -0.1379,  ...,
        -0.0024,
        -0.3455,
        0.3211
    ],
        ...,
    [
        -0.3261,
        0.2301,
        -0.1067,  ...,
        0.0376,
        -0.3585,
        0.3590
    ],
    [
        -0.3232,
        0.2804,
        -0.0799,  ...,
        0.0315,
        -0.4026,
        0.3106
    ],
    [
        -0.3597,
        0.2690,
        -0.0579,  ...,
        -0.0105,
        -0.3899,
        0.2686
    ]
],
       device='cuda: 0', grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1950,
        -0.1559,
        -0.0689
    ],
    [
        0.1154,
        0.0261,
        -0.0423,  ...,
        -0.1950,
        -0.1559,
        -0.0689
    ],
    [
        0.1154,
        0.0261,
        -0.0423,  ...,
        -0.1950,
        -0.1559,
        -0.0689
    ],
        ...,
    [
        0.1154,
        0.0261,
        -0.0423,  ...,
        -0.1950,
        -0.1559,
        -0.0689
    ],
    [
        0.1154,
        0.0261,
        -0.0423,  ...,
        -0.1950,
        -0.1559,
        -0.0689
    ],
    [
        0.1154,
        0.0261,
        -0.0423,  ...,
        -0.1950,
        -0.1559,
        -0.0689
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(2.9569, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(-0.0059, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 2/3125 [
    00: 21<9: 27: 13,
    10.90s/it, loss=1.71, v_num=0
]  ----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [
        -0.0808,
        0.0622,
        -0.0079,  ...,
        -0.0027,
        -0.0541,
        0.0741
    ],
    [
        -0.0842,
        0.0612,
        -0.0078,  ...,
        -0.0016,
        -0.0542,
        0.0749
    ],
    [
        -0.0849,
        0.0622,
        -0.0088,  ...,
        -0.0027,
        -0.0551,
        0.0754
    ],
        ...,
    [
        -0.0811,
        0.0619,
        -0.0071,  ...,
        -0.0019,
        -0.0562,
        0.0762
    ],
    [
        -0.2277,
        0.3631,
        -0.1716,  ...,
        0.0408,
        -0.2424,
        0.2500
    ],
    [
        -0.0834,
        0.0618,
        -0.0078,  ...,
        -0.0006,
        -0.0554,
        0.0756
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1764,
        0.2892,
        -0.3069
    ],
    [
        0.2217,
        -0.2986,
        0.2102,  ...,
        -0.1764,
        0.2892,
        -0.3069
    ],
    [
        0.2217,
        -0.2986,
        0.2102,  ...,
        -0.1764,
        0.2892,
        -0.3069
    ],
        ...,
    [
        0.2217,
        -0.2986,
        0.2102,  ...,
        -0.1764,
        0.2892,
        -0.3069
    ],
    [
        0.2217,
        -0.2986,
        0.2102,  ...,
        -0.1764,
        0.2892,
        -0.3069
    ],
    [
        0.2217,
        -0.2986,
        0.2102,  ...,
        -0.1764,
        0.2892,
        -0.3069
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -321.8330,
    -312.1516,
    -312.1407,
    -322.1730,
    -319.9937,
    -312.6472,
    -307.0956,
    -311.0525,
    -303.7970,
    -313.5747,
    -324.1564,
    -313.8076,
    -304.2292,
    -313.8029,
    -325.9514,
    -315.0864
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -321.8329,
    -312.1516,
    -312.1407,
    -322.1729,
    -319.9937,
    -312.6472,
    -307.0956,
    -311.0525,
    -303.7970,
    -313.5747,
    -324.1564,
    -313.8076,
    -304.2292,
    -313.8029,
    -325.9514,
    -315.0864
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.3713, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.0980,
        0.0632,
        0.0056,  ...,
        -0.0022,
        -0.0590,
        0.0817
    ],
    [
        -0.1025,
        0.0629,
        0.0047,  ...,
        -0.0006,
        -0.0591,
        0.0824
    ],
    [
        -0.1014,
        0.0629,
        0.0048,  ...,
        -0.0007,
        -0.0590,
        0.0841
    ],
        ...,
    [
        -0.0968,
        0.0637,
        0.0064,  ...,
        -0.0020,
        -0.0604,
        0.0809
    ],
    [
        -0.2398,
        0.3895,
        -0.1826,  ...,
        0.0493,
        -0.2604,
        0.2681
    ],
    [
        -0.1006,
        0.0640,
        0.0050,  ...,
        -0.0012,
        -0.0582,
        0.0836
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.0808,
            0.0622,
            -0.0079,  ...,
            -0.0027,
            -0.0541,
            0.0741
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.0842,
            0.0612,
            -0.0078,  ...,
            -0.0016,
            -0.0542,
            0.0749
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.0849,
            0.0622,
            -0.0088,  ...,
            -0.0027,
            -0.0551,
            0.0754
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1770,
        0.2865,
        -0.2989
    ],
    [
        0.2045,
        -0.2976,
        0.2236,  ...,
        -0.1770,
        0.2865,
        -0.2989
    ],
    [
        0.2045,
        -0.2976,
        0.2236,  ...,
        -0.1770,
        0.2865,
        -0.2989
    ],
        ...,
    [
        0.2045,
        -0.2976,
        0.2236,  ...,
        -0.1770,
        0.2865,
        -0.2989
    ],
    [
        0.2045,
        -0.2976,
        0.2236,  ...,
        -0.1770,
        0.2865,
        -0.2989
    ],
    [
        0.2045,
        -0.2976,
        0.2236,  ...,
        -0.1770,
        0.2865,
        -0.2989
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -318.9018,
    -309.2809,
    -309.2552,
    -319.9149,
    -317.0982,
    -309.7672,
    -304.1858,
    -308.1523,
    -300.9235,
    -310.6613,
    -321.7591,
    -310.8762,
    -301.3070,
    -310.8981,
    -323.3162,
    -312.1744
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -318.9018,
    -309.2808,
    -309.2552,
    -319.9149,
    -317.0983,
    -309.7671,
    -304.1858,
    -308.1523,
    -300.9234,
    -310.6613,
    -321.7591,
    -310.8762,
    -301.3070,
    -310.8981,
    -323.3162,
    -312.1744
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.3430, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1067,
        0.0652,
        0.0103,  ...,
        0.0038,
        -0.0619,
        0.0872
    ],
    [
        -0.1093,
        0.0647,
        0.0103,  ...,
        0.0052,
        -0.0616,
        0.0872
    ],
    [
        -0.1083,
        0.0637,
        0.0105,  ...,
        0.0050,
        -0.0630,
        0.0878
    ],
        ...,
    [
        -0.1060,
        0.0653,
        0.0112,  ...,
        0.0031,
        -0.0627,
        0.0867
    ],
    [
        -0.2522,
        0.4159,
        -0.1930,  ...,
        0.0580,
        -0.2783,
        0.2860
    ],
    [
        -0.1093,
        0.0648,
        0.0103,  ...,
        0.0031,
        -0.0605,
        0.0872
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -9.7978e-02,
            6.3240e-02,
            5.5654e-03,  ...,
            -2.1514e-03,
            -5.9021e-02,
            8.1717e-02
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -1.0248e-01,
            6.2924e-02,
            4.7429e-03,  ...,
            -5.6916e-04,
            -5.9071e-02,
            8.2405e-02
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -1.0139e-01,
            6.2859e-02,
            4.7921e-03,  ...,
            -7.3939e-04,
            -5.8970e-02,
            8.4076e-02
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],

        ...,
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1727,
        0.2842,
        -0.2953
    ],
    [
        0.1958,
        -0.2956,
        0.2283,  ...,
        -0.1727,
        0.2842,
        -0.2953
    ],
    [
        0.1958,
        -0.2956,
        0.2283,  ...,
        -0.1727,
        0.2842,
        -0.2953
    ],
        ...,
    [
        0.1958,
        -0.2956,
        0.2283,  ...,
        -0.1727,
        0.2842,
        -0.2953
    ],
    [
        0.1958,
        -0.2956,
        0.2283,  ...,
        -0.1727,
        0.2842,
        -0.2953
    ],
    [
        0.1958,
        -0.2956,
        0.2283,  ...,
        -0.1727,
        0.2842,
        -0.2953
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -315.2819,
    -305.7016,
    -305.6766,
    -316.8549,
    -313.5020,
    -306.1458,
    -300.6140,
    -304.5751,
    -297.3871,
    -307.1040,
    -318.5594,
    -307.2644,
    -297.7707,
    -307.3090,
    -319.8768,
    -308.5691
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -315.2819,
    -305.7016,
    -305.6766,
    -316.8549,
    -313.5020,
    -306.1458,
    -300.6140,
    -304.5752,
    -297.3871,
    -307.1039,
    -318.5594,
    -307.2644,
    -297.7707,
    -307.3090,
    -319.8768,
    -308.5691
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.3078, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1069,
        0.0667,
        0.0086,  ...,
        0.0074,
        -0.0616,
        0.0924
    ],
    [
        -0.1086,
        0.0659,
        0.0083,  ...,
        0.0085,
        -0.0621,
        0.0922
    ],
    [
        -0.1078,
        0.0674,
        0.0079,  ...,
        0.0078,
        -0.0635,
        0.0929
    ],
        ...,
    [
        -0.1058,
        0.0670,
        0.0085,  ...,
        0.0096,
        -0.0624,
        0.0922
    ],
    [
        -0.2650,
        0.4420,
        -0.2035,  ...,
        0.0671,
        -0.2958,
        0.3041
    ],
    [
        -0.1078,
        0.0650,
        0.0085,  ...,
        0.0087,
        -0.0625,
        0.0925
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1067,
            0.0652,
            0.0103,  ...,
            0.0038,
            -0.0619,
            0.0872
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1093,
            0.0647,
            0.0103,  ...,
            0.0052,
            -0.0616,
            0.0872
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1083,
            0.0637,
            0.0105,  ...,
            0.0050,
            -0.0630,
            0.0878
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1671,
        0.2821,
        -0.2900
    ],
    [
        0.1956,
        -0.2941,
        0.2266,  ...,
        -0.1671,
        0.2821,
        -0.2900
    ],
    [
        0.1956,
        -0.2941,
        0.2266,  ...,
        -0.1671,
        0.2821,
        -0.2900
    ],
        ...,
    [
        0.1956,
        -0.2941,
        0.2266,  ...,
        -0.1671,
        0.2821,
        -0.2900
    ],
    [
        0.1956,
        -0.2941,
        0.2266,  ...,
        -0.1671,
        0.2821,
        -0.2900
    ],
    [
        0.1956,
        -0.2941,
        0.2266,  ...,
        -0.1671,
        0.2821,
        -0.2900
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -313.9775,
    -304.4009,
    -304.4027,
    -316.1598,
    -312.2133,
    -304.8408,
    -299.3505,
    -303.3189,
    -296.0929,
    -305.8065,
    -317.7184,
    -305.9915,
    -296.4957,
    -306.0307,
    -318.7957,
    -307.2977
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -313.9775,
    -304.4009,
    -304.4027,
    -316.1598,
    -312.2133,
    -304.8408,
    -299.3506,
    -303.3189,
    -296.0929,
    -305.8065,
    -317.7184,
    -305.9915,
    -296.4957,
    -306.0307,
    -318.7957,
    -307.2977
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.2957, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1090,
        0.0636,
        0.0091,  ...,
        0.0093,
        -0.0614,
        0.0898
    ],
    [
        -0.1103,
        0.0629,
        0.0085,  ...,
        0.0089,
        -0.0604,
        0.0898
    ],
    [
        -0.1076,
        0.0642,
        0.0057,  ...,
        0.0081,
        -0.0610,
        0.0901
    ],
        ...,
    [
        -0.1087,
        0.0633,
        0.0085,  ...,
        0.0101,
        -0.0622,
        0.0895
    ],
    [
        -0.2781,
        0.4684,
        -0.2138,  ...,
        0.0762,
        -0.3130,
        0.3226
    ],
    [
        -0.1096,
        0.0637,
        0.0086,  ...,
        0.0088,
        -0.0637,
        0.0920
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1069,
            0.0667,
            0.0086,  ...,
            0.0074,
            -0.0616,
            0.0924
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1086,
            0.0659,
            0.0083,  ...,
            0.0085,
            -0.0621,
            0.0922
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1078,
            0.0674,
            0.0079,  ...,
            0.0078,
            -0.0635,
            0.0929
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1670,
        0.2809,
        -0.2905
    ],
    [
        0.1935,
        -0.2972,
        0.2272,  ...,
        -0.1670,
        0.2809,
        -0.2905
    ],
    [
        0.1935,
        -0.2972,
        0.2272,  ...,
        -0.1670,
        0.2809,
        -0.2905
    ],
        ...,
    [
        0.1935,
        -0.2972,
        0.2272,  ...,
        -0.1670,
        0.2809,
        -0.2905
    ],
    [
        0.1935,
        -0.2972,
        0.2272,  ...,
        -0.1670,
        0.2809,
        -0.2905
    ],
    [
        0.1935,
        -0.2972,
        0.2272,  ...,
        -0.1670,
        0.2809,
        -0.2905
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -313.7103,
    -304.1123,
    -304.0933,
    -316.4398,
    -311.9353,
    -304.5869,
    -299.0915,
    -303.0367,
    -295.8327,
    -305.5316,
    -317.8521,
    -305.7048,
    -296.2446,
    -305.7591,
    -318.6881,
    -307.0442
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -313.7103,
    -304.1123,
    -304.0933,
    -316.4398,
    -311.9353,
    -304.5869,
    -299.0915,
    -303.0367,
    -295.8327,
    -305.5316,
    -317.8521,
    -305.7048,
    -296.2446,
    -305.7591,
    -318.6881,
    -307.0441
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.2936, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1138,
        0.0605,
        0.0121,  ...,
        0.0098,
        -0.0608,
        0.0891
    ],
    [
        -0.1156,
        0.0597,
        0.0126,  ...,
        0.0094,
        -0.0603,
        0.0872
    ],
    [
        -0.1145,
        0.0613,
        0.0112,  ...,
        0.0073,
        -0.0587,
        0.0881
    ],
        ...,
    [
        -0.1137,
        0.0610,
        0.0120,  ...,
        0.0093,
        -0.0617,
        0.0881
    ],
    [
        -0.2913,
        0.4947,
        -0.2241,  ...,
        0.0855,
        -0.3299,
        0.3412
    ],
    [
        -0.1135,
        0.0616,
        0.0125,  ...,
        0.0093,
        -0.0608,
        0.0905
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1090,
            0.0636,
            0.0091,  ...,
            0.0093,
            -0.0614,
            0.0898
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1103,
            0.0629,
            0.0085,  ...,
            0.0089,
            -0.0604,
            0.0898
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1076,
            0.0642,
            0.0057,  ...,
            0.0081,
            -0.0610,
            0.0901
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1665,
        0.2839,
        -0.2920
    ],
    [
        0.1888,
        -0.3003,
        0.2301,  ...,
        -0.1665,
        0.2839,
        -0.2920
    ],
    [
        0.1888,
        -0.3003,
        0.2301,  ...,
        -0.1665,
        0.2839,
        -0.2920
    ],
        ...,
    [
        0.1888,
        -0.3003,
        0.2301,  ...,
        -0.1665,
        0.2839,
        -0.2920
    ],
    [
        0.1888,
        -0.3003,
        0.2301,  ...,
        -0.1665,
        0.2839,
        -0.2920
    ],
    [
        0.1888,
        -0.3003,
        0.2301,  ...,
        -0.1665,
        0.2839,
        -0.2920
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -313.3001,
    -303.7100,
    -303.7015,
    -316.5073,
    -311.5508,
    -304.1901,
    -298.6969,
    -302.6238,
    -295.4410,
    -305.1649,
    -317.7734,
    -305.3228,
    -295.8789,
    -305.3697,
    -318.3658,
    -306.6443
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -313.3001,
    -303.7100,
    -303.7015,
    -316.5073,
    -311.5508,
    -304.1902,
    -298.6969,
    -302.6239,
    -295.4410,
    -305.1649,
    -317.7735,
    -305.3228,
    -295.8789,
    -305.3697,
    -318.3658,
    -306.6443
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.2902, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1124,
        0.0588,
        0.0124,  ...,
        0.0037,
        -0.0543,
        0.0887
    ],
    [
        -0.1148,
        0.0585,
        0.0120,  ...,
        0.0038,
        -0.0552,
        0.0856
    ],
    [
        -0.1139,
        0.0592,
        0.0109,  ...,
        0.0012,
        -0.0539,
        0.0859
    ],
        ...,
    [
        -0.1110,
        0.0602,
        0.0125,  ...,
        0.0033,
        -0.0559,
        0.0865
    ],
    [
        -0.3046,
        0.5211,
        -0.2343,  ...,
        0.0950,
        -0.3463,
        0.3601
    ],
    [
        -0.1133,
        0.0595,
        0.0113,  ...,
        0.0027,
        -0.0570,
        0.0894
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1138,
            0.0605,
            0.0121,  ...,
            0.0098,
            -0.0608,
            0.0891
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1156,
            0.0597,
            0.0126,  ...,
            0.0094,
            -0.0603,
            0.0872
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1145,
            0.0613,
            0.0112,  ...,
            0.0073,
            -0.0587,
            0.0881
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1731,
        0.2876,
        -0.2931
    ],
    [
        0.1902,
        -0.3020,
        0.2304,  ...,
        -0.1731,
        0.2876,
        -0.2931
    ],
    [
        0.1902,
        -0.3020,
        0.2304,  ...,
        -0.1731,
        0.2876,
        -0.2931
    ],
        ...,
    [
        0.1902,
        -0.3020,
        0.2304,  ...,
        -0.1731,
        0.2876,
        -0.2931
    ],
    [
        0.1902,
        -0.3020,
        0.2304,  ...,
        -0.1731,
        0.2876,
        -0.2931
    ],
    [
        0.1902,
        -0.3020,
        0.2304,  ...,
        -0.1731,
        0.2876,
        -0.2931
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -315.7755,
    -306.1391,
    -306.1240,
    -319.4705,
    -314.0093,
    -306.6197,
    -301.1037,
    -305.0699,
    -297.8672,
    -307.6257,
    -320.5893,
    -307.7464,
    -298.2927,
    -307.8297,
    -320.9399,
    -309.0939
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -315.7754,
    -306.1391,
    -306.1240,
    -319.4705,
    -314.0093,
    -306.6197,
    -301.1037,
    -305.0699,
    -297.8672,
    -307.6257,
    -320.5893,
    -307.7463,
    -298.2926,
    -307.8297,
    -320.9399,
    -309.0939
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.3151, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -1.2134e-01,
        6.0786e-02,
        5.3223e-04,  ...,
        -6.5567e-04,
        -5.0560e-02,
        8.7108e-02
    ],
    [
        -1.2652e-01,
        6.1828e-02,
        -1.3104e-04,  ...,
        -1.2683e-03,
        -5.2978e-02,
        8.5923e-02
    ],
    [
        -1.2534e-01,
        6.2990e-02,
        -1.4876e-04,  ...,
        -3.5892e-03,
        -5.1023e-02,
        8.5513e-02
    ],
        ...,
    [
        -1.1986e-01,
        6.2322e-02,
        1.9101e-03,  ...,
        -2.5949e-03,
        -5.2802e-02,
        8.6853e-02
    ],
    [
        -3.1833e-01,
        5.4755e-01,
        -2.4461e-01,  ...,
        1.0487e-01,
        -3.6267e-01,
        3.7885e-01
    ],
    [
        -1.2340e-01,
        6.2901e-02,
        -1.6416e-03,  ...,
        -3.4357e-03,
        -5.3433e-02,
        8.9340e-02
    ]
], device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1124,
            0.0588,
            0.0124,  ...,
            0.0037,
            -0.0543,
            0.0887
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1148,
            0.0585,
            0.0120,  ...,
            0.0038,
            -0.0552,
            0.0856
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1139,
            0.0592,
            0.0109,  ...,
            0.0012,
            -0.0539,
            0.0859
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1792,
        0.2912,
        -0.2932
    ],
    [
        0.1812,
        -0.3000,
        0.2186,  ...,
        -0.1792,
        0.2912,
        -0.2932
    ],
    [
        0.1812,
        -0.3000,
        0.2186,  ...,
        -0.1792,
        0.2912,
        -0.2932
    ],
        ...,
    [
        0.1812,
        -0.3000,
        0.2186,  ...,
        -0.1792,
        0.2912,
        -0.2932
    ],
    [
        0.1812,
        -0.3000,
        0.2186,  ...,
        -0.1792,
        0.2912,
        -0.2932
    ],
    [
        0.1812,
        -0.3000,
        0.2186,  ...,
        -0.1792,
        0.2912,
        -0.2932
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -316.9886,
    -307.3669,
    -307.3458,
    -321.0639,
    -315.2126,
    -307.8383,
    -302.3448,
    -306.2970,
    -299.0694,
    -308.8588,
    -322.0370,
    -308.9662,
    -299.4931,
    -309.0569,
    -322.1460,
    -310.3091
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -316.9886,
    -307.3669,
    -307.3458,
    -321.0639,
    -315.2126,
    -307.8383,
    -302.3448,
    -306.2970,
    -299.0694,
    -308.8588,
    -322.0370,
    -308.9663,
    -299.4931,
    -309.0569,
    -322.1460,
    -310.3091
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.3276, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1326,
        0.0729,
        -0.0142,  ...,
        -0.0013,
        -0.0509,
        0.0904
    ],
    [
        -0.1386,
        0.0742,
        -0.0146,  ...,
        -0.0008,
        -0.0509,
        0.0887
    ],
    [
        -0.1375,
        0.0747,
        -0.0146,  ...,
        -0.0025,
        -0.0498,
        0.0875
    ],
        ...,
    [
        -0.1319,
        0.0742,
        -0.0131,  ...,
        -0.0022,
        -0.0525,
        0.0890
    ],
    [
        -0.3320,
        0.5738,
        -0.2549,  ...,
        0.1148,
        -0.3792,
        0.3977
    ],
    [
        -0.1350,
        0.0753,
        -0.0164,  ...,
        -0.0029,
        -0.0512,
        0.0922
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -1.2134e-01,
            6.0786e-02,
            5.3223e-04,  ...,
            -6.5567e-04,
            -5.0560e-02,
            8.7108e-02
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -1.2652e-01,
            6.1828e-02,
            -1.3104e-04,  ...,
            -1.2683e-03,
            -5.2978e-02,
            8.5923e-02
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -1.2534e-01,
            6.2990e-02,
            -1.4876e-04,  ...,
            -3.5892e-03,
            -5.1023e-02,
            8.5513e-02
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],

        ...,
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1787,
        0.2934,
        -0.2903
    ],
    [
        0.1699,
        -0.2879,
        0.2038,  ...,
        -0.1787,
        0.2934,
        -0.2903
    ],
    [
        0.1699,
        -0.2879,
        0.2038,  ...,
        -0.1787,
        0.2934,
        -0.2903
    ],
        ...,
    [
        0.1699,
        -0.2879,
        0.2038,  ...,
        -0.1787,
        0.2934,
        -0.2903
    ],
    [
        0.1699,
        -0.2879,
        0.2038,  ...,
        -0.1787,
        0.2934,
        -0.2903
    ],
    [
        0.1699,
        -0.2879,
        0.2038,  ...,
        -0.1787,
        0.2934,
        -0.2903
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -315.1172,
    -305.5440,
    -305.5491,
    -319.3639,
    -313.3415,
    -306.0299,
    -300.5627,
    -304.4765,
    -297.3255,
    -307.0558,
    -320.1910,
    -307.1612,
    -297.7386,
    -307.2440,
    -320.0549,
    -308.4847
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -315.1172,
    -305.5440,
    -305.5491,
    -319.3639,
    -313.3415,
    -306.0299,
    -300.5627,
    -304.4765,
    -297.3255,
    -307.0558,
    -320.1910,
    -307.1612,
    -297.7386,
    -307.2440,
    -320.0549,
    -308.4847
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.3094, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1385,
        0.0887,
        -0.0278,  ...,
        -0.0054,
        -0.0539,
        0.0964
    ],
    [
        -0.1447,
        0.0905,
        -0.0276,  ...,
        -0.0035,
        -0.0530,
        0.0961
    ],
    [
        -0.1448,
        0.0913,
        -0.0267,  ...,
        -0.0054,
        -0.0520,
        0.0942
    ],
        ...,
    [
        -0.1389,
        0.0883,
        -0.0260,  ...,
        -0.0048,
        -0.0549,
        0.0952
    ],
    [
        -0.3464,
        0.5998,
        -0.2652,  ...,
        0.1246,
        -0.3953,
        0.4169
    ],
    [
        -0.1416,
        0.0913,
        -0.0293,  ...,
        -0.0050,
        -0.0532,
        0.0992
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -1.3265e-01,
            7.2854e-02,
            -1.4230e-02,  ...,
            -1.3334e-03,
            -5.0851e-02,
            9.0402e-02
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -1.3865e-01,
            7.4203e-02,
            -1.4617e-02,  ...,
            -7.5289e-04,
            -5.0895e-02,
            8.8713e-02
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -1.3755e-01,
            7.4709e-02,
            -1.4573e-02,  ...,
            -2.4701e-03,
            -4.9783e-02,
            8.7547e-02
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],

        ...,
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1808,
        0.2914,
        -0.2833
    ],
    [
        0.1641,
        -0.2721,
        0.1903,  ...,
        -0.1808,
        0.2914,
        -0.2833
    ],
    [
        0.1641,
        -0.2721,
        0.1903,  ...,
        -0.1808,
        0.2914,
        -0.2833
    ],
        ...,
    [
        0.1641,
        -0.2721,
        0.1903,  ...,
        -0.1808,
        0.2914,
        -0.2833
    ],
    [
        0.1641,
        -0.2721,
        0.1903,  ...,
        -0.1808,
        0.2914,
        -0.2833
    ],
    [
        0.1641,
        -0.2721,
        0.1903,  ...,
        -0.1808,
        0.2914,
        -0.2833
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -309.0044,
    -299.5970,
    -299.6339,
    -313.1739,
    -307.2359,
    -300.0606,
    -294.6731,
    -298.5222,
    -291.4801,
    -301.1029,
    -313.8524,
    -301.1865,
    -291.8900,
    -301.2574,
    -313.4741,
    -302.4886
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -309.0044,
    -299.5970,
    -299.6339,
    -313.1739,
    -307.2359,
    -300.0606,
    -294.6731,
    -298.5222,
    -291.4802,
    -301.1029,
    -313.8524,
    -301.1866,
    -291.8900,
    -301.2574,
    -313.4741,
    -302.4886
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.2492, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1462,
        0.1074,
        -0.0448,  ...,
        -0.0093,
        -0.0611,
        0.1028
    ],
    [
        -0.1528,
        0.1108,
        -0.0454,  ...,
        -0.0072,
        -0.0599,
        0.1029
    ],
    [
        -0.1537,
        0.1110,
        -0.0445,  ...,
        -0.0090,
        -0.0600,
        0.1015
    ],
        ...,
    [
        -0.1466,
        0.1072,
        -0.0437,  ...,
        -0.0085,
        -0.0617,
        0.1021
    ],
    [
        -0.3608,
        0.6260,
        -0.2755,  ...,
        0.1349,
        -0.4116,
        0.4360
    ],
    [
        -0.1502,
        0.1111,
        -0.0462,  ...,
        -0.0089,
        -0.0602,
        0.1067
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1385,
            0.0887,
            -0.0278,  ...,
            -0.0054,
            -0.0539,
            0.0964
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1447,
            0.0905,
            -0.0276,  ...,
            -0.0035,
            -0.0530,
            0.0961
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1448,
            0.0913,
            -0.0267,  ...,
            -0.0054,
            -0.0520,
            0.0942
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1847,
        0.2844,
        -0.2758
    ],
    [
        0.1563,
        -0.2534,
        0.1732,  ...,
        -0.1847,
        0.2844,
        -0.2758
    ],
    [
        0.1563,
        -0.2534,
        0.1732,  ...,
        -0.1847,
        0.2844,
        -0.2758
    ],
        ...,
    [
        0.1563,
        -0.2534,
        0.1732,  ...,
        -0.1847,
        0.2844,
        -0.2758
    ],
    [
        0.1563,
        -0.2534,
        0.1732,  ...,
        -0.1847,
        0.2844,
        -0.2758
    ],
    [
        0.1563,
        -0.2534,
        0.1732,  ...,
        -0.1847,
        0.2844,
        -0.2758
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -299.8713,
    -290.7257,
    -290.7822,
    -303.7785,
    -298.1393,
    -291.1624,
    -285.8872,
    -289.6464,
    -282.7572,
    -292.2100,
    -304.3085,
    -292.2590,
    -283.1492,
    -292.3252,
    -303.6862,
    -293.5540
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -299.8713,
    -290.7256,
    -290.7822,
    -303.7785,
    -298.1393,
    -291.1624,
    -285.8872,
    -289.6464,
    -282.7571,
    -292.2101,
    -304.3085,
    -292.2589,
    -283.1492,
    -292.3252,
    -303.6862,
    -293.5540
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.1591, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1565,
        0.1319,
        -0.0632,  ...,
        -0.0093,
        -0.0729,
        0.1081
    ],
    [
        -0.1604,
        0.1348,
        -0.0632,  ...,
        -0.0070,
        -0.0722,
        0.1086
    ],
    [
        -0.1617,
        0.1340,
        -0.0635,  ...,
        -0.0082,
        -0.0726,
        0.1073
    ],
        ...,
    [
        -0.1566,
        0.1315,
        -0.0623,  ...,
        -0.0077,
        -0.0733,
        0.1072
    ],
    [
        -0.3758,
        0.6523,
        -0.2854,  ...,
        0.1451,
        -0.4276,
        0.4559
    ],
    [
        -0.1594,
        0.1351,
        -0.0650,  ...,
        -0.0080,
        -0.0722,
        0.1122
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1462,
            0.1074,
            -0.0448,  ...,
            -0.0093,
            -0.0611,
            0.1028
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1528,
            0.1108,
            -0.0454,  ...,
            -0.0072,
            -0.0599,
            0.1029
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1537,
            0.1110,
            -0.0445,  ...,
            -0.0090,
            -0.0600,
            0.1015
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1838,
        0.2724,
        -0.2703
    ],
    [
        0.1461,
        -0.2289,
        0.1548,  ...,
        -0.1838,
        0.2724,
        -0.2703
    ],
    [
        0.1461,
        -0.2289,
        0.1548,  ...,
        -0.1838,
        0.2724,
        -0.2703
    ],
        ...,
    [
        0.1461,
        -0.2289,
        0.1548,  ...,
        -0.1838,
        0.2724,
        -0.2703
    ],
    [
        0.1461,
        -0.2289,
        0.1548,  ...,
        -0.1838,
        0.2724,
        -0.2703
    ],
    [
        0.1461,
        -0.2289,
        0.1548,  ...,
        -0.1838,
        0.2724,
        -0.2703
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -288.6089,
    -279.7629,
    -279.8278,
    -292.0809,
    -286.9224,
    -280.1957,
    -275.0547,
    -278.7160,
    -272.0033,
    -281.2469,
    -292.4613,
    -281.2567,
    -272.3720,
    -281.3449,
    -291.5948,
    -282.5300
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -288.6089,
    -279.7630,
    -279.8277,
    -292.0808,
    -286.9225,
    -280.1957,
    -275.0547,
    -278.7160,
    -272.0033,
    -281.2469,
    -292.4613,
    -281.2567,
    -272.3719,
    -281.3449,
    -291.5949,
    -282.5300
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(0.0479, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1623,
        0.1544,
        -0.0778,  ...,
        -0.0088,
        -0.0893,
        0.1149
    ],
    [
        -0.1660,
        0.1574,
        -0.0772,  ...,
        -0.0062,
        -0.0897,
        0.1163
    ],
    [
        -0.1671,
        0.1567,
        -0.0776,  ...,
        -0.0071,
        -0.0903,
        0.1152
    ],
        ...,
    [
        -0.1625,
        0.1546,
        -0.0773,  ...,
        -0.0076,
        -0.0892,
        0.1138
    ],
    [
        -0.3905,
        0.6786,
        -0.2953,  ...,
        0.1553,
        -0.4440,
        0.4756
    ],
    [
        -0.1659,
        0.1585,
        -0.0783,  ...,
        -0.0079,
        -0.0892,
        0.1204
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1565,
            0.1319,
            -0.0632,  ...,
            -0.0093,
            -0.0729,
            0.1081
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1604,
            0.1348,
            -0.0632,  ...,
            -0.0070,
            -0.0722,
            0.1086
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1617,
            0.1340,
            -0.0635,  ...,
            -0.0082,
            -0.0726,
            0.1073
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1837,
        0.2554,
        -0.2621
    ],
    [
        0.1402,
        -0.2064,
        0.1403,  ...,
        -0.1837,
        0.2554,
        -0.2621
    ],
    [
        0.1402,
        -0.2064,
        0.1403,  ...,
        -0.1837,
        0.2554,
        -0.2621
    ],
        ...,
    [
        0.1402,
        -0.2064,
        0.1403,  ...,
        -0.1837,
        0.2554,
        -0.2621
    ],
    [
        0.1402,
        -0.2064,
        0.1403,  ...,
        -0.1837,
        0.2554,
        -0.2621
    ],
    [
        0.1402,
        -0.2064,
        0.1403,  ...,
        -0.1837,
        0.2554,
        -0.2621
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -276.9854,
    -268.4741,
    -268.5497,
    -279.9314,
    -275.3457,
    -268.8945,
    -263.9270,
    -267.4766,
    -260.9507,
    -269.9499,
    -280.1628,
    -269.9118,
    -261.3070,
    -270.0393,
    -279.0530,
    -271.1724
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -276.9854,
    -268.4741,
    -268.5497,
    -279.9314,
    -275.3457,
    -268.8945,
    -263.9270,
    -267.4766,
    -260.9507,
    -269.9498,
    -280.1628,
    -269.9118,
    -261.3070,
    -270.0393,
    -279.0530,
    -271.1724
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.0668, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1678,
        0.1773,
        -0.0910,  ...,
        -0.0062,
        -0.1110,
        0.1270
    ],
    [
        -0.1713,
        0.1798,
        -0.0910,  ...,
        -0.0038,
        -0.1119,
        0.1296
    ],
    [
        -0.1717,
        0.1797,
        -0.0910,  ...,
        -0.0041,
        -0.1128,
        0.1291
    ],
        ...,
    [
        -0.1679,
        0.1777,
        -0.0904,  ...,
        -0.0046,
        -0.1103,
        0.1262
    ],
    [
        -0.4053,
        0.7049,
        -0.3053,  ...,
        0.1658,
        -0.4605,
        0.4954
    ],
    [
        -0.1718,
        0.1818,
        -0.0915,  ...,
        -0.0052,
        -0.1117,
        0.1332
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1623,
            0.1544,
            -0.0778,  ...,
            -0.0088,
            -0.0893,
            0.1149
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1660,
            0.1574,
            -0.0772,  ...,
            -0.0062,
            -0.0897,
            0.1163
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1671,
            0.1567,
            -0.0776,  ...,
            -0.0071,
            -0.0903,
            0.1152
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1810,
        0.2329,
        -0.2493
    ],
    [
        0.1347,
        -0.1835,
        0.1270,  ...,
        -0.1810,
        0.2329,
        -0.2493
    ],
    [
        0.1347,
        -0.1835,
        0.1270,  ...,
        -0.1810,
        0.2329,
        -0.2493
    ],
        ...,
    [
        0.1347,
        -0.1835,
        0.1270,  ...,
        -0.1810,
        0.2329,
        -0.2493
    ],
    [
        0.1347,
        -0.1835,
        0.1270,  ...,
        -0.1810,
        0.2329,
        -0.2493
    ],
    [
        0.1347,
        -0.1835,
        0.1270,  ...,
        -0.1810,
        0.2329,
        -0.2493
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -265.4312,
    -257.2857,
    -257.3694,
    -267.7742,
    -263.8416,
    -257.6862,
    -252.9218,
    -256.3306,
    -250.0271,
    -258.7483,
    -267.8568,
    -258.6726,
    -250.3618,
    -258.8289,
    -266.5017,
    -259.9001
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -265.4312,
    -257.2857,
    -257.3694,
    -267.7742,
    -263.8416,
    -257.6862,
    -252.9218,
    -256.3306,
    -250.0271,
    -258.7482,
    -267.8568,
    -258.6726,
    -250.3618,
    -258.8289,
    -266.5017,
    -259.9001
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.1806, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -1.7417e-01,
        2.0099e-01,
        -1.0307e-01,  ...,
        -1.7621e-03,
        -1.3115e-01,
        1.4251e-01
    ],
    [
        -1.7771e-01,
        2.0429e-01,
        -1.0306e-01,  ...,
        -7.2828e-05,
        -1.3368e-01,
        1.4669e-01
    ],
    [
        -1.7746e-01,
        2.0399e-01,
        -1.0248e-01,  ...,
        3.3962e-05,
        -1.3359e-01,
        1.4483e-01
    ],
        ...,
    [
        -1.7481e-01,
        2.0210e-01,
        -1.0186e-01,  ...,
        -9.0814e-04,
        -1.3019e-01,
        1.4364e-01
    ],
    [
        -4.2030e-01,
        7.3123e-01,
        -3.1482e-01,  ...,
        1.7575e-01,
        -4.7689e-01,
        5.1510e-01
    ],
    [
        -1.7822e-01,
        2.0652e-01,
        -1.0250e-01,  ...,
        -1.4067e-03,
        -1.3242e-01,
        1.5015e-01
    ]
], device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1678,
            0.1773,
            -0.0910,  ...,
            -0.0062,
            -0.1110,
            0.1270
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1713,
            0.1798,
            -0.0910,  ...,
            -0.0038,
            -0.1119,
            0.1296
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1717,
            0.1797,
            -0.0910,  ...,
            -0.0041,
            -0.1128,
            0.1291
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1772,
        0.2122,
        -0.2324
    ],
    [
        0.1283,
        -0.1598,
        0.1150,  ...,
        -0.1772,
        0.2122,
        -0.2324
    ],
    [
        0.1283,
        -0.1598,
        0.1150,  ...,
        -0.1772,
        0.2122,
        -0.2324
    ],
        ...,
    [
        0.1283,
        -0.1598,
        0.1150,  ...,
        -0.1772,
        0.2122,
        -0.2324
    ],
    [
        0.1283,
        -0.1598,
        0.1150,  ...,
        -0.1772,
        0.2122,
        -0.2324
    ],
    [
        0.1283,
        -0.1598,
        0.1150,  ...,
        -0.1772,
        0.2122,
        -0.2324
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -254.3143,
    -246.5741,
    -246.6529,
    -255.9981,
    -252.7843,
    -246.9515,
    -242.4113,
    -245.6593,
    -239.5855,
    -248.0091,
    -255.9306,
    -247.9039,
    -239.9129,
    -248.0895,
    -254.3309,
    -249.0877
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -254.3143,
    -246.5741,
    -246.6529,
    -255.9981,
    -252.7843,
    -246.9516,
    -242.4113,
    -245.6593,
    -239.5855,
    -248.0092,
    -255.9305,
    -247.9039,
    -239.9129,
    -248.0895,
    -254.3309,
    -249.0877
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.2900, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1807,
        0.2272,
        -0.1161,  ...,
        0.0026,
        -0.1512,
        0.1593
    ],
    [
        -0.1847,
        0.2303,
        -0.1160,  ...,
        0.0038,
        -0.1537,
        0.1644
    ],
    [
        -0.1843,
        0.2297,
        -0.1153,  ...,
        0.0046,
        -0.1531,
        0.1619
    ],
        ...,
    [
        -0.1824,
        0.2274,
        -0.1144,  ...,
        0.0038,
        -0.1495,
        0.1605
    ],
    [
        -0.4353,
        0.7573,
        -0.3246,  ...,
        0.1860,
        -0.4935,
        0.5349
    ],
    [
        -0.1853,
        0.2325,
        -0.1152,  ...,
        0.0035,
        -0.1520,
        0.1670
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -1.7417e-01,
            2.0099e-01,
            -1.0307e-01,  ...,
            -1.7621e-03,
            -1.3115e-01,
            1.4251e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -1.7771e-01,
            2.0429e-01,
            -1.0306e-01,  ...,
            -7.2828e-05,
            -1.3368e-01,
            1.4669e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -1.7746e-01,
            2.0399e-01,
            -1.0248e-01,  ...,
            3.3962e-05,
            -1.3359e-01,
            1.4483e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],

        ...,
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ],
    [
        [
            -3.0251e-01,
            3.6080e-01,
            -2.1803e-01,  ...,
            2.9623e-01,
            -3.1522e-01,
            5.2889e-01
        ],
        [
            -4.0060e-01,
            6.8595e-01,
            -2.3028e-01,  ...,
            2.4168e-01,
            -5.2283e-01,
            8.3433e-01
        ],
        [
            -4.7936e-01,
            5.3881e-01,
            -3.0691e-01,  ...,
            2.7498e-01,
            -4.4059e-01,
            7.9998e-01
        ],
         ...,
        [
            -1.8946e-01,
            2.2664e-01,
            -6.7961e-02,  ...,
            6.8395e-02,
            -2.8867e-01,
            3.2113e-01
        ],
        [
            -3.2412e-01,
            2.1725e-01,
            -1.7222e-01,  ...,
            1.4393e-01,
            -2.8550e-01,
            3.2710e-01
        ],
        [
            -2.5420e-01,
            1.9838e-01,
            -6.7567e-02,  ...,
            1.7580e-01,
            -3.4462e-01,
            3.8251e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1723,
        0.1926,
        -0.2155
    ],
    [
        0.1218,
        -0.1336,
        0.1019,  ...,
        -0.1723,
        0.1926,
        -0.2155
    ],
    [
        0.1218,
        -0.1336,
        0.1019,  ...,
        -0.1723,
        0.1926,
        -0.2155
    ],
        ...,
    [
        0.1218,
        -0.1336,
        0.1019,  ...,
        -0.1723,
        0.1926,
        -0.2155
    ],
    [
        0.1218,
        -0.1336,
        0.1019,  ...,
        -0.1723,
        0.1926,
        -0.2155
    ],
    [
        0.1218,
        -0.1336,
        0.1019,  ...,
        -0.1723,
        0.1926,
        -0.2155
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -244.1965,
    -236.8831,
    -236.9509,
    -245.1767,
    -242.7273,
    -237.2356,
    -232.9270,
    -236.0133,
    -230.1747,
    -238.2844,
    -244.9591,
    -238.1502,
    -230.5028,
    -238.3633,
    -243.1163,
    -239.2868
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -244.1965,
    -236.8831,
    -236.9509,
    -245.1767,
    -242.7273,
    -237.2356,
    -232.9270,
    -236.0133,
    -230.1747,
    -238.2844,
    -244.9591,
    -238.1502,
    -230.5028,
    -238.3633,
    -243.1163,
    -239.2868
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.3893, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1890,
        0.2540,
        -0.1288,  ...,
        0.0080,
        -0.1699,
        0.1758
    ],
    [
        -0.1926,
        0.2568,
        -0.1281,  ...,
        0.0100,
        -0.1730,
        0.1816
    ],
    [
        -0.1921,
        0.2562,
        -0.1275,  ...,
        0.0109,
        -0.1718,
        0.1791
    ],
        ...,
    [
        -0.1905,
        0.2539,
        -0.1265,  ...,
        0.0095,
        -0.1685,
        0.1776
    ],
    [
        -0.4501,
        0.7835,
        -0.3342,  ...,
        0.1963,
        -0.5104,
        0.5547
    ],
    [
        -0.1930,
        0.2588,
        -0.1272,  ...,
        0.0096,
        -0.1709,
        0.1834
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1807,
            0.2272,
            -0.1161,  ...,
            0.0026,
            -0.1512,
            0.1593
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1847,
            0.2303,
            -0.1160,  ...,
            0.0038,
            -0.1537,
            0.1644
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1843,
            0.2297,
            -0.1153,  ...,
            0.0046,
            -0.1531,
            0.1619
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1662,
        0.1738,
        -0.1991
    ],
    [
        0.1135,
        -0.1068,
        0.0892,  ...,
        -0.1662,
        0.1738,
        -0.1991
    ],
    [
        0.1135,
        -0.1068,
        0.0892,  ...,
        -0.1662,
        0.1738,
        -0.1991
    ],
        ...,
    [
        0.1135,
        -0.1068,
        0.0892,  ...,
        -0.1662,
        0.1738,
        -0.1991
    ],
    [
        0.1135,
        -0.1068,
        0.0892,  ...,
        -0.1662,
        0.1738,
        -0.1991
    ],
    [
        0.1135,
        -0.1068,
        0.0892,  ...,
        -0.1662,
        0.1738,
        -0.1991
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -235.3874,
    -228.5078,
    -228.5772,
    -235.6204,
    -233.9811,
    -228.8335,
    -224.7671,
    -227.6886,
    -222.0929,
    -229.8794,
    -235.2553,
    -229.7150,
    -222.4185,
    -229.9648,
    -233.1650,
    -230.7981
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -235.3874,
    -228.5078,
    -228.5772,
    -235.6204,
    -233.9810,
    -228.8335,
    -224.7671,
    -227.6886,
    -222.0929,
    -229.8794,
    -235.2553,
    -229.7150,
    -222.4185,
    -229.9648,
    -233.1650,
    -230.7981
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.4755, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1974,
        0.2809,
        -0.1407,  ...,
        0.0140,
        -0.1886,
        0.1927
    ],
    [
        -0.2002,
        0.2836,
        -0.1401,  ...,
        0.0168,
        -0.1913,
        0.1989
    ],
    [
        -0.2001,
        0.2830,
        -0.1393,  ...,
        0.0177,
        -0.1905,
        0.1970
    ],
        ...,
    [
        -0.1986,
        0.2806,
        -0.1383,  ...,
        0.0160,
        -0.1877,
        0.1949
    ],
    [
        -0.4649,
        0.8101,
        -0.3442,  ...,
        0.2060,
        -0.5274,
        0.5746
    ],
    [
        -0.2014,
        0.2853,
        -0.1387,  ...,
        0.0161,
        -0.1898,
        0.2008
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1890,
            0.2540,
            -0.1288,  ...,
            0.0080,
            -0.1699,
            0.1758
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.1926,
            0.2568,
            -0.1281,  ...,
            0.0100,
            -0.1730,
            0.1816
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.1921,
            0.2562,
            -0.1275,  ...,
            0.0109,
            -0.1718,
            0.1791
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1597,
        0.1548,
        -0.1817
    ],
    [
        0.1051,
        -0.0799,
        0.0773,  ...,
        -0.1597,
        0.1548,
        -0.1817
    ],
    [
        0.1051,
        -0.0799,
        0.0773,  ...,
        -0.1597,
        0.1548,
        -0.1817
    ],
        ...,
    [
        0.1051,
        -0.0799,
        0.0773,  ...,
        -0.1597,
        0.1548,
        -0.1817
    ],
    [
        0.1051,
        -0.0799,
        0.0773,  ...,
        -0.1597,
        0.1548,
        -0.1817
    ],
    [
        0.1051,
        -0.0799,
        0.0773,  ...,
        -0.1597,
        0.1548,
        -0.1817
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -228.1280,
    -221.6889,
    -221.7619,
    -227.5844,
    -226.7871,
    -221.9899,
    -218.1714,
    -220.9250,
    -215.5726,
    -223.0334,
    -227.0698,
    -222.8300,
    -215.8929,
    -223.1167,
    -224.7355,
    -223.8681
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -228.1280,
    -221.6889,
    -221.7619,
    -227.5844,
    -226.7871,
    -221.9900,
    -218.1714,
    -220.9250,
    -215.5726,
    -223.0334,
    -227.0699,
    -222.8300,
    -215.8929,
    -223.1167,
    -224.7355,
    -223.8681
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.5463, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.2067,
        0.3076,
        -0.1524,  ...,
        0.0221,
        -0.2064,
        0.2107
    ],
    [
        -0.2090,
        0.3103,
        -0.1522,  ...,
        0.0245,
        -0.2093,
        0.2168
    ],
    [
        -0.2094,
        0.3100,
        -0.1510,  ...,
        0.0257,
        -0.2084,
        0.2152
    ],
        ...,
    [
        -0.2075,
        0.3074,
        -0.1498,  ...,
        0.0237,
        -0.2059,
        0.2125
    ],
    [
        -0.4794,
        0.8365,
        -0.3541,  ...,
        0.2163,
        -0.5444,
        0.5941
    ],
    [
        -0.2106,
        0.3123,
        -0.1501,  ...,
        0.0239,
        -0.2080,
        0.2189
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1974,
            0.2809,
            -0.1407,  ...,
            0.0140,
            -0.1886,
            0.1927
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.2002,
            0.2836,
            -0.1401,  ...,
            0.0168,
            -0.1913,
            0.1989
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.2001,
            0.2830,
            -0.1393,  ...,
            0.0177,
            -0.1905,
            0.1970
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1519,
        0.1366,
        -0.1636
    ],
    [
        0.0958,
        -0.0532,
        0.0657,  ...,
        -0.1519,
        0.1366,
        -0.1636
    ],
    [
        0.0958,
        -0.0532,
        0.0657,  ...,
        -0.1519,
        0.1366,
        -0.1636
    ],
        ...,
    [
        0.0958,
        -0.0532,
        0.0657,  ...,
        -0.1519,
        0.1366,
        -0.1636
    ],
    [
        0.0958,
        -0.0532,
        0.0657,  ...,
        -0.1519,
        0.1366,
        -0.1636
    ],
    [
        0.0958,
        -0.0532,
        0.0657,  ...,
        -0.1519,
        0.1366,
        -0.1636
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -222.3916,
    -216.4064,
    -216.4769,
    -221.0444,
    -221.1182,
    -216.6789,
    -213.1076,
    -215.6948,
    -210.5913,
    -217.7148,
    -220.3809,
    -217.4761,
    -210.9089,
    -217.7966,
    -217.7994,
    -218.4677
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -222.3916,
    -216.4064,
    -216.4769,
    -221.0444,
    -221.1182,
    -216.6789,
    -213.1076,
    -215.6948,
    -210.5913,
    -217.7148,
    -220.3809,
    -217.4761,
    -210.9089,
    -217.7966,
    -217.7994,
    -218.4677
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.6018, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.2175,
        0.3333,
        -0.1637,  ...,
        0.0314,
        -0.2243,
        0.2291
    ],
    [
        -0.2193,
        0.3364,
        -0.1639,  ...,
        0.0333,
        -0.2275,
        0.2347
    ],
    [
        -0.2199,
        0.3362,
        -0.1624,  ...,
        0.0347,
        -0.2261,
        0.2335
    ],
        ...,
    [
        -0.2179,
        0.3332,
        -0.1614,  ...,
        0.0326,
        -0.2240,
        0.2308
    ],
    [
        -0.4940,
        0.8629,
        -0.3642,  ...,
        0.2265,
        -0.5611,
        0.6138
    ],
    [
        -0.2208,
        0.3386,
        -0.1614,  ...,
        0.0329,
        -0.2261,
        0.2374
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.2067,
            0.3076,
            -0.1524,  ...,
            0.0221,
            -0.2064,
            0.2107
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.2090,
            0.3103,
            -0.1522,  ...,
            0.0245,
            -0.2093,
            0.2168
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.2094,
            0.3100,
            -0.1510,  ...,
            0.0257,
            -0.2084,
            0.2152
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],

        ...,
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ],
    [
        [
            -0.3025,
            0.3608,
            -0.2180,  ...,
            0.2962,
            -0.3152,
            0.5289
        ],
        [
            -0.4006,
            0.6860,
            -0.2303,  ...,
            0.2417,
            -0.5228,
            0.8343
        ],
        [
            -0.4794,
            0.5388,
            -0.3069,  ...,
            0.2750,
            -0.4406,
            0.8000
        ],
         ...,
        [
            -0.1895,
            0.2266,
            -0.0680,  ...,
            0.0684,
            -0.2887,
            0.3211
        ],
        [
            -0.3241,
            0.2173,
            -0.1722,  ...,
            0.1439,
            -0.2855,
            0.3271
        ],
        [
            -0.2542,
            0.1984,
            -0.0676,  ...,
            0.1758,
            -0.3446,
            0.3825
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1429,
        0.1186,
        -0.1451
    ],
    [
        0.0850,
        -0.0275,
        0.0543,  ...,
        -0.1429,
        0.1186,
        -0.1451
    ],
    [
        0.0850,
        -0.0275,
        0.0543,  ...,
        -0.1429,
        0.1186,
        -0.1451
    ],
        ...,
    [
        0.0850,
        -0.0275,
        0.0543,  ...,
        -0.1429,
        0.1186,
        -0.1451
    ],
    [
        0.0850,
        -0.0275,
        0.0543,  ...,
        -0.1429,
        0.1186,
        -0.1451
    ],
    [
        0.0850,
        -0.0275,
        0.0543,  ...,
        -0.1429,
        0.1186,
        -0.1451
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -218.3720,
    -212.8475,
    -212.9181,
    -216.2039,
    -217.1727,
    -213.0936,
    -209.7719,
    -212.1897,
    -207.3412,
    -214.1239,
    -215.3897,
    -213.8486,
    -207.6557,
    -214.1997,
    -212.5628,
    -214.7891
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -218.3720,
    -212.8475,
    -212.9181,
    -216.2039,
    -217.1727,
    -213.0936,
    -209.7718,
    -212.1897,
    -207.3411,
    -214.1239,
    -215.3897,
    -213.8486,
    -207.6557,
    -214.1997,
    -212.5628,
    -214.7891
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(-0.6402, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [
                -19.5837,
                -20.7014,
                -19.9932,  ...,
                -20.2054,
                -20.0793,
                -19.8509
            ],
            [
                -20.6802,
                -19.3398,
                -19.3525,  ...,
                -19.7669,
                -20.1599,
                -20.8882
            ],
            [
                -20.7170,
                -19.5836,
                -20.7501,  ...,
                -20.3881,
                -19.6563,
                -20.6709
            ],
          ...,
            [
                -20.4788,
                -20.7013,
                -19.9893,  ...,
                -19.1794,
                -20.1006,
                -19.4656
            ],
            [
                -20.3047,
                -19.8012,
                -20.2869,  ...,
                -19.1691,
                -19.2537,
                -20.9259
            ],
            [
                -19.5566,
                -20.1642,
                -20.2840,  ...,
                -20.1748,
                -19.4651,
                -20.8053
            ]
        ],
        [
            [
                -19.9529,
                -20.5114,
                -19.2668,  ...,
                -20.3308,
                -20.5272,
                -19.9889
            ],
            [
                -19.0879,
                -19.7784,
                -20.7529,  ...,
                -20.0630,
                -18.9801,
                -20.8585
            ],
            [
                -20.9308,
                -20.6373,
                -19.7826,  ...,
                -19.9279,
                -20.2491,
                -19.0363
            ],
          ...,
            [
                -20.2171,
                -19.7395,
                -20.8983,  ...,
                -20.1041,
                -20.3188,
                -20.6505
            ],
            [
                -19.1660,
                -19.4029,
                -19.3988,  ...,
                -19.2888,
                -20.0106,
                -19.3674
            ],
            [
                -20.0790,
                -19.6421,
                -19.3754,  ...,
                -20.9232,
                -19.2657,
                -19.2735
            ]
        ],
        [
            [
                -20.5074,
                -20.2091,
                -20.5566,  ...,
                -20.9326,
                -19.8878,
                -19.1729
            ],
            [
                -20.1966,
                -19.7751,
                -20.6599,  ...,
                -20.2885,
                -20.6329,
                -20.3281
            ],
            [
                -19.8642,
                -19.1352,
                -20.1143,  ...,
                -20.6619,
                -20.3839,
                -20.4643
            ],
          ...,
            [
                -19.0128,
                -19.4128,
                -20.0854,  ...,
                -19.6253,
                -19.4140,
                -20.5015
            ],
            [
                -19.4157,
                -20.8543,
                -19.4688,  ...,
                -19.5579,
                -19.7439,
                -20.2552
            ],
            [
                -20.7119,
                -19.7722,
                -19.9324,  ...,
                -20.0513,
                -20.0979,
                -20.1128
            ]
        ]
    ],
    [
        [
            [
                -20.3512,
                -19.4388,
                -20.2236,  ...,
                -19.3066,
                -19.3271,
                -20.5825
            ],
            [
                -19.4578,
                -20.8797,
                -19.1580,  ...,
                -20.6483,
                -20.9363,
                -20.7298
            ],
            [
                -19.1412,
                -19.4348,
                -21.0180,  ...,
                -20.7815,
                -19.7409,
                -20.4052
            ],
          ...,
            [
                -20.5671,
                -20.2822,
                -20.8299,  ...,
                -20.0302,
                -20.7370,
                -20.7583
            ],
            [
                -20.1347,
                -19.0819,
                -20.6400,  ...,
                -20.3179,
                -19.9639,
                -20.7699
            ],
            [
                -19.9965,
                -19.8639,
                -20.8311,  ...,
                -19.9509,
                -19.9943,
                -18.9882
            ]
        ],
        [
            [
                -20.9590,
                -19.4118,
                -20.4461,  ...,
                -20.1758,
                -20.0278,
                -19.7861
            ],
            [
                -20.2353,
                -20.9052,
                -19.8263,  ...,
                -19.8713,
                -18.9893,
                -19.6097
            ],
            [
                -19.6284,
                -20.9930,
                -20.3273,  ...,
                -20.6121,
                -20.1909,
                -20.7386
            ],
          ...,
            [
                -20.8391,
                -20.1090,
                -19.2430,  ...,
                -20.5317,
                -19.4589,
                -20.6431
            ],
            [
                -20.7376,
                -19.1209,
                -19.5503,  ...,
                -19.4035,
                -19.1141,
                -19.8028
            ],
            [
                -20.0901,
                -19.5548,
                -19.8222,  ...,
                -19.0876,
                -20.1831,
                -19.9783
            ]
        ],
        [
            [
                -20.0497,
                -19.1276,
                -20.5052,  ...,
                -19.5775,
                -20.1657,
                -20.0127
            ],
            [
                -19.9125,
                -19.2730,
                -18.9002,  ...,
                -20.1443,
                -19.8871,
                -20.2878
            ],
            [
                -19.9846,
                -19.2029,
                -19.0548,  ...,
                -20.6393,
                -19.6775,
                -19.7601
            ],
          ...,
            [
                -20.9835,
                -20.8109,
                -19.5401,  ...,
                -20.3336,
                -20.2436,
                -19.8997
            ],
            [
                -20.7382,
                -20.0291,
                -20.3943,  ...,
                -20.0264,
                -20.6704,
                -20.7790
            ],
            [
                -20.9225,
                -20.0603,
                -20.5941,  ...,
                -18.9953,
                -19.7472,
                -20.0495
            ]
        ]
    ],
    [
        [
            [
                -19.8420,
                -20.1722,
                -19.4978,  ...,
                -19.0855,
                -19.5810,
                -20.3975
            ],
            [
                -19.3880,
                -20.8100,
                -19.1347,  ...,
                -20.4277,
                -19.2347,
                -20.1840
            ],
            [
                -20.2496,
                -19.5196,
                -20.0250,  ...,
                -20.4947,
                -20.0236,
                -20.5608
            ],
          ...,
            [
                -20.1071,
                -19.3222,
                -19.3606,  ...,
                -19.6003,
                -19.8498,
                -18.9927
            ],
            [
                -19.3054,
                -20.6703,
                -19.8612,  ...,
                -20.8245,
                -20.5511,
                -18.9310
            ],
            [
                -19.5423,
                -19.5263,
                -19.5762,  ...,
                -20.3099,
                -19.7805,
                -19.0506
            ]
        ],
        [
            [
                -20.6019,
                -20.2693,
                -20.2967,  ...,
                -20.5157,
                -19.0615,
                -19.9693
            ],
            [
                -19.1989,
                -20.5624,
                -19.5174,  ...,
                -20.5224,
                -19.2717,
                -19.4458
            ],
            [
                -20.0236,
                -20.0489,
                -20.2189,  ...,
                -20.8108,
                -20.0744,
                -20.3493
            ],
          ...,
            [
                -20.3697,
                -19.6531,
                -20.5533,  ...,
                -20.4498,
                -19.4527,
                -19.6263
            ],
            [
                -20.8114,
                -20.0787,
                -20.4512,  ...,
                -20.6570,
                -20.8703,
                -19.7971
            ],
            [
                -20.4536,
                -20.6747,
                -20.6522,  ...,
                -20.7681,
                -20.2065,
                -20.4493
            ]
        ],
        [
            [
                -20.1302,
                -19.9304,
                -20.4067,  ...,
                -19.9701,
                -20.0329,
                -19.2769
            ],
            [
                -19.7910,
                -19.3725,
                -19.1873,  ...,
                -19.0713,
                -19.5383,
                -19.9495
            ],
            [
                -18.9797,
                -19.7854,
                -20.9527,  ...,
                -19.9487,
                -19.0831,
                -20.3818
            ],
          ...,
            [
                -20.6960,
                -19.5958,
                -20.7914,  ...,
                -20.5519,
                -20.3158,
                -19.2577
            ],
            [
                -19.5049,
                -20.5100,
                -19.0747,  ...,
                -19.7013,
                -19.7708,
                -20.5841
            ],
            [
                -20.3602,
                -19.8112,
                -20.4915,  ...,
                -19.9154,
                -20.2812,
                -20.2512
            ]
        ]
    ],


        ...,
    [
        [
            [
                -20.0386,
                -19.6860,
                -20.9796,  ...,
                -19.0320,
                -19.2437,
                -19.7529
            ],
            [
                -20.1463,
                -19.6160,
                -20.4549,  ...,
                -20.1160,
                -19.5779,
                -20.0441
            ],
            [
                -20.7615,
                -19.7772,
                -19.0736,  ...,
                -19.8665,
                -19.7311,
                -20.4414
            ],
          ...,
            [
                -20.8799,
                -20.7395,
                -20.6173,  ...,
                -20.4670,
                -20.1663,
                -20.6782
            ],
            [
                -20.6707,
                -19.4219,
                -20.1811,  ...,
                -20.8566,
                -19.1048,
                -19.7931
            ],
            [
                -20.1002,
                -19.2876,
                -19.2825,  ...,
                -19.3149,
                -20.5551,
                -20.4893
            ]
        ],
        [
            [
                -20.6190,
                -19.4419,
                -20.6436,  ...,
                -20.1254,
                -19.0093,
                -20.8731
            ],
            [
                -19.2225,
                -20.4402,
                -20.8198,  ...,
                -20.4450,
                -19.9054,
                -20.0762
            ],
            [
                -20.3611,
                -19.3342,
                -19.4027,  ...,
                -19.1662,
                -20.3431,
                -19.2626
            ],
          ...,
            [
                -20.5023,
                -19.9099,
                -20.1123,  ...,
                -19.6647,
                -20.9732,
                -20.0420
            ],
            [
                -19.7394,
                -19.8239,
                -20.4652,  ...,
                -20.2430,
                -20.9473,
                -20.9332
            ],
            [
                -19.9160,
                -19.0519,
                -19.9257,  ...,
                -20.6992,
                -20.3788,
                -19.2826
            ]
        ],
        [
            [
                -20.3792,
                -20.5434,
                -19.4980,  ...,
                -19.0345,
                -20.7050,
                -20.5555
            ],
            [
                -19.2222,
                -18.9900,
                -19.9522,  ...,
                -19.2485,
                -20.1892,
                -19.6740
            ],
            [
                -19.0775,
                -19.8646,
                -19.2736,  ...,
                -19.9458,
                -19.8118,
                -20.4515
            ],
          ...,
            [
                -20.2313,
                -19.7465,
                -19.7808,  ...,
                -19.2551,
                -19.6028,
                -19.9102
            ],
            [
                -19.1011,
                -19.6142,
                -19.7667,  ...,
                -19.5864,
                -20.7817,
                -19.2528
            ],
            [
                -20.8494,
                -19.4367,
                -20.5385,  ...,
                -19.3499,
                -20.6338,
                -20.2409
            ]
        ]
    ],
    [
        [
            [
                -39.2199,
                -39.2294,
                -39.8750,  ...,
                -40.1137,
                -39.1660,
                -39.6854
            ],
            [
                -39.3851,
                -40.0890,
                -39.8489,  ...,
                -40.0833,
                -39.9554,
                -39.3936
            ],
            [
                -40.7823,
                -39.7391,
                -40.2975,  ...,
                -40.1073,
                -40.3012,
                -39.1933
            ],
          ...,
            [
                -40.4848,
                -40.1631,
                -40.9977,  ...,
                -39.1784,
                -40.0383,
                -40.6479
            ],
            [
                -39.9738,
                -40.0796,
                -40.8869,  ...,
                -40.7711,
                -39.4378,
                -39.0319
            ],
            [
                -39.3153,
                -40.3153,
                -40.5174,  ...,
                -39.3274,
                -40.3599,
                -39.1175
            ]
        ],
        [
            [
                -40.7137,
                -40.2519,
                -40.7094,  ...,
                -39.1603,
                -40.1649,
                -40.0776
            ],
            [
                -39.9007,
                -39.3593,
                -40.0312,  ...,
                -40.7314,
                -39.3362,
                -40.7913
            ],
            [
                -40.9649,
                -39.1317,
                -40.4323,  ...,
                -40.8759,
                -39.6775,
                -39.3427
            ],
          ...,
            [
                -39.5161,
                -40.7278,
                -40.5861,  ...,
                -40.3319,
                -39.6903,
                -39.1190
            ],
            [
                -39.2726,
                -39.0035,
                -40.3479,  ...,
                -39.0502,
                -40.4411,
                -39.8297
            ],
            [
                -39.9160,
                -40.0842,
                -40.2350,  ...,
                -40.9410,
                -39.4410,
                -39.5026
            ]
        ],
        [
            [
                -40.1279,
                -39.7745,
                -40.6978,  ...,
                -39.3393,
                -40.7017,
                -40.0701
            ],
            [
                -39.0214,
                -40.3622,
                -40.1534,  ...,
                -39.3718,
                -40.3566,
                -40.2879
            ],
            [
                -40.1449,
                -40.9744,
                -40.6081,  ...,
                -40.5182,
                -39.6787,
                -40.3610
            ],
          ...,
            [
                -39.2967,
                -39.3122,
                -39.0419,  ...,
                -40.8081,
                -39.7233,
                -40.6100
            ],
            [
                -40.0736,
                -40.4842,
                -40.4252,  ...,
                -38.9416,
                -40.2002,
                -40.8578
            ],
            [
                -39.7389,
                -39.8918,
                -39.2981,  ...,
                -40.5930,
                -40.5466,
                -39.7356
            ]
        ]
    ],
    [
        [
            [
                -20.5348,
                -19.7157,
                -20.0750,  ...,
                -19.6628,
                -19.8741,
                -20.8939
            ],
            [
                -19.8265,
                -20.9413,
                -19.8561,  ...,
                -19.8328,
                -19.7504,
                -20.4022
            ],
            [
                -19.2272,
                -20.1703,
                -20.3748,  ...,
                -19.2578,
                -19.9768,
                -20.7528
            ],
          ...,
            [
                -20.2417,
                -20.7232,
                -20.9015,  ...,
                -20.5345,
                -20.0932,
                -20.7384
            ],
            [
                -20.8899,
                -19.5796,
                -19.1709,  ...,
                -19.8400,
                -21.0122,
                -19.5476
            ],
            [
                -19.7232,
                -20.7094,
                -20.2667,  ...,
                -20.5258,
                -20.0918,
                -20.6710
            ]
        ],
        [
            [
                -19.2948,
                -20.2143,
                -19.3253,  ...,
                -20.9017,
                -20.8086,
                -20.9754
            ],
            [
                -19.7598,
                -20.7140,
                -18.9802,  ...,
                -19.9680,
                -19.2926,
                -19.4770
            ],
            [
                -19.0555,
                -20.7850,
                -20.7350,  ...,
                -20.1535,
                -20.1082,
                -19.1444
            ],
          ...,
            [
                -20.9136,
                -20.2111,
                -20.9209,  ...,
                -19.7235,
                -20.9185,
                -19.3757
            ],
            [
                -20.0663,
                -20.9107,
                -20.3386,  ...,
                -20.6575,
                -20.4203,
                -19.6241
            ],
            [
                -19.2119,
                -20.1336,
                -19.7758,  ...,
                -19.9120,
                -20.8620,
                -19.3562
            ]
        ],
        [
            [
                -20.2868,
                -20.7790,
                -20.6482,  ...,
                -20.2953,
                -20.5568,
                -20.9187
            ],
            [
                -20.8792,
                -19.1550,
                -20.6630,  ...,
                -20.3608,
                -19.1498,
                -19.8051
            ],
            [
                -19.7272,
                -19.2722,
                -20.1992,  ...,
                -19.4458,
                -20.2484,
                -20.3998
            ],
          ...,
            [
                -20.8154,
                -19.8327,
                -20.7142,  ...,
                -19.3446,
                -19.5328,
                -19.7312
            ],
            [
                -20.9742,
                -19.0501,
                -20.1143,  ...,
                -20.0278,
                -20.5736,
                -19.0640
            ],
            [
                -20.3958,
                -20.0589,
                -19.9003,  ...,
                -20.6513,
                -20.5419,
                -19.2929
            ]
        ]
    ]
],
       device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1310,
        -0.0879,
        0.3400
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1310,
        -0.0879,
        0.3400
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1310,
        -0.0879,
        0.3400
    ],
        ...,
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1310,
        -0.0879,
        0.3400
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1310,
        -0.0879,
        0.3400
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1310,
        -0.0879,
        0.3400
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
tensor([
    [
        -0.5231,
        0.6024,
        -0.3405,  ...,
        0.3028,
        -0.4471,
        0.8164
    ],
    [
        -0.4091,
        0.5387,
        -0.3142,  ...,
        0.3309,
        -0.5072,
        0.7923
    ],
    [
        -0.3352,
        0.5804,
        -0.3174,  ...,
        0.2764,
        -0.4961,
        0.7611
    ],
        ...,
    [
        -0.4234,
        0.5638,
        -0.3201,  ...,
        0.2935,
        -0.5201,
        0.7362
    ],
    [
        -0.4849,
        0.5290,
        -0.3211,  ...,
        0.3607,
        -0.4543,
        0.8097
    ],
    [
        -0.4796,
        0.5710,
        -0.3187,  ...,
        0.2864,
        -0.4909,
        0.8242
    ]
],
       device='cuda: 0', grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1106,
        -0.1462,
        0.4417
    ],
    [
        -0.2206,
        0.2416,
        -0.1225,  ...,
        0.1106,
        -0.1462,
        0.4417
    ],
    [
        -0.2206,
        0.2416,
        -0.1225,  ...,
        0.1106,
        -0.1462,
        0.4417
    ],
        ...,
    [
        -0.2206,
        0.2416,
        -0.1225,  ...,
        0.1106,
        -0.1462,
        0.4417
    ],
    [
        -0.2206,
        0.2416,
        -0.1225,  ...,
        0.1106,
        -0.1462,
        0.4417
    ],
    [
        -0.2206,
        0.2416,
        -0.1225,  ...,
        0.1106,
        -0.1462,
        0.4417
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(3.5399, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(-0.0145, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 3/3125 [
    00: 24<6: 57: 03,
    8.02s/it, loss=2.33, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [
        -0.3652,
        0.5190,
        -0.1685,  ...,
        0.1180,
        -0.3914,
        0.5498
    ],
    [
        -0.1095,
        0.1323,
        -0.0539,  ...,
        0.0074,
        -0.1209,
        0.1565
    ],
    [
        -0.1130,
        0.1338,
        -0.0549,  ...,
        0.0047,
        -0.1232,
        0.1616
    ],
        ...,
    [
        -0.3672,
        0.5207,
        -0.1672,  ...,
        0.1187,
        -0.3905,
        0.5525
    ],
    [
        -0.1115,
        0.1333,
        -0.0547,  ...,
        0.0062,
        -0.1250,
        0.1593
    ],
    [
        -0.1097,
        0.1307,
        -0.0568,  ...,
        0.0075,
        -0.1233,
        0.1583
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2202,
        0.1945,
        -0.2370
    ],
    [
        0.3219,
        -0.2041,
        -0.0564,  ...,
        -0.2202,
        0.1945,
        -0.2370
    ],
    [
        0.3219,
        -0.2041,
        -0.0564,  ...,
        -0.2202,
        0.1945,
        -0.2370
    ],
        ...,
    [
        0.3219,
        -0.2041,
        -0.0564,  ...,
        -0.2202,
        0.1945,
        -0.2370
    ],
    [
        0.3219,
        -0.2041,
        -0.0564,  ...,
        -0.2202,
        0.1945,
        -0.2370
    ],
    [
        0.3219,
        -0.2041,
        -0.0564,  ...,
        -0.2202,
        0.1945,
        -0.2370
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -552.3862,
    -527.4617,
    -546.7573,
    -555.4338,
    -538.6388,
    -521.4834,
    -543.1248,
    -562.1134,
    -518.0146,
    -559.0703,
    -551.3812,
    -536.9487,
    -556.7389,
    -560.4888,
    -527.3619,
    -516.3175
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -552.3863,
    -527.4617,
    -546.7573,
    -555.4338,
    -538.6388,
    -521.4835,
    -543.1248,
    -562.1134,
    -518.0146,
    -559.0703,
    -551.3812,
    -536.9487,
    -556.7390,
    -560.4888,
    -527.3620,
    -516.3176
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(2.6365, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.3929,
        0.5641,
        -0.1783,  ...,
        0.1327,
        -0.4245,
        0.5940
    ],
    [
        -0.1280,
        0.1273,
        -0.0273,  ...,
        0.0023,
        -0.1066,
        0.1643
    ],
    [
        -0.1305,
        0.1292,
        -0.0288,  ...,
        0.0036,
        -0.1079,
        0.1681
    ],
        ...,
    [
        -0.3951,
        0.5657,
        -0.1771,  ...,
        0.1334,
        -0.4230,
        0.5970
    ],
    [
        -0.1310,
        0.1283,
        -0.0279,  ...,
        0.0037,
        -0.1071,
        0.1658
    ],
    [
        -0.1286,
        0.1269,
        -0.0285,  ...,
        0.0040,
        -0.1060,
        0.1672
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.3652,
            0.5190,
            -0.1685,  ...,
            0.1180,
            -0.3914,
            0.5498
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1095,
            0.1323,
            -0.0539,  ...,
            0.0074,
            -0.1209,
            0.1565
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1130,
            0.1338,
            -0.0549,  ...,
            0.0047,
            -0.1232,
            0.1616
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2237,
        0.2118,
        -0.2282
    ],
    [
        0.2941,
        -0.1590,
        -0.0662,  ...,
        -0.2237,
        0.2118,
        -0.2282
    ],
    [
        0.2941,
        -0.1590,
        -0.0662,  ...,
        -0.2237,
        0.2118,
        -0.2282
    ],
        ...,
    [
        0.2941,
        -0.1590,
        -0.0662,  ...,
        -0.2237,
        0.2118,
        -0.2282
    ],
    [
        0.2941,
        -0.1590,
        -0.0662,  ...,
        -0.2237,
        0.2118,
        -0.2282
    ],
    [
        0.2941,
        -0.1590,
        -0.0662,  ...,
        -0.2237,
        0.2118,
        -0.2282
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -573.4873,
    -545.6125,
    -565.1779,
    -575.9448,
    -556.9612,
    -539.5983,
    -561.5051,
    -581.2186,
    -531.4902,
    -578.8823,
    -572.5563,
    -555.3044,
    -577.2072,
    -579.7797,
    -545.4558,
    -534.4037
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -573.4873,
    -545.6125,
    -565.1779,
    -575.9448,
    -556.9613,
    -539.5982,
    -561.5052,
    -581.2186,
    -531.4901,
    -578.8822,
    -572.5563,
    -555.3045,
    -577.2072,
    -579.7796,
    -545.4558,
    -534.4036
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(2.8224, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.4208,
        0.6087,
        -0.1880,  ...,
        0.1484,
        -0.4576,
        0.6388
    ],
    [
        -0.1401,
        0.1230,
        -0.0077,  ...,
        0.0046,
        -0.1086,
        0.1734
    ],
    [
        -0.1431,
        0.1276,
        -0.0090,  ...,
        0.0059,
        -0.1075,
        0.1779
    ],
        ...,
    [
        -0.4232,
        0.6106,
        -0.1869,  ...,
        0.1483,
        -0.4557,
        0.6417
    ],
    [
        -0.1420,
        0.1249,
        -0.0072,  ...,
        0.0086,
        -0.1065,
        0.1743
    ],
    [
        -0.1416,
        0.1250,
        -0.0096,  ...,
        0.0069,
        -0.1068,
        0.1764
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.3929,
            0.5641,
            -0.1783,  ...,
            0.1327,
            -0.4245,
            0.5940
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1280,
            0.1273,
            -0.0273,  ...,
            0.0023,
            -0.1066,
            0.1643
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1305,
            0.1292,
            -0.0288,  ...,
            0.0036,
            -0.1079,
            0.1681
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2208,
        0.2110,
        -0.2190
    ],
    [
        0.2663,
        -0.1144,
        -0.0759,  ...,
        -0.2208,
        0.2110,
        -0.2190
    ],
    [
        0.2663,
        -0.1144,
        -0.0759,  ...,
        -0.2208,
        0.2110,
        -0.2190
    ],
        ...,
    [
        0.2663,
        -0.1144,
        -0.0759,  ...,
        -0.2208,
        0.2110,
        -0.2190
    ],
    [
        0.2663,
        -0.1144,
        -0.0759,  ...,
        -0.2208,
        0.2110,
        -0.2190
    ],
    [
        0.2663,
        -0.1144,
        -0.0759,  ...,
        -0.2208,
        0.2110,
        -0.2190
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -593.1388,
    -563.2378,
    -582.8319,
    -595.0016,
    -574.6381,
    -557.2064,
    -579.2020,
    -598.8601,
    -543.4319,
    -597.2353,
    -592.2781,
    -572.9359,
    -596.2218,
    -597.6056,
    -563.0933,
    -551.9995
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -593.1388,
    -563.2378,
    -582.8319,
    -595.0016,
    -574.6382,
    -557.2064,
    -579.2020,
    -598.8601,
    -543.4319,
    -597.2353,
    -592.2781,
    -572.9359,
    -596.2218,
    -597.6056,
    -563.0933,
    -551.9995
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(2.9981, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -4.4857e-01,
        6.5334e-01,
        -1.9707e-01,  ...,
        1.6421e-01,
        -4.9072e-01,
        6.8360e-01
    ],
    [
        -1.5433e-01,
        1.2397e-01,
        -4.6121e-04,  ...,
        1.2315e-02,
        -1.1450e-01,
        1.7567e-01
    ],
    [
        -1.5470e-01,
        1.2606e-01,
        -2.4000e-03,  ...,
        1.2829e-02,
        -1.1403e-01,
        1.7735e-01
    ],
        ...,
    [
        -4.5087e-01,
        6.5534e-01,
        -1.9638e-01,  ...,
        1.6403e-01,
        -4.8853e-01,
        6.8666e-01
    ],
    [
        -1.5263e-01,
        1.2419e-01,
        -1.0285e-03,  ...,
        1.5391e-02,
        -1.1324e-01,
        1.7514e-01
    ],
    [
        -1.5328e-01,
        1.2649e-01,
        -3.5332e-03,  ...,
        1.1103e-02,
        -1.1543e-01,
        1.7598e-01
    ]
], device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.4208,
            0.6087,
            -0.1880,  ...,
            0.1484,
            -0.4576,
            0.6388
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1401,
            0.1230,
            -0.0077,  ...,
            0.0046,
            -0.1086,
            0.1734
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1431,
            0.1276,
            -0.0090,  ...,
            0.0059,
            -0.1075,
            0.1779
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2166,
        0.2024,
        -0.2194
    ],
    [
        0.2385,
        -0.0698,
        -0.0850,  ...,
        -0.2166,
        0.2024,
        -0.2194
    ],
    [
        0.2385,
        -0.0698,
        -0.0850,  ...,
        -0.2166,
        0.2024,
        -0.2194
    ],
        ...,
    [
        0.2385,
        -0.0698,
        -0.0850,  ...,
        -0.2166,
        0.2024,
        -0.2194
    ],
    [
        0.2385,
        -0.0698,
        -0.0850,  ...,
        -0.2166,
        0.2024,
        -0.2194
    ],
    [
        0.2385,
        -0.0698,
        -0.0850,  ...,
        -0.2166,
        0.2024,
        -0.2194
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -616.7498,
    -585.2114,
    -604.7311,
    -618.0178,
    -596.5940,
    -579.0830,
    -601.1362,
    -620.4459,
    -559.3008,
    -619.5377,
    -615.9623,
    -594.8092,
    -619.1915,
    -619.3776,
    -585.0780,
    -573.9263
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -616.7498,
    -585.2114,
    -604.7311,
    -618.0178,
    -596.5940,
    -579.0830,
    -601.1364,
    -620.4459,
    -559.3007,
    -619.5377,
    -615.9623,
    -594.8092,
    -619.1916,
    -619.3776,
    -585.0779,
    -573.9263
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(3.2148, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.4765,
        0.6980,
        -0.2056,  ...,
        0.1806,
        -0.5241,
        0.7288
    ],
    [
        -0.1519,
        0.1212,
        -0.0047,  ...,
        0.0172,
        -0.1198,
        0.1815
    ],
    [
        -0.1548,
        0.1252,
        -0.0059,  ...,
        0.0160,
        -0.1182,
        0.1815
    ],
        ...,
    [
        -0.4788,
        0.6999,
        -0.2052,  ...,
        0.1802,
        -0.5218,
        0.7318
    ],
    [
        -0.1513,
        0.1229,
        -0.0044,  ...,
        0.0184,
        -0.1199,
        0.1830
    ],
    [
        -0.1520,
        0.1237,
        -0.0038,  ...,
        0.0160,
        -0.1202,
        0.1832
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -4.4857e-01,
            6.5334e-01,
            -1.9707e-01,  ...,
            1.6421e-01,
            -4.9072e-01,
            6.8360e-01
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -1.5433e-01,
            1.2397e-01,
            -4.6121e-04,  ...,
            1.2315e-02,
            -1.1450e-01,
            1.7567e-01
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -1.5470e-01,
            1.2606e-01,
            -2.4000e-03,  ...,
            1.2829e-02,
            -1.1403e-01,
            1.7735e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],

        ...,
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2117,
        0.1976,
        -0.2122
    ],
    [
        0.2106,
        -0.0252,
        -0.0935,  ...,
        -0.2117,
        0.1976,
        -0.2122
    ],
    [
        0.2106,
        -0.0252,
        -0.0935,  ...,
        -0.2117,
        0.1976,
        -0.2122
    ],
        ...,
    [
        0.2106,
        -0.0252,
        -0.0935,  ...,
        -0.2117,
        0.1976,
        -0.2122
    ],
    [
        0.2106,
        -0.0252,
        -0.0935,  ...,
        -0.2117,
        0.1976,
        -0.2122
    ],
    [
        0.2106,
        -0.0252,
        -0.0935,  ...,
        -0.2117,
        0.1976,
        -0.2122
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -646.0453,
    -612.8850,
    -632.5593,
    -646.7094,
    -624.4410,
    -606.8743,
    -628.9175,
    -647.7006,
    -580.8160,
    -647.5132,
    -645.3275,
    -622.6116,
    -647.8455,
    -646.8218,
    -612.8235,
    -601.7015
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -646.0453,
    -612.8849,
    -632.5592,
    -646.7094,
    -624.4411,
    -606.8743,
    -628.9175,
    -647.7006,
    -580.8160,
    -647.5132,
    -645.3275,
    -622.6116,
    -647.8455,
    -646.8218,
    -612.8235,
    -601.7015
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(3.4887, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.5043,
        0.7422,
        -0.2135,  ...,
        0.1982,
        -0.5573,
        0.7746
    ],
    [
        -0.1547,
        0.1175,
        -0.0034,  ...,
        0.0184,
        -0.1180,
        0.1816
    ],
    [
        -0.1558,
        0.1199,
        -0.0050,  ...,
        0.0184,
        -0.1175,
        0.1818
    ],
        ...,
    [
        -0.5066,
        0.7444,
        -0.2134,  ...,
        0.1977,
        -0.5549,
        0.7778
    ],
    [
        -0.1540,
        0.1197,
        -0.0048,  ...,
        0.0171,
        -0.1185,
        0.1826
    ],
    [
        -0.1534,
        0.1189,
        -0.0046,  ...,
        0.0184,
        -0.1161,
        0.1829
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.4765,
            0.6980,
            -0.2056,  ...,
            0.1806,
            -0.5241,
            0.7288
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1519,
            0.1212,
            -0.0047,  ...,
            0.0172,
            -0.1198,
            0.1815
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1548,
            0.1252,
            -0.0059,  ...,
            0.0160,
            -0.1182,
            0.1815
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2093,
        0.2017,
        -0.2125
    ],
    [
        0.1828,
        0.0191,
        -0.1014,  ...,
        -0.2093,
        0.2017,
        -0.2125
    ],
    [
        0.1828,
        0.0191,
        -0.1014,  ...,
        -0.2093,
        0.2017,
        -0.2125
    ],
        ...,
    [
        0.1828,
        0.0191,
        -0.1014,  ...,
        -0.2093,
        0.2017,
        -0.2125
    ],
    [
        0.1828,
        0.0191,
        -0.1014,  ...,
        -0.2093,
        0.2017,
        -0.2125
    ],
    [
        0.1828,
        0.0191,
        -0.1014,  ...,
        -0.2093,
        0.2017,
        -0.2125
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -680.6695,
    -646.2467,
    -665.9224,
    -680.7314,
    -657.7288,
    -640.1743,
    -662.2947,
    -680.2773,
    -607.6499,
    -680.8161,
    -680.0259,
    -655.9836,
    -681.8306,
    -679.5891,
    -646.1172,
    -634.9920
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -680.6696,
    -646.2468,
    -665.9224,
    -680.7314,
    -657.7288,
    -640.1742,
    -662.2947,
    -680.2773,
    -607.6500,
    -680.8160,
    -680.0260,
    -655.9836,
    -681.8306,
    -679.5891,
    -646.1171,
    -634.9920
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(3.8168, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -5.3268e-01,
        7.8595e-01,
        -2.2115e-01,  ...,
        2.1671e-01,
        -5.8987e-01,
        8.2084e-01
    ],
    [
        -1.5678e-01,
        1.1304e-01,
        1.3904e-03,  ...,
        2.2103e-02,
        -1.1657e-01,
        1.7987e-01
    ],
    [
        -1.5693e-01,
        1.1336e-01,
        5.5000e-04,  ...,
        2.3078e-02,
        -1.1886e-01,
        1.8009e-01
    ],
        ...,
    [
        -5.3502e-01,
        7.8826e-01,
        -2.2130e-01,  ...,
        2.1597e-01,
        -5.8780e-01,
        8.2461e-01
    ],
    [
        -1.5612e-01,
        1.1373e-01,
        2.2275e-04,  ...,
        2.1786e-02,
        -1.1744e-01,
        1.7804e-01
    ],
    [
        -1.5548e-01,
        1.1414e-01,
        -1.5595e-03,  ...,
        2.2536e-02,
        -1.1798e-01,
        1.7979e-01
    ]
], device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.5043,
            0.7422,
            -0.2135,  ...,
            0.1982,
            -0.5573,
            0.7746
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1547,
            0.1175,
            -0.0034,  ...,
            0.0184,
            -0.1180,
            0.1816
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1558,
            0.1199,
            -0.0050,  ...,
            0.0184,
            -0.1175,
            0.1818
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2052,
        0.1998,
        -0.2156
    ],
    [
        0.1544,
        0.0628,
        -0.1091,  ...,
        -0.2052,
        0.1998,
        -0.2156
    ],
    [
        0.1544,
        0.0628,
        -0.1091,  ...,
        -0.2052,
        0.1998,
        -0.2156
    ],
        ...,
    [
        0.1544,
        0.0628,
        -0.1091,  ...,
        -0.2052,
        0.1998,
        -0.2156
    ],
    [
        0.1544,
        0.0628,
        -0.1091,  ...,
        -0.2052,
        0.1998,
        -0.2156
    ],
    [
        0.1544,
        0.0628,
        -0.1091,  ...,
        -0.2052,
        0.1998,
        -0.2156
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -718.2265,
    -683.0176,
    -702.5692,
    -717.6844,
    -694.4314,
    -676.9258,
    -698.9796,
    -715.7782,
    -637.3751,
    -717.0449,
    -717.6556,
    -692.7175,
    -718.7432,
    -715.2797,
    -682.8107,
    -671.7499
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -718.2264,
    -683.0176,
    -702.5692,
    -717.6844,
    -694.4314,
    -676.9258,
    -698.9796,
    -715.7783,
    -637.3752,
    -717.0449,
    -717.6556,
    -692.7175,
    -718.7432,
    -715.2798,
    -682.8107,
    -671.7499
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(4.1762, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.5608,
        0.8296,
        -0.2287,  ...,
        0.2359,
        -0.6219,
        0.8669
    ],
    [
        -0.1534,
        0.1098,
        0.0121,  ...,
        0.0208,
        -0.1103,
        0.1810
    ],
    [
        -0.1533,
        0.1101,
        0.0123,  ...,
        0.0203,
        -0.1117,
        0.1826
    ],
        ...,
    [
        -0.5632,
        0.8316,
        -0.2286,  ...,
        0.2350,
        -0.6195,
        0.8709
    ],
    [
        -0.1536,
        0.1111,
        0.0124,  ...,
        0.0207,
        -0.1125,
        0.1793
    ],
    [
        -0.1521,
        0.1102,
        0.0126,  ...,
        0.0220,
        -0.1103,
        0.1806
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -5.3268e-01,
            7.8595e-01,
            -2.2115e-01,  ...,
            2.1671e-01,
            -5.8987e-01,
            8.2084e-01
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -1.5678e-01,
            1.1304e-01,
            1.3904e-03,  ...,
            2.2103e-02,
            -1.1657e-01,
            1.7987e-01
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -1.5693e-01,
            1.1336e-01,
            5.5000e-04,  ...,
            2.3078e-02,
            -1.1886e-01,
            1.8009e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],

        ...,
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ],
    [
        [
            -6.8709e-01,
            7.2312e-01,
            -1.1205e-01,  ...,
            4.3066e-01,
            -6.4394e-01,
            1.2986e+00
        ],
        [
            -6.1261e-01,
            7.5508e-01,
            -1.9165e-01,  ...,
            3.2980e-01,
            -6.8040e-01,
            1.2186e+00
        ],
        [
            -5.3151e-01,
            5.6632e-01,
            -3.1703e-01,  ...,
            2.6956e-01,
            -5.6223e-01,
            9.3116e-01
        ],
         ...,
        [
            -3.6249e-01,
            3.0746e-01,
            -2.2263e-01,  ...,
            1.6545e-01,
            -3.4703e-01,
            4.8344e-01
        ],
        [
            -3.3367e-01,
            3.0841e-01,
            -2.3380e-01,  ...,
            1.1065e-01,
            -4.1446e-01,
            3.8512e-01
        ],
        [
            -2.3255e-01,
            3.2806e-01,
            -1.6989e-01,  ...,
            2.2771e-01,
            -3.1781e-01,
            3.9536e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2057,
        0.2075,
        -0.2147
    ],
    [
        0.1263,
        0.1065,
        -0.1167,  ...,
        -0.2057,
        0.2075,
        -0.2147
    ],
    [
        0.1263,
        0.1065,
        -0.1167,  ...,
        -0.2057,
        0.2075,
        -0.2147
    ],
        ...,
    [
        0.1263,
        0.1065,
        -0.1167,  ...,
        -0.2057,
        0.2075,
        -0.2147
    ],
    [
        0.1263,
        0.1065,
        -0.1167,  ...,
        -0.2057,
        0.2075,
        -0.2147
    ],
    [
        0.1263,
        0.1065,
        -0.1167,  ...,
        -0.2057,
        0.2075,
        -0.2147
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -760.8064,
    -725.0250,
    -744.5049,
    -759.6588,
    -736.4677,
    -718.9326,
    -740.9857,
    -756.2911,
    -672.1377,
    -758.2907,
    -760.3080,
    -734.7266,
    -760.6769,
    -755.9867,
    -724.8353,
    -713.7100
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -760.8065,
    -725.0250,
    -744.5048,
    -759.6588,
    -736.4677,
    -718.9327,
    -740.9857,
    -756.2911,
    -672.1378,
    -758.2907,
    -760.3081,
    -734.7266,
    -760.6769,
    -755.9866,
    -724.8353,
    -713.7101
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(4.5866, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.5890,
        0.8729,
        -0.2357,  ...,
        0.2550,
        -0.6538,
        0.9134
    ],
    [
        -0.1532,
        0.1111,
        0.0132,  ...,
        0.0138,
        -0.0957,
        0.1810
    ],
    [
        -0.1531,
        0.1107,
        0.0125,  ...,
        0.0131,
        -0.0983,
        0.1812
    ],
        ...,
    [
        -0.5914,
        0.8748,
        -0.2358,  ...,
        0.2544,
        -0.6512,
        0.9170
    ],
    [
        -0.1534,
        0.1104,
        0.0139,  ...,
        0.0153,
        -0.0966,
        0.1783
    ],
    [
        -0.1523,
        0.1104,
        0.0143,  ...,
        0.0159,
        -0.0966,
        0.1798
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.5608,
            0.8296,
            -0.2287,  ...,
            0.2359,
            -0.6219,
            0.8669
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1534,
            0.1098,
            0.0121,  ...,
            0.0208,
            -0.1103,
            0.1810
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1533,
            0.1101,
            0.0123,  ...,
            0.0203,
            -0.1117,
            0.1826
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2118,
        0.2212,
        -0.2155
    ],
    [
        0.0981,
        0.1498,
        -0.1237,  ...,
        -0.2118,
        0.2212,
        -0.2155
    ],
    [
        0.0981,
        0.1498,
        -0.1237,  ...,
        -0.2118,
        0.2212,
        -0.2155
    ],
        ...,
    [
        0.0981,
        0.1498,
        -0.1237,  ...,
        -0.2118,
        0.2212,
        -0.2155
    ],
    [
        0.0981,
        0.1498,
        -0.1237,  ...,
        -0.2118,
        0.2212,
        -0.2155
    ],
    [
        0.0981,
        0.1498,
        -0.1237,  ...,
        -0.2118,
        0.2212,
        -0.2155
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -807.6094,
    -771.6277,
    -791.0201,
    -805.8558,
    -782.9928,
    -765.5262,
    -787.5616,
    -801.0223,
    -711.0664,
    -803.7557,
    -807.1842,
    -781.2869,
    -806.8300,
    -800.9182,
    -771.4138,
    -760.3256
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -807.6094,
    -771.6277,
    -791.0201,
    -805.8557,
    -782.9928,
    -765.5262,
    -787.5616,
    -801.0223,
    -711.0664,
    -803.7557,
    -807.1842,
    -781.2869,
    -806.8300,
    -800.9182,
    -771.4138,
    -760.3256
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(5.0406, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.6171,
        0.9160,
        -0.2426,  ...,
        0.2742,
        -0.6856,
        0.9592
    ],
    [
        -0.1587,
        0.1124,
        0.0031,  ...,
        0.0086,
        -0.0838,
        0.1799
    ],
    [
        -0.1597,
        0.1125,
        0.0020,  ...,
        0.0094,
        -0.0852,
        0.1796
    ],
        ...,
    [
        -0.6194,
        0.9181,
        -0.2425,  ...,
        0.2737,
        -0.6830,
        0.9633
    ],
    [
        -0.1585,
        0.1113,
        0.0038,  ...,
        0.0132,
        -0.0847,
        0.1765
    ],
    [
        -0.1602,
        0.1127,
        0.0033,  ...,
        0.0109,
        -0.0859,
        0.1786
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.5890,
            0.8729,
            -0.2357,  ...,
            0.2550,
            -0.6538,
            0.9134
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1532,
            0.1111,
            0.0132,  ...,
            0.0138,
            -0.0957,
            0.1810
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1531,
            0.1107,
            0.0125,  ...,
            0.0131,
            -0.0983,
            0.1812
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2168,
        0.2319,
        -0.2168
    ],
    [
        0.0700,
        0.1929,
        -0.1306,  ...,
        -0.2168,
        0.2319,
        -0.2168
    ],
    [
        0.0700,
        0.1929,
        -0.1306,  ...,
        -0.2168,
        0.2319,
        -0.2168
    ],
        ...,
    [
        0.0700,
        0.1929,
        -0.1306,  ...,
        -0.2168,
        0.2319,
        -0.2168
    ],
    [
        0.0700,
        0.1929,
        -0.1306,  ...,
        -0.2168,
        0.2319,
        -0.2168
    ],
    [
        0.0700,
        0.1929,
        -0.1306,  ...,
        -0.2168,
        0.2319,
        -0.2168
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -856.7627,
    -821.1378,
    -840.3467,
    -854.4036,
    -832.3978,
    -815.0734,
    -836.9725,
    -848.1030,
    -752.3547,
    -851.5690,
    -856.4115,
    -830.6765,
    -855.3357,
    -848.1982,
    -820.8506,
    -809.8818
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -856.7628,
    -821.1379,
    -840.3467,
    -854.4036,
    -832.3978,
    -815.0734,
    -836.9725,
    -848.1030,
    -752.3547,
    -851.5689,
    -856.4115,
    -830.6765,
    -855.3357,
    -848.1982,
    -820.8506,
    -809.8818
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(5.5201, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.6456,
        0.9599,
        -0.2489,  ...,
        0.2934,
        -0.7176,
        1.0051
    ],
    [
        -0.1589,
        0.1237,
        -0.0148,  ...,
        0.0162,
        -0.0854,
        0.1855
    ],
    [
        -0.1595,
        0.1235,
        -0.0150,  ...,
        0.0190,
        -0.0850,
        0.1843
    ],
        ...,
    [
        -0.6477,
        0.9618,
        -0.2488,  ...,
        0.2930,
        -0.7148,
        1.0096
    ],
    [
        -0.1608,
        0.1233,
        -0.0133,  ...,
        0.0216,
        -0.0865,
        0.1823
    ],
    [
        -0.1613,
        0.1249,
        -0.0145,  ...,
        0.0193,
        -0.0865,
        0.1844
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.6171,
            0.9160,
            -0.2426,  ...,
            0.2742,
            -0.6856,
            0.9592
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1587,
            0.1124,
            0.0031,  ...,
            0.0086,
            -0.0838,
            0.1799
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1597,
            0.1125,
            0.0020,  ...,
            0.0094,
            -0.0852,
            0.1796
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2084,
        0.2313,
        -0.2110
    ],
    [
        0.0415,
        0.2368,
        -0.1368,  ...,
        -0.2084,
        0.2313,
        -0.2110
    ],
    [
        0.0415,
        0.2368,
        -0.1368,  ...,
        -0.2084,
        0.2313,
        -0.2110
    ],
        ...,
    [
        0.0415,
        0.2368,
        -0.1368,  ...,
        -0.2084,
        0.2313,
        -0.2110
    ],
    [
        0.0415,
        0.2368,
        -0.1368,  ...,
        -0.2084,
        0.2313,
        -0.2110
    ],
    [
        0.0415,
        0.2368,
        -0.1368,  ...,
        -0.2084,
        0.2313,
        -0.2110
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -904.0914,
    -869.8120,
    -888.5983,
    -901.1257,
    -880.8564,
    -863.8441,
    -885.4073,
    -893.3591,
    -791.8022,
    -897.5592,
    -903.8149,
    -879.1650,
    -902.0168,
    -893.6449,
    -869.4851,
    -858.6994
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -904.0914,
    -869.8120,
    -888.5983,
    -901.1258,
    -880.8564,
    -863.8442,
    -885.4073,
    -893.3591,
    -791.8021,
    -897.5593,
    -903.8149,
    -879.1650,
    -902.0168,
    -893.6449,
    -869.4850,
    -858.6994
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(5.9856, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.6737,
        1.0035,
        -0.2552,  ...,
        0.3126,
        -0.7497,
        1.0510
    ],
    [
        -0.1661,
        0.1480,
        -0.0368,  ...,
        0.0267,
        -0.0988,
        0.1977
    ],
    [
        -0.1665,
        0.1493,
        -0.0376,  ...,
        0.0291,
        -0.0982,
        0.1957
    ],
        ...,
    [
        -0.6763,
        1.0057,
        -0.2552,  ...,
        0.3118,
        -0.7467,
        1.0558
    ],
    [
        -0.1682,
        0.1495,
        -0.0367,  ...,
        0.0306,
        -0.1000,
        0.1940
    ],
    [
        -0.1675,
        0.1500,
        -0.0374,  ...,
        0.0294,
        -0.0992,
        0.1971
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.6456,
            0.9599,
            -0.2489,  ...,
            0.2934,
            -0.7176,
            1.0051
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1589,
            0.1237,
            -0.0148,  ...,
            0.0162,
            -0.0854,
            0.1855
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1595,
            0.1235,
            -0.0150,  ...,
            0.0190,
            -0.0850,
            0.1843
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1983,
        0.2186,
        -0.1982
    ],
    [
        0.0134,
        0.2804,
        -0.1432,  ...,
        -0.1983,
        0.2186,
        -0.1982
    ],
    [
        0.0134,
        0.2804,
        -0.1432,  ...,
        -0.1983,
        0.2186,
        -0.1982
    ],
        ...,
    [
        0.0134,
        0.2804,
        -0.1432,  ...,
        -0.1983,
        0.2186,
        -0.1982
    ],
    [
        0.0134,
        0.2804,
        -0.1432,  ...,
        -0.1983,
        0.2186,
        -0.1982
    ],
    [
        0.0134,
        0.2804,
        -0.1432,  ...,
        -0.1983,
        0.2186,
        -0.1982
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -949.1652,
    -917.3273,
    -935.4368,
    -945.5936,
    -927.9728,
    -911.5184,
    -932.4551,
    -936.3502,
    -828.9923,
    -941.2920,
    -948.9634,
    -926.3817,
    -946.4475,
    -936.8350,
    -916.9056,
    -906.4039
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -949.1652,
    -917.3273,
    -935.4368,
    -945.5936,
    -927.9728,
    -911.5184,
    -932.4551,
    -936.3503,
    -828.9923,
    -941.2921,
    -948.9633,
    -926.3817,
    -946.4475,
    -936.8351,
    -916.9055,
    -906.4039
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(6.4325, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.7023,
        1.0473,
        -0.2611,  ...,
        0.3316,
        -0.7817,
        1.0974
    ],
    [
        -0.1765,
        0.1852,
        -0.0594,  ...,
        0.0344,
        -0.1237,
        0.2207
    ],
    [
        -0.1743,
        0.1877,
        -0.0593,  ...,
        0.0389,
        -0.1220,
        0.2175
    ],
        ...,
    [
        -0.7045,
        1.0491,
        -0.2614,  ...,
        0.3312,
        -0.7787,
        1.1020
    ],
    [
        -0.1777,
        0.1871,
        -0.0591,  ...,
        0.0389,
        -0.1237,
        0.2169
    ],
    [
        -0.1756,
        0.1879,
        -0.0586,  ...,
        0.0386,
        -0.1228,
        0.2190
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.6737,
            1.0035,
            -0.2552,  ...,
            0.3126,
            -0.7497,
            1.0510
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1661,
            0.1480,
            -0.0368,  ...,
            0.0267,
            -0.0988,
            0.1977
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1665,
            0.1493,
            -0.0376,  ...,
            0.0291,
            -0.0982,
            0.1957
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1891,
        0.1950,
        -0.1764
    ],
    [
        -0.0152,
        0.3242,
        -0.1490,  ...,
        -0.1891,
        0.1950,
        -0.1764
    ],
    [
        -0.0152,
        0.3242,
        -0.1490,  ...,
        -0.1891,
        0.1950,
        -0.1764
    ],
        ...,
    [
        -0.0152,
        0.3242,
        -0.1490,  ...,
        -0.1891,
        0.1950,
        -0.1764
    ],
    [
        -0.0152,
        0.3242,
        -0.1490,  ...,
        -0.1891,
        0.1950,
        -0.1764
    ],
    [
        -0.0152,
        0.3242,
        -0.1490,  ...,
        -0.1891,
        0.1950,
        -0.1764
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -993.6318,
    -965.1814,
    -982.3517,
    -989.4536,
    -975.3078,
    -959.5720,
    -979.6322,
    -978.7397,
    -865.5565,
    -984.4180,
    -993.5040,
    -973.8300,
    -990.2662,
    -979.4164,
    -964.6570,
    -954.5546
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -993.6319,
    -965.1815,
    -982.3516,
    -989.4535,
    -975.3077,
    -959.5720,
    -979.6321,
    -978.7397,
    -865.5565,
    -984.4179,
    -993.5040,
    -973.8300,
    -990.2661,
    -979.4164,
    -964.6570,
    -954.5547
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(6.8764, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.7309,
        1.0914,
        -0.2679,  ...,
        0.3508,
        -0.8132,
        1.1436
    ],
    [
        -0.1896,
        0.2263,
        -0.0796,  ...,
        0.0415,
        -0.1571,
        0.2512
    ],
    [
        -0.1863,
        0.2280,
        -0.0797,  ...,
        0.0458,
        -0.1553,
        0.2491
    ],
        ...,
    [
        -0.7332,
        1.0931,
        -0.2677,  ...,
        0.3503,
        -0.8104,
        1.1487
    ],
    [
        -0.1903,
        0.2270,
        -0.0792,  ...,
        0.0457,
        -0.1562,
        0.2479
    ],
    [
        -0.1887,
        0.2284,
        -0.0775,  ...,
        0.0460,
        -0.1564,
        0.2497
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.7023,
            1.0473,
            -0.2611,  ...,
            0.3316,
            -0.7817,
            1.0974
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1765,
            0.1852,
            -0.0594,  ...,
            0.0344,
            -0.1237,
            0.2207
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1743,
            0.1877,
            -0.0593,  ...,
            0.0389,
            -0.1220,
            0.2175
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1817,
        0.1614,
        -0.1456
    ],
    [
        -0.0438,
        0.3683,
        -0.1558,  ...,
        -0.1817,
        0.1614,
        -0.1456
    ],
    [
        -0.0438,
        0.3683,
        -0.1558,  ...,
        -0.1817,
        0.1614,
        -0.1456
    ],
        ...,
    [
        -0.0438,
        0.3683,
        -0.1558,  ...,
        -0.1817,
        0.1614,
        -0.1456
    ],
    [
        -0.0438,
        0.3683,
        -0.1558,  ...,
        -0.1817,
        0.1614,
        -0.1456
    ],
    [
        -0.0438,
        0.3683,
        -0.1558,  ...,
        -0.1817,
        0.1614,
        -0.1456
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1040.4634,
    -1016.0637,
    -1032.1364,
    -1035.6755,
    -1025.5872,
    -1010.6746,
    -1029.7139,
    -1023.4882,
    -904.4697,
    -1029.9080,
    -1040.4106,
    -1024.2366,
    -1036.4452,
    -1024.3586,
    -1015.4427,
    -1005.8174
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1040.4634,
    -1016.0638,
    -1032.1365,
    -1035.6754,
    -1025.5870,
    -1010.6746,
    -1029.7137,
    -1023.4881,
    -904.4697,
    -1029.9080,
    -1040.4104,
    -1024.2366,
    -1036.4453,
    -1024.3586,
    -1015.4426,
    -1005.8174
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(7.3452, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.7591,
        1.1353,
        -0.2741,  ...,
        0.3703,
        -0.8450,
        1.1899
    ],
    [
        -0.2090,
        0.2662,
        -0.0973,  ...,
        0.0495,
        -0.1915,
        0.2924
    ],
    [
        -0.2060,
        0.2673,
        -0.0970,  ...,
        0.0530,
        -0.1912,
        0.2914
    ],
        ...,
    [
        -0.7617,
        1.1369,
        -0.2743,  ...,
        0.3697,
        -0.8418,
        1.1954
    ],
    [
        -0.2097,
        0.2665,
        -0.0967,  ...,
        0.0528,
        -0.1909,
        0.2894
    ],
    [
        -0.2091,
        0.2674,
        -0.0939,  ...,
        0.0531,
        -0.1914,
        0.2916
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.7309,
            1.0914,
            -0.2679,  ...,
            0.3508,
            -0.8132,
            1.1436
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.1896,
            0.2263,
            -0.0796,  ...,
            0.0415,
            -0.1571,
            0.2512
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.1863,
            0.2280,
            -0.0797,  ...,
            0.0458,
            -0.1553,
            0.2491
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1746,
        0.1264,
        -0.1037
    ],
    [
        -0.0720,
        0.4122,
        -0.1621,  ...,
        -0.1746,
        0.1264,
        -0.1037
    ],
    [
        -0.0720,
        0.4122,
        -0.1621,  ...,
        -0.1746,
        0.1264,
        -0.1037
    ],
        ...,
    [
        -0.0720,
        0.4122,
        -0.1621,  ...,
        -0.1746,
        0.1264,
        -0.1037
    ],
    [
        -0.0720,
        0.4122,
        -0.1621,  ...,
        -0.1746,
        0.1264,
        -0.1037
    ],
    [
        -0.0720,
        0.4122,
        -0.1621,  ...,
        -0.1746,
        0.1264,
        -0.1037
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1091.4247,
    -1071.5923,
    -1086.4421,
    -1086.0269,
    -1080.4673,
    -1066.4565,
    -1084.3400,
    -1072.3608,
    -947.5239,
    -1079.5237,
    -1091.4451,
    -1079.2421,
    -1086.7588,
    -1073.4338,
    -1070.8821,
    -1061.7957
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1091.4247,
    -1071.5923,
    -1086.4423,
    -1086.0269,
    -1080.4672,
    -1066.4565,
    -1084.3400,
    -1072.3608,
    -947.5240,
    -1079.5237,
    -1091.4451,
    -1079.2419,
    -1086.7589,
    -1073.4340,
    -1070.8821,
    -1061.7955
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(7.8556, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.7873,
        1.1794,
        -0.2806,  ...,
        0.3895,
        -0.8765,
        1.2361
    ],
    [
        -0.2343,
        0.3031,
        -0.1109,  ...,
        0.0575,
        -0.2245,
        0.3363
    ],
    [
        -0.2319,
        0.3041,
        -0.1101,  ...,
        0.0608,
        -0.2248,
        0.3356
    ],
        ...,
    [
        -0.7902,
        1.1809,
        -0.2809,  ...,
        0.3891,
        -0.8735,
        1.2414
    ],
    [
        -0.2348,
        0.3037,
        -0.1101,  ...,
        0.0614,
        -0.2242,
        0.3326
    ],
    [
        -0.2351,
        0.3043,
        -0.1075,  ...,
        0.0610,
        -0.2255,
        0.3355
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.7591,
            1.1353,
            -0.2741,  ...,
            0.3703,
            -0.8450,
            1.1899
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.2090,
            0.2662,
            -0.0973,  ...,
            0.0495,
            -0.1915,
            0.2924
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.2060,
            0.2673,
            -0.0970,  ...,
            0.0530,
            -0.1912,
            0.2914
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1667,
        0.0923,
        -0.0599
    ],
    [
        -0.1002,
        0.4563,
        -0.1685,  ...,
        -0.1667,
        0.0923,
        -0.0599
    ],
    [
        -0.1002,
        0.4563,
        -0.1685,  ...,
        -0.1667,
        0.0923,
        -0.0599
    ],
        ...,
    [
        -0.1002,
        0.4563,
        -0.1685,  ...,
        -0.1667,
        0.0923,
        -0.0599
    ],
    [
        -0.1002,
        0.4563,
        -0.1685,  ...,
        -0.1667,
        0.0923,
        -0.0599
    ],
    [
        -0.1002,
        0.4563,
        -0.1685,  ...,
        -0.1667,
        0.0923,
        -0.0599
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1148.5720,
    -1133.6008,
    -1147.1445,
    -1142.5588,
    -1141.7889,
    -1128.7428,
    -1145.3947,
    -1127.4246,
    -996.7515,
    -1135.3198,
    -1148.6656,
    -1140.6997,
    -1143.2544,
    -1128.6964,
    -1132.7963,
    -1124.2830
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1148.5721,
    -1133.6007,
    -1147.1445,
    -1142.5588,
    -1141.7889,
    -1128.7430,
    -1145.3948,
    -1127.4247,
    -996.7515,
    -1135.3198,
    -1148.6658,
    -1140.6997,
    -1143.2545,
    -1128.6964,
    -1132.7963,
    -1124.2831
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(8.4269, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.8162,
        1.2234,
        -0.2870,  ...,
        0.4094,
        -0.9083,
        1.2823
    ],
    [
        -0.2614,
        0.3428,
        -0.1243,  ...,
        0.0689,
        -0.2568,
        0.3789
    ],
    [
        -0.2592,
        0.3431,
        -0.1224,  ...,
        0.0716,
        -0.2579,
        0.3786
    ],
        ...,
    [
        -0.8187,
        1.2253,
        -0.2874,  ...,
        0.4087,
        -0.9050,
        1.2882
    ],
    [
        -0.2613,
        0.3426,
        -0.1222,  ...,
        0.0727,
        -0.2573,
        0.3750
    ],
    [
        -0.2626,
        0.3443,
        -0.1203,  ...,
        0.0715,
        -0.2591,
        0.3780
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.7873,
            1.1794,
            -0.2806,  ...,
            0.3895,
            -0.8765,
            1.2361
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.2343,
            0.3031,
            -0.1109,  ...,
            0.0575,
            -0.2245,
            0.3363
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.2319,
            0.3041,
            -0.1101,  ...,
            0.0608,
            -0.2248,
            0.3356
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1562,
        0.0587,
        -0.0174
    ],
    [
        -0.1291,
        0.5002,
        -0.1750,  ...,
        -0.1562,
        0.0587,
        -0.0174
    ],
    [
        -0.1291,
        0.5002,
        -0.1750,  ...,
        -0.1562,
        0.0587,
        -0.0174
    ],
        ...,
    [
        -0.1291,
        0.5002,
        -0.1750,  ...,
        -0.1562,
        0.0587,
        -0.0174
    ],
    [
        -0.1291,
        0.5002,
        -0.1750,  ...,
        -0.1562,
        0.0587,
        -0.0174
    ],
    [
        -0.1291,
        0.5002,
        -0.1750,  ...,
        -0.1562,
        0.0587,
        -0.0174
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1212.3949,
    -1202.5854,
    -1214.7394,
    -1205.7776,
    -1210.0394,
    -1198.0361,
    -1213.3691,
    -1189.1580,
    -1052.6426,
    -1197.8003,
    -1212.5634,
    -1209.0905,
    -1206.4302,
    -1190.6154,
    -1201.6829,
    -1193.7814
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1212.3949,
    -1202.5854,
    -1214.7396,
    -1205.7776,
    -1210.0392,
    -1198.0363,
    -1213.3693,
    -1189.1580,
    -1052.6426,
    -1197.8004,
    -1212.5634,
    -1209.0903,
    -1206.4302,
    -1190.6151,
    -1201.6829,
    -1193.7812
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(9.0638, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.8442,
        1.2676,
        -0.2929,  ...,
        0.4291,
        -0.9399,
        1.3284
    ],
    [
        -0.2880,
        0.3842,
        -0.1359,  ...,
        0.0817,
        -0.2916,
        0.4221
    ],
    [
        -0.2862,
        0.3844,
        -0.1341,  ...,
        0.0848,
        -0.2933,
        0.4218
    ],
        ...,
    [
        -0.8472,
        1.2693,
        -0.2938,  ...,
        0.4281,
        -0.9367,
        1.3347
    ],
    [
        -0.2884,
        0.3839,
        -0.1334,  ...,
        0.0855,
        -0.2920,
        0.4186
    ],
    [
        -0.2897,
        0.3861,
        -0.1318,  ...,
        0.0842,
        -0.2942,
        0.4205
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.8162,
            1.2234,
            -0.2870,  ...,
            0.4094,
            -0.9083,
            1.2823
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.2614,
            0.3428,
            -0.1243,  ...,
            0.0689,
            -0.2568,
            0.3789
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.2592,
            0.3431,
            -0.1224,  ...,
            0.0716,
            -0.2579,
            0.3786
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1435,
        0.0236,
        0.0252
    ],
    [
        -0.1572,
        0.5444,
        -0.1809,  ...,
        -0.1435,
        0.0236,
        0.0252
    ],
    [
        -0.1572,
        0.5444,
        -0.1809,  ...,
        -0.1435,
        0.0236,
        0.0252
    ],
        ...,
    [
        -0.1572,
        0.5444,
        -0.1809,  ...,
        -0.1435,
        0.0236,
        0.0252
    ],
    [
        -0.1572,
        0.5444,
        -0.1809,  ...,
        -0.1435,
        0.0236,
        0.0252
    ],
    [
        -0.1572,
        0.5444,
        -0.1809,  ...,
        -0.1435,
        0.0236,
        0.0252
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1283.2527,
    -1278.8351,
    -1289.5562,
    -1276.0248,
    -1285.5393,
    -1274.6073,
    -1288.5669,
    -1257.9259,
    -1115.5881,
    -1267.3008,
    -1283.4937,
    -1284.7339,
    -1276.6299,
    -1259.5869,
    -1277.8556,
    -1270.5762
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1283.2528,
    -1278.8351,
    -1289.5560,
    -1276.0248,
    -1285.5394,
    -1274.6072,
    -1288.5669,
    -1257.9259,
    -1115.5881,
    -1267.3007,
    -1283.4935,
    -1284.7339,
    -1276.6299,
    -1259.5868,
    -1277.8555,
    -1270.5762
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(9.7695, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.8731,
        1.3117,
        -0.2994,  ...,
        0.4491,
        -0.9715,
        1.3751
    ],
    [
        -0.3136,
        0.4281,
        -0.1482,  ...,
        0.0927,
        -0.3244,
        0.4649
    ],
    [
        -0.3121,
        0.4287,
        -0.1459,  ...,
        0.0955,
        -0.3262,
        0.4643
    ],
        ...,
    [
        -0.8757,
        1.3134,
        -0.2997,  ...,
        0.4480,
        -0.9681,
        1.3809
    ],
    [
        -0.3133,
        0.4283,
        -0.1453,  ...,
        0.0965,
        -0.3244,
        0.4617
    ],
    [
        -0.3149,
        0.4305,
        -0.1439,  ...,
        0.0956,
        -0.3273,
        0.4635
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.8442,
            1.2676,
            -0.2929,  ...,
            0.4291,
            -0.9399,
            1.3284
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.2880,
            0.3842,
            -0.1359,  ...,
            0.0817,
            -0.2916,
            0.4221
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.2862,
            0.3844,
            -0.1341,  ...,
            0.0848,
            -0.2933,
            0.4218
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1321,
        -0.0095,
        0.0681
    ],
    [
        -0.1860,
        0.5886,
        -0.1874,  ...,
        -0.1321,
        -0.0095,
        0.0681
    ],
    [
        -0.1860,
        0.5886,
        -0.1874,  ...,
        -0.1321,
        -0.0095,
        0.0681
    ],
        ...,
    [
        -0.1860,
        0.5886,
        -0.1874,  ...,
        -0.1321,
        -0.0095,
        0.0681
    ],
    [
        -0.1860,
        0.5886,
        -0.1874,  ...,
        -0.1321,
        -0.0095,
        0.0681
    ],
    [
        -0.1860,
        0.5886,
        -0.1874,  ...,
        -0.1321,
        -0.0095,
        0.0681
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1362.4695,
    -1363.5898,
    -1372.8323,
    -1354.6255,
    -1369.5286,
    -1359.6814,
    -1372.2439,
    -1335.0457,
    -1186.8684,
    -1345.1747,
    -1362.7842,
    -1368.8739,
    -1355.1899,
    -1336.9082,
    -1362.5225,
    -1355.8845
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1362.4695,
    -1363.5900,
    -1372.8322,
    -1354.6255,
    -1369.5284,
    -1359.6815,
    -1372.2440,
    -1335.0457,
    -1186.8685,
    -1345.1748,
    -1362.7841,
    -1368.8738,
    -1355.1899,
    -1336.9084,
    -1362.5225,
    -1355.8846
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(10.5566, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.9016,
        1.3554,
        -0.3057,  ...,
        0.4690,
        -1.0032,
        1.4215
    ],
    [
        -0.3384,
        0.4729,
        -0.1595,  ...,
        0.1038,
        -0.3571,
        0.5085
    ],
    [
        -0.3373,
        0.4738,
        -0.1572,  ...,
        0.1063,
        -0.3591,
        0.5078
    ],
        ...,
    [
        -0.9041,
        1.3574,
        -0.3063,  ...,
        0.4679,
        -0.9996,
        1.4278
    ],
    [
        -0.3383,
        0.4739,
        -0.1564,  ...,
        0.1074,
        -0.3572,
        0.5055
    ],
    [
        -0.3399,
        0.4760,
        -0.1555,  ...,
        0.1065,
        -0.3600,
        0.5074
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.8731,
            1.3117,
            -0.2994,  ...,
            0.4491,
            -0.9715,
            1.3751
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.3136,
            0.4281,
            -0.1482,  ...,
            0.0927,
            -0.3244,
            0.4649
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.3121,
            0.4287,
            -0.1459,  ...,
            0.0955,
            -0.3262,
            0.4643
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],

        ...,
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ],
    [
        [
            -0.6871,
            0.7231,
            -0.1120,  ...,
            0.4307,
            -0.6439,
            1.2986
        ],
        [
            -0.6126,
            0.7551,
            -0.1916,  ...,
            0.3298,
            -0.6804,
            1.2186
        ],
        [
            -0.5315,
            0.5663,
            -0.3170,  ...,
            0.2696,
            -0.5622,
            0.9312
        ],
         ...,
        [
            -0.3625,
            0.3075,
            -0.2226,  ...,
            0.1654,
            -0.3470,
            0.4834
        ],
        [
            -0.3337,
            0.3084,
            -0.2338,  ...,
            0.1107,
            -0.4145,
            0.3851
        ],
        [
            -0.2325,
            0.3281,
            -0.1699,  ...,
            0.2277,
            -0.3178,
            0.3954
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.1212,
        -0.0422,
        0.1120
    ],
    [
        -0.2146,
        0.6322,
        -0.1937,  ...,
        -0.1212,
        -0.0422,
        0.1120
    ],
    [
        -0.2146,
        0.6322,
        -0.1937,  ...,
        -0.1212,
        -0.0422,
        0.1120
    ],
        ...,
    [
        -0.2146,
        0.6322,
        -0.1937,  ...,
        -0.1212,
        -0.0422,
        0.1120
    ],
    [
        -0.2146,
        0.6322,
        -0.1937,  ...,
        -0.1212,
        -0.0422,
        0.1120
    ],
    [
        -0.2146,
        0.6322,
        -0.1937,  ...,
        -0.1212,
        -0.0422,
        0.1120
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1450.2258,
    -1456.9995,
    -1464.7322,
    -1441.7695,
    -1462.1473,
    -1453.4297,
    -1464.5447,
    -1420.7073,
    -1266.6873,
    -1431.5792,
    -1450.6201,
    -1461.6484,
    -1442.2906,
    -1422.7686,
    -1455.8475,
    -1449.8601
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1450.2257,
    -1456.9994,
    -1464.7322,
    -1441.7697,
    -1462.1472,
    -1453.4298,
    -1464.5448,
    -1420.7074,
    -1266.6873,
    -1431.5792,
    -1450.6200,
    -1461.6483,
    -1442.2909,
    -1422.7686,
    -1455.8477,
    -1449.8602
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(11.4267, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [
                -39.3937,
                -40.5793,
                -40.8772,  ...,
                -40.3065,
                -40.1028,
                -39.8651
            ],
            [
                -39.7727,
                -40.5305,
                -39.9756,  ...,
                -40.0126,
                -39.5514,
                -39.0338
            ],
            [
                -40.4721,
                -39.4811,
                -40.5808,  ...,
                -39.6939,
                -40.7036,
                -40.1336
            ],
          ...,
            [
                -40.4239,
                -39.8161,
                -40.5938,  ...,
                -40.8954,
                -39.0805,
                -40.0893
            ],
            [
                -40.4636,
                -39.1756,
                -39.7125,  ...,
                -40.6030,
                -39.1185,
                -39.4546
            ],
            [
                -39.7504,
                -39.7050,
                -39.3268,  ...,
                -39.6831,
                -39.8361,
                -39.9861
            ]
        ],
        [
            [
                -40.8843,
                -39.1464,
                -40.4182,  ...,
                -39.4557,
                -39.7801,
                -39.5670
            ],
            [
                -39.4849,
                -41.0026,
                -40.8232,  ...,
                -40.5789,
                -39.7723,
                -39.4323
            ],
            [
                -40.7424,
                -40.1935,
                -40.6210,  ...,
                -39.5750,
                -39.5802,
                -40.3846
            ],
          ...,
            [
                -39.3121,
                -40.4910,
                -39.4969,  ...,
                -40.5150,
                -40.9332,
                -40.8797
            ],
            [
                -39.2818,
                -40.5268,
                -40.5206,  ...,
                -39.5647,
                -40.5879,
                -40.3867
            ],
            [
                -38.9672,
                -40.5074,
                -39.7096,  ...,
                -39.8363,
                -40.4329,
                -40.1496
            ]
        ],
        [
            [
                -40.4119,
                -39.9737,
                -40.9087,  ...,
                -39.0593,
                -39.3582,
                -39.2483
            ],
            [
                -40.2553,
                -39.0900,
                -40.3398,  ...,
                -40.4279,
                -40.9720,
                -39.2005
            ],
            [
                -39.5056,
                -39.6510,
                -39.9543,  ...,
                -40.5566,
                -40.5868,
                -39.1218
            ],
          ...,
            [
                -40.3151,
                -39.2219,
                -39.9889,  ...,
                -40.2859,
                -39.8882,
                -39.8055
            ],
            [
                -40.5835,
                -39.1307,
                -40.7905,  ...,
                -39.1036,
                -40.5427,
                -40.5402
            ],
            [
                -39.3419,
                -39.4780,
                -40.2891,  ...,
                -39.0638,
                -40.6181,
                -40.4507
            ]
        ]
    ],
    [
        [
            [
                -20.2109,
                -19.8480,
                -19.0993,  ...,
                -19.5869,
                -20.9313,
                -20.0909
            ],
            [
                -20.2578,
                -19.6925,
                -19.0672,  ...,
                -19.0878,
                -20.8356,
                -19.1404
            ],
            [
                -20.6849,
                -19.5318,
                -19.6466,  ...,
                -19.1668,
                -20.5096,
                -20.2644
            ],
          ...,
            [
                -19.3465,
                -19.9127,
                -20.9676,  ...,
                -18.9546,
                -18.9815,
                -19.7164
            ],
            [
                -20.2436,
                -19.3967,
                -19.4277,  ...,
                -20.6498,
                -19.8133,
                -19.7110
            ],
            [
                -19.8774,
                -20.2703,
                -20.0449,  ...,
                -19.4624,
                -19.3044,
                -19.4547
            ]
        ],
        [
            [
                -20.3713,
                -20.5757,
                -19.0435,  ...,
                -19.2490,
                -18.9899,
                -20.6424
            ],
            [
                -20.7721,
                -19.2870,
                -19.1211,  ...,
                -20.5104,
                -19.0402,
                -21.0315
            ],
            [
                -20.0910,
                -20.0160,
                -20.3067,  ...,
                -19.9362,
                -19.2767,
                -20.1733
            ],
          ...,
            [
                -19.5917,
                -19.9747,
                -20.6102,  ...,
                -20.5495,
                -20.9849,
                -20.7903
            ],
            [
                -19.2055,
                -19.1310,
                -20.7652,  ...,
                -19.8400,
                -20.6612,
                -19.9552
            ],
            [
                -19.0430,
                -20.7891,
                -18.9793,  ...,
                -20.6263,
                -20.7390,
                -20.2931
            ]
        ],
        [
            [
                -19.9436,
                -19.2204,
                -19.2273,  ...,
                -20.4001,
                -20.9141,
                -20.5480
            ],
            [
                -21.0409,
                -19.5234,
                -20.9625,  ...,
                -20.5804,
                -20.0783,
                -20.9794
            ],
            [
                -20.0061,
                -19.5451,
                -19.6274,  ...,
                -20.2707,
                -19.2451,
                -20.3112
            ],
          ...,
            [
                -19.2194,
                -19.3157,
                -20.2443,  ...,
                -20.4104,
                -20.8503,
                -19.7388
            ],
            [
                -20.0741,
                -19.9079,
                -19.9450,  ...,
                -20.2977,
                -19.0715,
                -19.2173
            ],
            [
                -19.1618,
                -19.2155,
                -20.4080,  ...,
                -19.6423,
                -19.9783,
                -20.2241
            ]
        ]
    ],
    [
        [
            [
                -20.5794,
                -20.4913,
                -20.5205,  ...,
                -20.2779,
                -19.9005,
                -20.1339
            ],
            [
                -19.4428,
                -20.2364,
                -19.0955,  ...,
                -19.0119,
                -20.3837,
                -20.5722
            ],
            [
                -20.2161,
                -20.8989,
                -20.5703,  ...,
                -20.0062,
                -20.5495,
                -20.3018
            ],
          ...,
            [
                -19.1665,
                -20.1242,
                -19.3109,  ...,
                -19.7056,
                -19.2270,
                -19.9492
            ],
            [
                -19.9828,
                -19.9731,
                -19.6528,  ...,
                -20.2815,
                -19.6517,
                -20.1800
            ],
            [
                -20.8788,
                -20.6124,
                -19.3086,  ...,
                -20.0262,
                -20.6366,
                -20.5516
            ]
        ],
        [
            [
                -19.0823,
                -20.2787,
                -19.0776,  ...,
                -20.4534,
                -20.4824,
                -19.5810
            ],
            [
                -20.5789,
                -20.7165,
                -19.6512,  ...,
                -20.0996,
                -19.5784,
                -19.8229
            ],
            [
                -19.4689,
                -20.5573,
                -20.2476,  ...,
                -19.5643,
                -19.8912,
                -19.1437
            ],
          ...,
            [
                -19.5676,
                -20.7007,
                -20.4604,  ...,
                -20.6611,
                -19.7496,
                -19.6100
            ],
            [
                -20.0673,
                -20.8602,
                -19.9078,  ...,
                -19.8925,
                -19.5235,
                -19.3454
            ],
            [
                -20.0120,
                -20.4448,
                -20.2070,  ...,
                -20.1875,
                -19.2379,
                -20.2773
            ]
        ],
        [
            [
                -20.2322,
                -20.9981,
                -20.1324,  ...,
                -20.6868,
                -19.1976,
                -20.2558
            ],
            [
                -19.9429,
                -19.8036,
                -20.0564,  ...,
                -19.4659,
                -19.1548,
                -20.5309
            ],
            [
                -19.1726,
                -20.9294,
                -19.4132,  ...,
                -20.2518,
                -20.4123,
                -19.1027
            ],
          ...,
            [
                -19.0001,
                -20.7225,
                -19.0490,  ...,
                -20.5121,
                -19.4237,
                -19.4732
            ],
            [
                -19.7071,
                -20.1467,
                -19.4109,  ...,
                -20.9051,
                -19.1359,
                -20.8461
            ],
            [
                -20.8643,
                -19.7482,
                -20.5375,  ...,
                -20.7055,
                -20.5733,
                -20.0376
            ]
        ]
    ],


        ...,
    [
        [
            [
                -39.8872,
                -40.1649,
                -39.6610,  ...,
                -39.1241,
                -39.6038,
                -40.3777
            ],
            [
                -39.3703,
                -40.7990,
                -39.1511,  ...,
                -40.3829,
                -39.2040,
                -40.2283
            ],
            [
                -40.2896,
                -39.4855,
                -40.0982,  ...,
                -40.4589,
                -40.0411,
                -40.5423
            ],
          ...,
            [
                -40.1584,
                -39.3376,
                -39.3168,  ...,
                -39.6544,
                -39.7754,
                -38.9902
            ],
            [
                -39.3012,
                -40.6970,
                -39.8127,  ...,
                -40.7952,
                -40.5459,
                -38.9251
            ],
            [
                -39.5477,
                -39.5051,
                -39.5448,  ...,
                -40.3402,
                -39.8232,
                -39.0010
            ]
        ],
        [
            [
                -40.6370,
                -40.2747,
                -40.2956,  ...,
                -40.5184,
                -39.0320,
                -39.8399
            ],
            [
                -39.1102,
                -40.5463,
                -39.5075,  ...,
                -40.5153,
                -39.2442,
                -39.4460
            ],
            [
                -40.0974,
                -39.9974,
                -40.1973,  ...,
                -40.8183,
                -40.1967,
                -40.3270
            ],
          ...,
            [
                -40.3680,
                -39.6781,
                -40.5793,  ...,
                -40.4569,
                -39.4776,
                -39.6272
            ],
            [
                -40.8306,
                -40.1066,
                -40.4524,  ...,
                -40.6593,
                -40.8473,
                -39.7869
            ],
            [
                -40.4671,
                -40.6627,
                -40.6572,  ...,
                -40.7930,
                -40.2715,
                -40.4168
            ]
        ],
        [
            [
                -40.0791,
                -40.0041,
                -40.3882,  ...,
                -40.0011,
                -40.0236,
                -39.2596
            ],
            [
                -39.7578,
                -39.3596,
                -39.1832,  ...,
                -39.1428,
                -39.5689,
                -39.9485
            ],
            [
                -38.9610,
                -39.8102,
                -40.9746,  ...,
                -39.9494,
                -39.0600,
                -40.3697
            ],
          ...,
            [
                -40.7068,
                -39.5544,
                -40.7849,  ...,
                -40.5589,
                -40.2836,
                -39.3246
            ],
            [
                -39.4840,
                -40.4494,
                -39.0866,  ...,
                -39.7250,
                -39.7144,
                -40.6973
            ],
            [
                -40.3855,
                -39.8681,
                -40.5396,  ...,
                -39.9538,
                -40.2367,
                -40.2056
            ]
        ]
    ],
    [
        [
            [
                -19.8134,
                -19.5771,
                -20.1235,  ...,
                -19.3466,
                -19.2728,
                -20.1263
            ],
            [
                -19.6614,
                -19.4885,
                -20.1880,  ...,
                -20.8362,
                -19.3422,
                -19.2179
            ],
            [
                -19.2282,
                -19.3396,
                -19.2031,  ...,
                -20.1468,
                -20.9574,
                -19.7699
            ],
          ...,
            [
                -20.8136,
                -19.4686,
                -19.3305,  ...,
                -20.5390,
                -20.2107,
                -20.4209
            ],
            [
                -20.0186,
                -20.3779,
                -19.6263,  ...,
                -19.5824,
                -20.4230,
                -20.2857
            ],
            [
                -20.7712,
                -20.5719,
                -20.1074,  ...,
                -20.5791,
                -20.5340,
                -20.0565
            ]
        ],
        [
            [
                -20.7834,
                -19.8248,
                -19.8193,  ...,
                -20.7232,
                -19.1294,
                -19.3059
            ],
            [
                -20.6587,
                -19.6529,
                -19.8040,  ...,
                -20.4709,
                -19.3834,
                -19.0762
            ],
            [
                -20.6939,
                -19.0381,
                -19.7193,  ...,
                -19.5787,
                -20.8454,
                -20.7287
            ],
          ...,
            [
                -19.9754,
                -19.7824,
                -19.2273,  ...,
                -18.9384,
                -19.0888,
                -19.8762
            ],
            [
                -19.1104,
                -19.0819,
                -20.2588,  ...,
                -19.1715,
                -20.3346,
                -20.5303
            ],
            [
                -20.3684,
                -20.2239,
                -20.7860,  ...,
                -19.5542,
                -19.8280,
                -20.3908
            ]
        ],
        [
            [
                -20.2102,
                -20.5214,
                -19.5935,  ...,
                -21.0170,
                -19.3848,
                -19.3979
            ],
            [
                -20.5679,
                -20.4781,
                -19.0210,  ...,
                -19.6855,
                -19.2313,
                -20.7368
            ],
            [
                -20.4907,
                -19.3204,
                -20.7794,  ...,
                -20.6500,
                -19.3620,
                -20.5137
            ],
          ...,
            [
                -20.9525,
                -20.6341,
                -19.9797,  ...,
                -19.9489,
                -20.0212,
                -19.8366
            ],
            [
                -19.3968,
                -20.4077,
                -20.4605,  ...,
                -20.6339,
                -20.8949,
                -20.0452
            ],
            [
                -20.1789,
                -20.3427,
                -20.1910,  ...,
                -20.5368,
                -19.3971,
                -18.9992
            ]
        ]
    ],
    [
        [
            [
                -19.6023,
                -19.2240,
                -19.7744,  ...,
                -19.1125,
                -19.1279,
                -20.8498
            ],
            [
                -20.1009,
                -20.0261,
                -19.7973,  ...,
                -19.5654,
                -19.8648,
                -19.5118
            ],
            [
                -19.0622,
                -20.7879,
                -20.4326,  ...,
                -20.2195,
                -19.7504,
                -19.6870
            ],
          ...,
            [
                -20.5933,
                -20.9925,
                -20.3899,  ...,
                -19.3721,
                -20.0624,
                -20.9204
            ],
            [
                -19.7895,
                -19.4681,
                -19.8473,  ...,
                -19.6743,
                -19.1280,
                -20.4149
            ],
            [
                -20.1992,
                -19.6658,
                -19.2532,  ...,
                -19.2112,
                -19.4364,
                -20.2846
            ]
        ],
        [
            [
                -19.0702,
                -19.9331,
                -18.9928,  ...,
                -20.4923,
                -20.4244,
                -19.0197
            ],
            [
                -20.3744,
                -20.2180,
                -19.9650,  ...,
                -20.7994,
                -19.6674,
                -20.2156
            ],
            [
                -20.5337,
                -20.1545,
                -19.1300,  ...,
                -20.4238,
                -20.6623,
                -20.0496
            ],
          ...,
            [
                -19.1713,
                -19.3247,
                -20.6349,  ...,
                -20.0333,
                -19.9828,
                -19.0986
            ],
            [
                -18.9466,
                -20.8167,
                -19.6269,  ...,
                -20.5999,
                -19.4833,
                -19.0992
            ],
            [
                -20.1037,
                -19.9803,
                -19.2546,  ...,
                -20.5397,
                -19.6774,
                -20.4054
            ]
        ],
        [
            [
                -19.4312,
                -20.8222,
                -20.0069,  ...,
                -20.6478,
                -19.9307,
                -20.6624
            ],
            [
                -20.4700,
                -19.3120,
                -19.6787,  ...,
                -19.9195,
                -19.0150,
                -20.1982
            ],
            [
                -19.6172,
                -19.0070,
                -19.1691,  ...,
                -19.7794,
                -20.4255,
                -20.9748
            ],
          ...,
            [
                -20.8459,
                -20.6898,
                -19.5020,  ...,
                -19.7956,
                -19.0237,
                -20.4424
            ],
            [
                -20.1914,
                -19.6258,
                -20.1527,  ...,
                -20.0733,
                -19.4920,
                -20.7170
            ],
            [
                -19.7617,
                -19.2425,
                -19.5874,  ...,
                -20.5418,
                -20.5899,
                -20.6111
            ]
        ]
    ]
],
       device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.2179,
        -0.4216,
        0.9724
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.2179,
        -0.4216,
        0.9724
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.2179,
        -0.4216,
        0.9724
    ],
        ...,
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.2179,
        -0.4216,
        0.9724
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.2179,
        -0.4216,
        0.9724
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.2179,
        -0.4216,
        0.9724
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
tensor([
    [
        -0.5551,
        0.7414,
        -0.3650,  ...,
        0.3155,
        -0.7166,
        1.1608
    ],
    [
        -0.5770,
        0.7658,
        -0.3134,  ...,
        0.3375,
        -0.6862,
        1.1522
    ],
    [
        -0.5331,
        0.7006,
        -0.2790,  ...,
        0.3330,
        -0.6937,
        1.1062
    ],
        ...,
    [
        -0.6025,
        0.6895,
        -0.2293,  ...,
        0.3008,
        -0.6155,
        1.1566
    ],
    [
        -0.5434,
        0.6813,
        -0.2295,  ...,
        0.2494,
        -0.7016,
        1.1610
    ],
    [
        -0.5993,
        0.7403,
        -0.3378,  ...,
        0.3343,
        -0.6794,
        1.0988
    ]
],
       device='cuda: 0', grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1066,
        -0.3616,
        0.7035
    ],
    [
        0.1319,
        0.0183,
        -0.2529,  ...,
        0.1066,
        -0.3616,
        0.7035
    ],
    [
        0.1319,
        0.0183,
        -0.2529,  ...,
        0.1066,
        -0.3616,
        0.7035
    ],
        ...,
    [
        0.1319,
        0.0183,
        -0.2529,  ...,
        0.1066,
        -0.3616,
        0.7035
    ],
    [
        0.1319,
        0.0183,
        -0.2529,  ...,
        0.1066,
        -0.3616,
        0.7035
    ],
    [
        0.1319,
        0.0183,
        -0.2529,  ...,
        0.1066,
        -0.3616,
        0.7035
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(3.5304, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(0.0006, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 4/3125 [
    00: 26<5: 41: 48,
    6.57s/it, loss=2.63, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [
        -0.1117,
        0.2580,
        -0.0959,  ...,
        0.0691,
        -0.2159,
        0.2750
    ],
    [
        -0.3700,
        0.7106,
        -0.1503,  ...,
        0.2309,
        -0.4984,
        0.8295
    ],
    [
        -0.1130,
        0.2588,
        -0.0945,  ...,
        0.0685,
        -0.2163,
        0.2765
    ],
        ...,
    [
        -0.1139,
        0.2584,
        -0.0946,  ...,
        0.0711,
        -0.2141,
        0.2755
    ],
    [
        -0.1094,
        0.2599,
        -0.0914,  ...,
        0.0686,
        -0.2165,
        0.2751
    ],
    [
        -0.1106,
        0.2589,
        -0.0947,  ...,
        0.0660,
        -0.2160,
        0.2768
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0262,
        0.1072,
        -0.2100
    ],
    [
        0.5033,
        -0.7719,
        0.0684,  ...,
        -0.0262,
        0.1072,
        -0.2100
    ],
    [
        0.5033,
        -0.7719,
        0.0684,  ...,
        -0.0262,
        0.1072,
        -0.2100
    ],
        ...,
    [
        0.5033,
        -0.7719,
        0.0684,  ...,
        -0.0262,
        0.1072,
        -0.2100
    ],
    [
        0.5033,
        -0.7719,
        0.0684,  ...,
        -0.0262,
        0.1072,
        -0.2100
    ],
    [
        0.5033,
        -0.7719,
        0.0684,  ...,
        -0.0262,
        0.1072,
        -0.2100
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -648.2523,
    -704.5681,
    -660.5258,
    -704.5627,
    -664.8676,
    -702.5802,
    -651.9033,
    -664.5533,
    -675.6494,
    -695.9161,
    -664.6173,
    -693.5490,
    -699.9928,
    -650.6832,
    -673.5743,
    -660.9053
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -648.2523,
    -704.5681,
    -660.5257,
    -704.5627,
    -664.8676,
    -702.5802,
    -651.9034,
    -664.5533,
    -675.6494,
    -695.9160,
    -664.6173,
    -693.5490,
    -699.9928,
    -650.6832,
    -673.5743,
    -660.9053
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(3.9680, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1228,
        0.2420,
        -0.0746,  ...,
        0.0471,
        -0.2022,
        0.2686
    ],
    [
        -0.4056,
        0.7825,
        -0.1551,  ...,
        0.2649,
        -0.5486,
        0.9164
    ],
    [
        -0.1251,
        0.2420,
        -0.0728,  ...,
        0.0454,
        -0.2015,
        0.2693
    ],
        ...,
    [
        -0.1262,
        0.2423,
        -0.0727,  ...,
        0.0492,
        -0.1993,
        0.2676
    ],
    [
        -0.1221,
        0.2415,
        -0.0708,  ...,
        0.0468,
        -0.1980,
        0.2678
    ],
    [
        -0.1222,
        0.2408,
        -0.0743,  ...,
        0.0448,
        -0.2011,
        0.2681
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1117,
            0.2580,
            -0.0959,  ...,
            0.0691,
            -0.2159,
            0.2750
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.3700,
            0.7106,
            -0.1503,  ...,
            0.2309,
            -0.4984,
            0.8295
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1130,
            0.2588,
            -0.0945,  ...,
            0.0685,
            -0.2163,
            0.2765
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0474,
        0.1221,
        -0.2187
    ],
    [
        0.4922,
        -0.7879,
        0.0896,  ...,
        -0.0474,
        0.1221,
        -0.2187
    ],
    [
        0.4922,
        -0.7879,
        0.0896,  ...,
        -0.0474,
        0.1221,
        -0.2187
    ],
        ...,
    [
        0.4922,
        -0.7879,
        0.0896,  ...,
        -0.0474,
        0.1221,
        -0.2187
    ],
    [
        0.4922,
        -0.7879,
        0.0896,  ...,
        -0.0474,
        0.1221,
        -0.2187
    ],
    [
        0.4922,
        -0.7879,
        0.0896,  ...,
        -0.0474,
        0.1221,
        -0.2187
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -691.1921,
    -750.7000,
    -703.7668,
    -750.8627,
    -708.2180,
    -749.5495,
    -694.8902,
    -707.9473,
    -719.4435,
    -746.0637,
    -708.0148,
    -743.9518,
    -748.4740,
    -693.6166,
    -717.2100,
    -704.1168
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -691.1921,
    -750.7000,
    -703.7668,
    -750.8626,
    -708.2180,
    -749.5494,
    -694.8901,
    -707.9473,
    -719.4434,
    -746.0637,
    -708.0148,
    -743.9518,
    -748.4741,
    -693.6166,
    -717.2099,
    -704.1168
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(4.4145, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1337,
        0.2368,
        -0.0473,  ...,
        0.0285,
        -0.1831,
        0.2807
    ],
    [
        -0.4415,
        0.8571,
        -0.1585,  ...,
        0.2984,
        -0.6001,
        1.0053
    ],
    [
        -0.1356,
        0.2362,
        -0.0448,  ...,
        0.0280,
        -0.1832,
        0.2810
    ],
        ...,
    [
        -0.1397,
        0.2350,
        -0.0452,  ...,
        0.0317,
        -0.1811,
        0.2810
    ],
    [
        -0.1345,
        0.2347,
        -0.0439,  ...,
        0.0297,
        -0.1797,
        0.2801
    ],
    [
        -0.1349,
        0.2351,
        -0.0465,  ...,
        0.0284,
        -0.1826,
        0.2805
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1228,
            0.2420,
            -0.0746,  ...,
            0.0471,
            -0.2022,
            0.2686
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4056,
            0.7825,
            -0.1551,  ...,
            0.2649,
            -0.5486,
            0.9164
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1251,
            0.2420,
            -0.0728,  ...,
            0.0454,
            -0.2015,
            0.2693
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0638,
        0.1405,
        -0.2062
    ],
    [
        0.4813,
        -0.7930,
        0.1170,  ...,
        -0.0638,
        0.1405,
        -0.2062
    ],
    [
        0.4813,
        -0.7930,
        0.1170,  ...,
        -0.0638,
        0.1405,
        -0.2062
    ],
        ...,
    [
        0.4813,
        -0.7930,
        0.1170,  ...,
        -0.0638,
        0.1405,
        -0.2062
    ],
    [
        0.4813,
        -0.7930,
        0.1170,  ...,
        -0.0638,
        0.1405,
        -0.2062
    ],
    [
        0.4813,
        -0.7930,
        0.1170,  ...,
        -0.0638,
        0.1405,
        -0.2062
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -736.9443,
    -797.4631,
    -749.6948,
    -797.7955,
    -754.2682,
    -797.1638,
    -740.7177,
    -753.9954,
    -765.7029,
    -796.8956,
    -753.9966,
    -795.0244,
    -797.6166,
    -739.3034,
    -763.4072,
    -750.0610
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -736.9443,
    -797.4631,
    -749.6948,
    -797.7955,
    -754.2681,
    -797.1638,
    -740.7177,
    -753.9954,
    -765.7029,
    -796.8956,
    -753.9966,
    -795.0244,
    -797.6166,
    -739.3034,
    -763.4072,
    -750.0610
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(4.8818, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1512,
        0.2384,
        -0.0288,  ...,
        0.0142,
        -0.1778,
        0.2985
    ],
    [
        -0.4782,
        0.9324,
        -0.1614,  ...,
        0.3332,
        -0.6520,
        1.0956
    ],
    [
        -0.1494,
        0.2371,
        -0.0269,  ...,
        0.0156,
        -0.1780,
        0.3002
    ],
        ...,
    [
        -0.1518,
        0.2364,
        -0.0287,  ...,
        0.0159,
        -0.1794,
        0.3011
    ],
    [
        -0.1526,
        0.2346,
        -0.0249,  ...,
        0.0172,
        -0.1771,
        0.2961
    ],
    [
        -0.1502,
        0.2360,
        -0.0279,  ...,
        0.0167,
        -0.1767,
        0.3009
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1337,
            0.2368,
            -0.0473,  ...,
            0.0285,
            -0.1831,
            0.2807
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4415,
            0.8571,
            -0.1585,  ...,
            0.2984,
            -0.6001,
            1.0053
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1356,
            0.2362,
            -0.0448,  ...,
            0.0280,
            -0.1832,
            0.2810
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0755,
        0.1465,
        -0.1858
    ],
    [
        0.4638,
        -0.7915,
        0.1355,  ...,
        -0.0755,
        0.1465,
        -0.1858
    ],
    [
        0.4638,
        -0.7915,
        0.1355,  ...,
        -0.0755,
        0.1465,
        -0.1858
    ],
        ...,
    [
        0.4638,
        -0.7915,
        0.1355,  ...,
        -0.0755,
        0.1465,
        -0.1858
    ],
    [
        0.4638,
        -0.7915,
        0.1355,  ...,
        -0.0755,
        0.1465,
        -0.1858
    ],
    [
        0.4638,
        -0.7915,
        0.1355,  ...,
        -0.0755,
        0.1465,
        -0.1858
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -783.9215,
    -843.1332,
    -796.6997,
    -843.6400,
    -801.3654,
    -843.6985,
    -787.7068,
    -801.0918,
    -812.9806,
    -846.6691,
    -801.0704,
    -845.0414,
    -845.6929,
    -786.3162,
    -810.5770,
    -797.2000
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -783.9215,
    -843.1332,
    -796.6998,
    -843.6401,
    -801.3654,
    -843.6985,
    -787.7068,
    -801.0919,
    -812.9805,
    -846.6691,
    -801.0704,
    -845.0415,
    -845.6929,
    -786.3162,
    -810.5769,
    -797.1998
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(5.3541, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1725,
        0.2328,
        -0.0210,  ...,
        0.0163,
        -0.1930,
        0.2965
    ],
    [
        -0.5146,
        1.0084,
        -0.1635,  ...,
        0.3684,
        -0.7044,
        1.1869
    ],
    [
        -0.1664,
        0.2340,
        -0.0181,  ...,
        0.0166,
        -0.1901,
        0.3011
    ],
        ...,
    [
        -0.1740,
        0.2343,
        -0.0201,  ...,
        0.0177,
        -0.1926,
        0.2996
    ],
    [
        -0.1743,
        0.2297,
        -0.0149,  ...,
        0.0183,
        -0.1920,
        0.2954
    ],
    [
        -0.1682,
        0.2338,
        -0.0197,  ...,
        0.0169,
        -0.1922,
        0.2995
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1512,
            0.2384,
            -0.0288,  ...,
            0.0142,
            -0.1778,
            0.2985
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4782,
            0.9324,
            -0.1614,  ...,
            0.3332,
            -0.6520,
            1.0956
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1494,
            0.2371,
            -0.0269,  ...,
            0.0156,
            -0.1780,
            0.3002
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0753,
        0.1310,
        -0.1873
    ],
    [
        0.4425,
        -0.7970,
        0.1433,  ...,
        -0.0753,
        0.1310,
        -0.1873
    ],
    [
        0.4425,
        -0.7970,
        0.1433,  ...,
        -0.0753,
        0.1310,
        -0.1873
    ],
        ...,
    [
        0.4425,
        -0.7970,
        0.1433,  ...,
        -0.0753,
        0.1310,
        -0.1873
    ],
    [
        0.4425,
        -0.7970,
        0.1433,  ...,
        -0.0753,
        0.1310,
        -0.1873
    ],
    [
        0.4425,
        -0.7970,
        0.1433,  ...,
        -0.0753,
        0.1310,
        -0.1873
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -839.6176,
    -895.8471,
    -852.3802,
    -896.5347,
    -857.0688,
    -897.2861,
    -843.3103,
    -856.8463,
    -868.6327,
    -903.5179,
    -856.7587,
    -902.1404,
    -900.8259,
    -841.9896,
    -866.2867,
    -852.9502
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -839.6175,
    -895.8472,
    -852.3803,
    -896.5347,
    -857.0688,
    -897.2861,
    -843.3104,
    -856.8463,
    -868.6328,
    -903.5179,
    -856.7587,
    -902.1404,
    -900.8259,
    -841.9896,
    -866.2867,
    -852.9502
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(5.9082, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1678,
        0.2313,
        -0.0247,  ...,
        0.0208,
        -0.2047,
        0.3009
    ],
    [
        -0.5510,
        1.0837,
        -0.1648,  ...,
        0.4042,
        -0.7561,
        1.2776
    ],
    [
        -0.1685,
        0.2333,
        -0.0240,  ...,
        0.0232,
        -0.2042,
        0.3017
    ],
        ...,
    [
        -0.1705,
        0.2326,
        -0.0245,  ...,
        0.0199,
        -0.2055,
        0.2990
    ],
    [
        -0.1711,
        0.2287,
        -0.0228,  ...,
        0.0232,
        -0.2035,
        0.2985
    ],
    [
        -0.1667,
        0.2319,
        -0.0224,  ...,
        0.0202,
        -0.2046,
        0.3026
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1725,
            0.2328,
            -0.0210,  ...,
            0.0163,
            -0.1930,
            0.2965
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.5146,
            1.0084,
            -0.1635,  ...,
            0.3684,
            -0.7044,
            1.1869
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1664,
            0.2340,
            -0.0181,  ...,
            0.0166,
            -0.1901,
            0.3011
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0719,
        0.1185,
        -0.1842
    ],
    [
        0.4472,
        -0.7986,
        0.1396,  ...,
        -0.0719,
        0.1185,
        -0.1842
    ],
    [
        0.4472,
        -0.7986,
        0.1396,  ...,
        -0.0719,
        0.1185,
        -0.1842
    ],
        ...,
    [
        0.4472,
        -0.7986,
        0.1396,  ...,
        -0.0719,
        0.1185,
        -0.1842
    ],
    [
        0.4472,
        -0.7986,
        0.1396,  ...,
        -0.0719,
        0.1185,
        -0.1842
    ],
    [
        0.4472,
        -0.7986,
        0.1396,  ...,
        -0.0719,
        0.1185,
        -0.1842
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -913.0594,
    -965.5895,
    -925.8800,
    -966.4518,
    -930.5430,
    -967.9112,
    -916.7485,
    -930.2753,
    -942.1572,
    -977.4316,
    -930.3359,
    -976.3051,
    -973.0180,
    -915.4579,
    -939.8715,
    -926.4980
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -913.0594,
    -965.5894,
    -925.8800,
    -966.4517,
    -930.5430,
    -967.9112,
    -916.7485,
    -930.2753,
    -942.1572,
    -977.4316,
    -930.3359,
    -976.3051,
    -973.0179,
    -915.4580,
    -939.8715,
    -926.4980
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(6.6382, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1744,
        0.2291,
        -0.0283,  ...,
        0.0272,
        -0.2031,
        0.3029
    ],
    [
        -0.5881,
        1.1588,
        -0.1666,  ...,
        0.4408,
        -0.8073,
        1.3689
    ],
    [
        -0.1751,
        0.2311,
        -0.0296,  ...,
        0.0275,
        -0.2038,
        0.3046
    ],
        ...,
    [
        -0.1764,
        0.2260,
        -0.0279,  ...,
        0.0261,
        -0.2040,
        0.2988
    ],
    [
        -0.1742,
        0.2292,
        -0.0301,  ...,
        0.0268,
        -0.2025,
        0.3023
    ],
    [
        -0.1756,
        0.2312,
        -0.0270,  ...,
        0.0262,
        -0.2027,
        0.3025
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1678,
            0.2313,
            -0.0247,  ...,
            0.0208,
            -0.2047,
            0.3009
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.5510,
            1.0837,
            -0.1648,  ...,
            0.4042,
            -0.7561,
            1.2776
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1685,
            0.2333,
            -0.0240,  ...,
            0.0232,
            -0.2042,
            0.3017
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0660,
        0.1205,
        -0.1843
    ],
    [
        0.4406,
        -0.8007,
        0.1360,  ...,
        -0.0660,
        0.1205,
        -0.1843
    ],
    [
        0.4406,
        -0.8007,
        0.1360,  ...,
        -0.0660,
        0.1205,
        -0.1843
    ],
        ...,
    [
        0.4406,
        -0.8007,
        0.1360,  ...,
        -0.0660,
        0.1205,
        -0.1843
    ],
    [
        0.4406,
        -0.8007,
        0.1360,  ...,
        -0.0660,
        0.1205,
        -0.1843
    ],
    [
        0.4406,
        -0.8007,
        0.1360,  ...,
        -0.0660,
        0.1205,
        -0.1843
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1000.9669,
    -1048.5955,
    -1013.7841,
    -1049.6355,
    -1018.4417,
    -1051.8013,
    -1004.6027,
    -1018.1484,
    -1030.1121,
    -1064.6375,
    -1018.2084,
    -1063.7592,
    -1058.4855,
    -1003.1956,
    -1027.8313,
    -1014.3582
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1000.9668,
    -1048.5955,
    -1013.7839,
    -1049.6355,
    -1018.4417,
    -1051.8011,
    -1004.6026,
    -1018.1484,
    -1030.1121,
    -1064.6373,
    -1018.2084,
    -1063.7593,
    -1058.4855,
    -1003.1955,
    -1027.8312,
    -1014.3582
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(7.5087, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1741,
        0.2209,
        -0.0232,  ...,
        0.0301,
        -0.1956,
        0.3049
    ],
    [
        -0.6257,
        1.2345,
        -0.1678,  ...,
        0.4779,
        -0.8582,
        1.4606
    ],
    [
        -0.1745,
        0.2228,
        -0.0247,  ...,
        0.0294,
        -0.1966,
        0.3049
    ],
        ...,
    [
        -0.1729,
        0.2161,
        -0.0220,  ...,
        0.0299,
        -0.1955,
        0.3012
    ],
    [
        -0.1744,
        0.2195,
        -0.0271,  ...,
        0.0298,
        -0.1933,
        0.3028
    ],
    [
        -0.1772,
        0.2216,
        -0.0234,  ...,
        0.0283,
        -0.1921,
        0.3018
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1744,
            0.2291,
            -0.0283,  ...,
            0.0272,
            -0.2031,
            0.3029
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.5881,
            1.1588,
            -0.1666,  ...,
            0.4408,
            -0.8073,
            1.3689
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1751,
            0.2311,
            -0.0296,  ...,
            0.0275,
            -0.2038,
            0.3046
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0639,
        0.1311,
        -0.1850
    ],
    [
        0.4409,
        -0.8089,
        0.1411,  ...,
        -0.0639,
        0.1311,
        -0.1850
    ],
    [
        0.4409,
        -0.8089,
        0.1411,  ...,
        -0.0639,
        0.1311,
        -0.1850
    ],
        ...,
    [
        0.4409,
        -0.8089,
        0.1411,  ...,
        -0.0639,
        0.1311,
        -0.1850
    ],
    [
        0.4409,
        -0.8089,
        0.1411,  ...,
        -0.0639,
        0.1311,
        -0.1850
    ],
    [
        0.4409,
        -0.8089,
        0.1411,  ...,
        -0.0639,
        0.1311,
        -0.1850
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1105.4473,
    -1147.1804,
    -1118.2317,
    -1148.4119,
    -1122.8643,
    -1151.2822,
    -1109.0326,
    -1122.6010,
    -1134.5985,
    -1167.4519,
    -1122.6443,
    -1166.8280,
    -1159.5566,
    -1107.6572,
    -1132.2886,
    -1118.8318
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1105.4474,
    -1147.1804,
    -1118.2317,
    -1148.4119,
    -1122.8643,
    -1151.2822,
    -1109.0325,
    -1122.6012,
    -1134.5984,
    -1167.4519,
    -1122.6444,
    -1166.8279,
    -1159.5568,
    -1107.6573,
    -1132.2885,
    -1118.8319
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(8.5419, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1720,
        0.2075,
        -0.0151,  ...,
        0.0290,
        -0.1891,
        0.2978
    ],
    [
        -0.6633,
        1.3108,
        -0.1688,  ...,
        0.5151,
        -0.9095,
        1.5529
    ],
    [
        -0.1740,
        0.2090,
        -0.0147,  ...,
        0.0299,
        -0.1885,
        0.2996
    ],
        ...,
    [
        -0.1716,
        0.2065,
        -0.0133,  ...,
        0.0307,
        -0.1898,
        0.2970
    ],
    [
        -0.1737,
        0.2060,
        -0.0144,  ...,
        0.0302,
        -0.1905,
        0.2990
    ],
    [
        -0.1718,
        0.2073,
        -0.0141,  ...,
        0.0297,
        -0.1865,
        0.2979
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1741,
            0.2209,
            -0.0232,  ...,
            0.0301,
            -0.1956,
            0.3049
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.6257,
            1.2345,
            -0.1678,  ...,
            0.4779,
            -0.8582,
            1.4606
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1745,
            0.2228,
            -0.0247,  ...,
            0.0294,
            -0.1966,
            0.3049
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0625,
        0.1367,
        -0.1889
    ],
    [
        0.4430,
        -0.8224,
        0.1492,  ...,
        -0.0625,
        0.1367,
        -0.1889
    ],
    [
        0.4430,
        -0.8224,
        0.1492,  ...,
        -0.0625,
        0.1367,
        -0.1889
    ],
        ...,
    [
        0.4430,
        -0.8224,
        0.1492,  ...,
        -0.0625,
        0.1367,
        -0.1889
    ],
    [
        0.4430,
        -0.8224,
        0.1492,  ...,
        -0.0625,
        0.1367,
        -0.1889
    ],
    [
        0.4430,
        -0.8224,
        0.1492,  ...,
        -0.0625,
        0.1367,
        -0.1889
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1220.0038,
    -1254.3921,
    -1232.8422,
    -1255.8007,
    -1237.5671,
    -1259.3962,
    -1223.6497,
    -1237.2268,
    -1249.2395,
    -1278.9043,
    -1237.2185,
    -1278.5377,
    -1269.2498,
    -1222.4478,
    -1246.8899,
    -1233.4248
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1220.0037,
    -1254.3920,
    -1232.8420,
    -1255.8008,
    -1237.5673,
    -1259.3961,
    -1223.6498,
    -1237.2267,
    -1249.2395,
    -1278.9043,
    -1237.2186,
    -1278.5380,
    -1269.2499,
    -1222.4478,
    -1246.8899,
    -1233.4248
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(9.6717, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1671,
        0.1980,
        0.0035,  ...,
        0.0291,
        -0.1865,
        0.3000
    ],
    [
        -0.7013,
        1.3869,
        -0.1692,  ...,
        0.5522,
        -0.9609,
        1.6458
    ],
    [
        -0.1685,
        0.1981,
        0.0031,  ...,
        0.0310,
        -0.1885,
        0.2990
    ],
        ...,
    [
        -0.1673,
        0.1971,
        0.0053,  ...,
        0.0326,
        -0.1872,
        0.2968
    ],
    [
        -0.1684,
        0.1964,
        0.0050,  ...,
        0.0318,
        -0.1878,
        0.2990
    ],
    [
        -0.1651,
        0.1964,
        0.0039,  ...,
        0.0317,
        -0.1850,
        0.2960
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1720,
            0.2075,
            -0.0151,  ...,
            0.0290,
            -0.1891,
            0.2978
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.6633,
            1.3108,
            -0.1688,  ...,
            0.5151,
            -0.9095,
            1.5529
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1740,
            0.2090,
            -0.0147,  ...,
            0.0299,
            -0.1885,
            0.2996
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0605,
        0.1382,
        -0.1908
    ],
    [
        0.4479,
        -0.8318,
        0.1678,  ...,
        -0.0605,
        0.1382,
        -0.1908
    ],
    [
        0.4479,
        -0.8318,
        0.1678,  ...,
        -0.0605,
        0.1382,
        -0.1908
    ],
        ...,
    [
        0.4479,
        -0.8318,
        0.1678,  ...,
        -0.0605,
        0.1382,
        -0.1908
    ],
    [
        0.4479,
        -0.8318,
        0.1678,  ...,
        -0.0605,
        0.1382,
        -0.1908
    ],
    [
        0.4479,
        -0.8318,
        0.1678,  ...,
        -0.0605,
        0.1382,
        -0.1908
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1350.3995,
    -1376.2388,
    -1363.1079,
    -1377.8202,
    -1367.9312,
    -1382.1633,
    -1354.0194,
    -1367.5359,
    -1379.5260,
    -1405.0195,
    -1367.6040,
    -1404.9064,
    -1393.6074,
    -1352.8301,
    -1377.2219,
    -1363.7513
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1350.3997,
    -1376.2386,
    -1363.1077,
    -1377.8204,
    -1367.9312,
    -1382.1632,
    -1354.0193,
    -1367.5359,
    -1379.5260,
    -1405.0194,
    -1367.6039,
    -1404.9065,
    -1393.6073,
    -1352.8303,
    -1377.2218,
    -1363.7513
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(10.9545, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1591,
        0.1947,
        0.0066,  ...,
        0.0210,
        -0.1612,
        0.2953
    ],
    [
        -0.7397,
        1.4636,
        -0.1709,  ...,
        0.5900,
        -1.0129,
        1.7387
    ],
    [
        -0.1592,
        0.1939,
        0.0059,  ...,
        0.0226,
        -0.1615,
        0.2961
    ],
        ...,
    [
        -0.1596,
        0.1936,
        0.0066,  ...,
        0.0245,
        -0.1617,
        0.2952
    ],
    [
        -0.1601,
        0.1941,
        0.0064,  ...,
        0.0228,
        -0.1628,
        0.2958
    ],
    [
        -0.1579,
        0.1933,
        0.0049,  ...,
        0.0247,
        -0.1597,
        0.2933
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1671,
            0.1980,
            0.0035,  ...,
            0.0291,
            -0.1865,
            0.3000
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.7013,
            1.3869,
            -0.1692,  ...,
            0.5522,
            -0.9609,
            1.6458
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1685,
            0.1981,
            0.0031,  ...,
            0.0310,
            -0.1885,
            0.2990
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0675,
        0.1635,
        -0.1935
    ],
    [
        0.4559,
        -0.8351,
        0.1709,  ...,
        -0.0675,
        0.1635,
        -0.1935
    ],
    [
        0.4559,
        -0.8351,
        0.1709,  ...,
        -0.0675,
        0.1635,
        -0.1935
    ],
        ...,
    [
        0.4559,
        -0.8351,
        0.1709,  ...,
        -0.0675,
        0.1635,
        -0.1935
    ],
    [
        0.4559,
        -0.8351,
        0.1709,  ...,
        -0.0675,
        0.1635,
        -0.1935
    ],
    [
        0.4559,
        -0.8351,
        0.1709,  ...,
        -0.0675,
        0.1635,
        -0.1935
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1494.2192,
    -1510.2885,
    -1506.8823,
    -1512.0421,
    -1511.8466,
    -1517.1093,
    -1497.9067,
    -1511.3656,
    -1523.2975,
    -1543.3281,
    -1511.4410,
    -1543.4786,
    -1530.1567,
    -1496.7756,
    -1521.0500,
    -1507.6420
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1494.2192,
    -1510.2885,
    -1506.8824,
    -1512.0422,
    -1511.8464,
    -1517.1094,
    -1497.9067,
    -1511.3656,
    -1523.2976,
    -1543.3280,
    -1511.4409,
    -1543.4785,
    -1530.1567,
    -1496.7755,
    -1521.0500,
    -1507.6420
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(12.3670, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -1.5654e-01,
        1.9351e-01,
        3.2494e-03,  ...,
        1.9804e-02,
        -1.4292e-01,
        2.8448e-01
    ],
    [
        -7.7777e-01,
        1.5400e+00,
        -1.7219e-01,  ...,
        6.2801e-01,
        -1.0651e+00,
        1.8318e+00
    ],
    [
        -1.5457e-01,
        1.9284e-01,
        1.7403e-03,  ...,
        2.1048e-02,
        -1.4034e-01,
        2.8577e-01
    ],
        ...,
    [
        -1.5914e-01,
        1.9295e-01,
        -4.8420e-04,  ...,
        2.4397e-02,
        -1.4263e-01,
        2.8558e-01
    ],
    [
        -1.5770e-01,
        1.9185e-01,
        6.9926e-04,  ...,
        2.1706e-02,
        -1.3993e-01,
        2.8447e-01
    ],
    [
        -1.5745e-01,
        1.9108e-01,
        -2.6809e-04,  ...,
        2.3551e-02,
        -1.4165e-01,
        2.8364e-01
    ]
], device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1591,
            0.1947,
            0.0066,  ...,
            0.0210,
            -0.1612,
            0.2953
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.7397,
            1.4636,
            -0.1709,  ...,
            0.5900,
            -1.0129,
            1.7387
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1592,
            0.1939,
            0.0059,  ...,
            0.0226,
            -0.1615,
            0.2961
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0686,
        0.1815,
        -0.2032
    ],
    [
        0.4585,
        -0.8363,
        0.1675,  ...,
        -0.0686,
        0.1815,
        -0.2032
    ],
    [
        0.4585,
        -0.8363,
        0.1675,  ...,
        -0.0686,
        0.1815,
        -0.2032
    ],
        ...,
    [
        0.4585,
        -0.8363,
        0.1675,  ...,
        -0.0686,
        0.1815,
        -0.2032
    ],
    [
        0.4585,
        -0.8363,
        0.1675,  ...,
        -0.0686,
        0.1815,
        -0.2032
    ],
    [
        0.4585,
        -0.8363,
        0.1675,  ...,
        -0.0686,
        0.1815,
        -0.2032
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1647.4702,
    -1651.8489,
    -1659.8386,
    -1653.7988,
    -1664.9312,
    -1659.5891,
    -1651.0784,
    -1664.3452,
    -1676.1298,
    -1689.1602,
    -1664.4491,
    -1689.5797,
    -1674.2263,
    -1649.9921,
    -1673.8075,
    -1660.6785
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1647.4701,
    -1651.8489,
    -1659.8385,
    -1653.7990,
    -1664.9313,
    -1659.5892,
    -1651.0785,
    -1664.3448,
    -1676.1298,
    -1689.1600,
    -1664.4491,
    -1689.5796,
    -1674.2264,
    -1649.9921,
    -1673.8076,
    -1660.6785
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(13.8639, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1655,
        0.2151,
        -0.0111,  ...,
        0.0386,
        -0.1419,
        0.2909
    ],
    [
        -0.8163,
        1.6170,
        -0.1732,  ...,
        0.6665,
        -1.1167,
        1.9248
    ],
    [
        -0.1633,
        0.2127,
        -0.0118,  ...,
        0.0380,
        -0.1414,
        0.2929
    ],
        ...,
    [
        -0.1662,
        0.2176,
        -0.0153,  ...,
        0.0414,
        -0.1444,
        0.2946
    ],
    [
        -0.1671,
        0.2144,
        -0.0141,  ...,
        0.0397,
        -0.1391,
        0.2947
    ],
    [
        -0.1662,
        0.2126,
        -0.0128,  ...,
        0.0397,
        -0.1420,
        0.2923
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -1.5654e-01,
            1.9351e-01,
            3.2494e-03,  ...,
            1.9804e-02,
            -1.4292e-01,
            2.8448e-01
        ],
        [
            -4.7451e-01,
            8.8687e-01,
            -2.6811e-01,  ...,
            1.5733e-01,
            -7.1828e-01,
            1.2624e+00
        ],
        [
            -5.3865e-01,
            1.0496e+00,
            -1.8880e-01,  ...,
            2.9296e-01,
            -7.8874e-01,
            1.5436e+00
        ],
         ...,
        [
            -3.7824e-01,
            4.2086e-01,
            -2.5842e-01,  ...,
            2.5678e-01,
            -4.0869e-01,
            7.0124e-01
        ],
        [
            -3.9628e-01,
            4.7817e-01,
            -1.7523e-01,  ...,
            2.6364e-01,
            -5.4027e-01,
            5.9821e-01
        ],
        [
            -2.2367e-01,
            3.4622e-01,
            -1.3283e-01,  ...,
            9.2174e-02,
            -3.2318e-01,
            4.8679e-01
        ]
    ],
    [
        [
            -6.1501e-01,
            1.0298e+00,
            -1.6428e-01,  ...,
            3.4761e-01,
            -7.7032e-01,
            1.4797e+00
        ],
        [
            -7.7777e-01,
            1.5400e+00,
            -1.7219e-01,  ...,
            6.2801e-01,
            -1.0651e+00,
            1.8318e+00
        ],
        [
            -5.3865e-01,
            1.0496e+00,
            -1.8880e-01,  ...,
            2.9296e-01,
            -7.8874e-01,
            1.5436e+00
        ],
         ...,
        [
            -3.7824e-01,
            4.2086e-01,
            -2.5842e-01,  ...,
            2.5678e-01,
            -4.0869e-01,
            7.0124e-01
        ],
        [
            -3.9628e-01,
            4.7817e-01,
            -1.7523e-01,  ...,
            2.6364e-01,
            -5.4027e-01,
            5.9821e-01
        ],
        [
            -2.2367e-01,
            3.4622e-01,
            -1.3283e-01,  ...,
            9.2174e-02,
            -3.2318e-01,
            4.8679e-01
        ]
    ],
    [
        [
            -6.1501e-01,
            1.0298e+00,
            -1.6428e-01,  ...,
            3.4761e-01,
            -7.7032e-01,
            1.4797e+00
        ],
        [
            -4.7451e-01,
            8.8687e-01,
            -2.6811e-01,  ...,
            1.5733e-01,
            -7.1828e-01,
            1.2624e+00
        ],
        [
            -1.5457e-01,
            1.9284e-01,
            1.7403e-03,  ...,
            2.1048e-02,
            -1.4034e-01,
            2.8577e-01
        ],
         ...,
        [
            -3.7824e-01,
            4.2086e-01,
            -2.5842e-01,  ...,
            2.5678e-01,
            -4.0869e-01,
            7.0124e-01
        ],
        [
            -3.9628e-01,
            4.7817e-01,
            -1.7523e-01,  ...,
            2.6364e-01,
            -5.4027e-01,
            5.9821e-01
        ],
        [
            -2.2367e-01,
            3.4622e-01,
            -1.3283e-01,  ...,
            9.2174e-02,
            -3.2318e-01,
            4.8679e-01
        ]
    ],

        ...,
    [
        [
            -6.1501e-01,
            1.0298e+00,
            -1.6428e-01,  ...,
            3.4761e-01,
            -7.7032e-01,
            1.4797e+00
        ],
        [
            -4.7451e-01,
            8.8687e-01,
            -2.6811e-01,  ...,
            1.5733e-01,
            -7.1828e-01,
            1.2624e+00
        ],
        [
            -5.3865e-01,
            1.0496e+00,
            -1.8880e-01,  ...,
            2.9296e-01,
            -7.8874e-01,
            1.5436e+00
        ],
         ...,
        [
            -3.7824e-01,
            4.2086e-01,
            -2.5842e-01,  ...,
            2.5678e-01,
            -4.0869e-01,
            7.0124e-01
        ],
        [
            -3.9628e-01,
            4.7817e-01,
            -1.7523e-01,  ...,
            2.6364e-01,
            -5.4027e-01,
            5.9821e-01
        ],
        [
            -2.2367e-01,
            3.4622e-01,
            -1.3283e-01,  ...,
            9.2174e-02,
            -3.2318e-01,
            4.8679e-01
        ]
    ],
    [
        [
            -6.1501e-01,
            1.0298e+00,
            -1.6428e-01,  ...,
            3.4761e-01,
            -7.7032e-01,
            1.4797e+00
        ],
        [
            -4.7451e-01,
            8.8687e-01,
            -2.6811e-01,  ...,
            1.5733e-01,
            -7.1828e-01,
            1.2624e+00
        ],
        [
            -5.3865e-01,
            1.0496e+00,
            -1.8880e-01,  ...,
            2.9296e-01,
            -7.8874e-01,
            1.5436e+00
        ],
         ...,
        [
            -3.7824e-01,
            4.2086e-01,
            -2.5842e-01,  ...,
            2.5678e-01,
            -4.0869e-01,
            7.0124e-01
        ],
        [
            -3.9628e-01,
            4.7817e-01,
            -1.7523e-01,  ...,
            2.6364e-01,
            -5.4027e-01,
            5.9821e-01
        ],
        [
            -2.2367e-01,
            3.4622e-01,
            -1.3283e-01,  ...,
            9.2174e-02,
            -3.2318e-01,
            4.8679e-01
        ]
    ],
    [
        [
            -6.1501e-01,
            1.0298e+00,
            -1.6428e-01,  ...,
            3.4761e-01,
            -7.7032e-01,
            1.4797e+00
        ],
        [
            -4.7451e-01,
            8.8687e-01,
            -2.6811e-01,  ...,
            1.5733e-01,
            -7.1828e-01,
            1.2624e+00
        ],
        [
            -5.3865e-01,
            1.0496e+00,
            -1.8880e-01,  ...,
            2.9296e-01,
            -7.8874e-01,
            1.5436e+00
        ],
         ...,
        [
            -3.7824e-01,
            4.2086e-01,
            -2.5842e-01,  ...,
            2.5678e-01,
            -4.0869e-01,
            7.0124e-01
        ],
        [
            -3.9628e-01,
            4.7817e-01,
            -1.7523e-01,  ...,
            2.6364e-01,
            -5.4027e-01,
            5.9821e-01
        ],
        [
            -2.2367e-01,
            3.4622e-01,
            -1.3283e-01,  ...,
            9.2174e-02,
            -3.2318e-01,
            4.8679e-01
        ]
    ]
], device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0525,
        0.1811,
        -0.1945
    ],
    [
        0.4495,
        -0.8147,
        0.1531,  ...,
        -0.0525,
        0.1811,
        -0.1945
    ],
    [
        0.4495,
        -0.8147,
        0.1531,  ...,
        -0.0525,
        0.1811,
        -0.1945
    ],
        ...,
    [
        0.4495,
        -0.8147,
        0.1531,  ...,
        -0.0525,
        0.1811,
        -0.1945
    ],
    [
        0.4495,
        -0.8147,
        0.1531,  ...,
        -0.0525,
        0.1811,
        -0.1945
    ],
    [
        0.4495,
        -0.8147,
        0.1531,  ...,
        -0.0525,
        0.1811,
        -0.1945
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1795.0135,
    -1784.4557,
    -1806.9150,
    -1786.5974,
    -1812.1361,
    -1793.1118,
    -1798.5603,
    -1811.4451,
    -1822.6877,
    -1826.0544,
    -1811.5662,
    -1826.7412,
    -1809.3634,
    -1797.5771,
    -1820.5094,
    -1807.8457
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1795.0134,
    -1784.4556,
    -1806.9150,
    -1786.5975,
    -1812.1360,
    -1793.1117,
    -1798.5602,
    -1811.4449,
    -1822.6877,
    -1826.0543,
    -1811.5660,
    -1826.7413,
    -1809.3635,
    -1797.5770,
    -1820.5096,
    -1807.8457
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(15.2881, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1766,
        0.2643,
        -0.0345,  ...,
        0.0547,
        -0.1616,
        0.3175
    ],
    [
        -0.8546,
        1.6943,
        -0.1740,  ...,
        0.7044,
        -1.1684,
        2.0187
    ],
    [
        -0.1745,
        0.2620,
        -0.0383,  ...,
        0.0540,
        -0.1609,
        0.3190
    ],
        ...,
    [
        -0.1764,
        0.2671,
        -0.0404,  ...,
        0.0565,
        -0.1654,
        0.3221
    ],
    [
        -0.1774,
        0.2637,
        -0.0399,  ...,
        0.0546,
        -0.1604,
        0.3209
    ],
    [
        -0.1767,
        0.2622,
        -0.0374,  ...,
        0.0552,
        -0.1624,
        0.3182
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1655,
            0.2151,
            -0.0111,  ...,
            0.0386,
            -0.1419,
            0.2909
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.8163,
            1.6170,
            -0.1732,  ...,
            0.6665,
            -1.1167,
            1.9248
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1633,
            0.2127,
            -0.0118,  ...,
            0.0380,
            -0.1414,
            0.2929
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0370,
        0.1608,
        -0.1686
    ],
    [
        0.4384,
        -0.7656,
        0.1297,  ...,
        -0.0370,
        0.1608,
        -0.1686
    ],
    [
        0.4384,
        -0.7656,
        0.1297,  ...,
        -0.0370,
        0.1608,
        -0.1686
    ],
        ...,
    [
        0.4384,
        -0.7656,
        0.1297,  ...,
        -0.0370,
        0.1608,
        -0.1686
    ],
    [
        0.4384,
        -0.7656,
        0.1297,  ...,
        -0.0370,
        0.1608,
        -0.1686
    ],
    [
        0.4384,
        -0.7656,
        0.1297,  ...,
        -0.0370,
        0.1608,
        -0.1686
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -1937.9160,
    -1909.0017,
    -1949.1361,
    -1911.3140,
    -1954.2587,
    -1918.5825,
    -1941.3333,
    -1953.5798,
    -1963.9856,
    -1954.8910,
    -1953.7527,
    -1955.8357,
    -1936.4337,
    -1940.3693,
    -1962.0040,
    -1950.0557
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -1937.9159,
    -1909.0017,
    -1949.1361,
    -1911.3141,
    -1954.2589,
    -1918.5826,
    -1941.3331,
    -1953.5797,
    -1963.9855,
    -1954.8910,
    -1953.7527,
    -1955.8357,
    -1936.4337,
    -1940.3691,
    -1962.0039,
    -1950.0557
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(16.6458, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.1934,
        0.3248,
        -0.0617,  ...,
        0.0747,
        -0.1997,
        0.3694
    ],
    [
        -0.8928,
        1.7711,
        -0.1750,  ...,
        0.7429,
        -1.2206,
        2.1123
    ],
    [
        -0.1914,
        0.3220,
        -0.0662,  ...,
        0.0735,
        -0.1995,
        0.3689
    ],
        ...,
    [
        -0.1939,
        0.3263,
        -0.0678,  ...,
        0.0755,
        -0.2042,
        0.3732
    ],
    [
        -0.1941,
        0.3238,
        -0.0672,  ...,
        0.0749,
        -0.1985,
        0.3700
    ],
    [
        -0.1936,
        0.3227,
        -0.0633,  ...,
        0.0738,
        -0.2004,
        0.3670
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1766,
            0.2643,
            -0.0345,  ...,
            0.0547,
            -0.1616,
            0.3175
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.8546,
            1.6943,
            -0.1740,  ...,
            0.7044,
            -1.1684,
            2.0187
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1745,
            0.2620,
            -0.0383,  ...,
            0.0540,
            -0.1609,
            0.3190
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0184,
        0.1228,
        -0.1197
    ],
    [
        0.4216,
        -0.7051,
        0.1025,  ...,
        -0.0184,
        0.1228,
        -0.1197
    ],
    [
        0.4216,
        -0.7051,
        0.1025,  ...,
        -0.0184,
        0.1228,
        -0.1197
    ],
        ...,
    [
        0.4216,
        -0.7051,
        0.1025,  ...,
        -0.0184,
        0.1228,
        -0.1197
    ],
    [
        0.4216,
        -0.7051,
        0.1025,  ...,
        -0.0184,
        0.1228,
        -0.1197
    ],
    [
        0.4216,
        -0.7051,
        0.1025,  ...,
        -0.0184,
        0.1228,
        -0.1197
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -2085.0928,
    -2035.0826,
    -2095.3967,
    -2037.5945,
    -2100.3235,
    -2045.5975,
    -2088.3350,
    -2099.6697,
    -2109.0623,
    -2085.2891,
    -2099.8684,
    -2086.4766,
    -2065.0662,
    -2087.3906,
    -2107.2732,
    -2096.3015
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -2085.0928,
    -2035.0825,
    -2095.3965,
    -2037.5944,
    -2100.3232,
    -2045.5975,
    -2088.3350,
    -2099.6694,
    -2109.0620,
    -2085.2891,
    -2099.8684,
    -2086.4766,
    -2065.0664,
    -2087.3906,
    -2107.2732,
    -2096.3015
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(18.0258, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.2186,
        0.3839,
        -0.0830,  ...,
        0.0924,
        -0.2432,
        0.4329
    ],
    [
        -0.9311,
        1.8480,
        -0.1763,  ...,
        0.7819,
        -1.2721,
        2.2060
    ],
    [
        -0.2170,
        0.3810,
        -0.0864,  ...,
        0.0909,
        -0.2421,
        0.4311
    ],
        ...,
    [
        -0.2196,
        0.3853,
        -0.0889,  ...,
        0.0924,
        -0.2475,
        0.4361
    ],
    [
        -0.2193,
        0.3823,
        -0.0881,  ...,
        0.0933,
        -0.2411,
        0.4319
    ],
    [
        -0.2187,
        0.3818,
        -0.0839,  ...,
        0.0909,
        -0.2452,
        0.4304
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.1934,
            0.3248,
            -0.0617,  ...,
            0.0747,
            -0.1997,
            0.3694
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.8928,
            1.7711,
            -0.1750,  ...,
            0.7429,
            -1.2206,
            2.1123
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.1914,
            0.3220,
            -0.0662,  ...,
            0.0735,
            -0.1995,
            0.3689
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0013,
        0.0780,
        -0.0564
    ],
    [
        0.3964,
        -0.6459,
        0.0813,  ...,
        -0.0013,
        0.0780,
        -0.0564
    ],
    [
        0.3964,
        -0.6459,
        0.0813,  ...,
        -0.0013,
        0.0780,
        -0.0564
    ],
        ...,
    [
        0.3964,
        -0.6459,
        0.0813,  ...,
        -0.0013,
        0.0780,
        -0.0564
    ],
    [
        0.3964,
        -0.6459,
        0.0813,  ...,
        -0.0013,
        0.0780,
        -0.0564
    ],
    [
        0.3964,
        -0.6459,
        0.0813,  ...,
        -0.0013,
        0.0780,
        -0.0564
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -2246.1792,
    -2173.2039,
    -2255.4194,
    -2175.9014,
    -2260.1379,
    -2184.6338,
    -2249.1899,
    -2259.4878,
    -2267.6948,
    -2227.7119,
    -2259.6592,
    -2229.1885,
    -2205.7212,
    -2248.2825,
    -2266.1245,
    -2256.3809
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -2246.1790,
    -2173.2041,
    -2255.4194,
    -2175.9014,
    -2260.1379,
    -2184.6338,
    -2249.1899,
    -2259.4878,
    -2267.6948,
    -2227.7119,
    -2259.6592,
    -2229.1885,
    -2205.7212,
    -2248.2825,
    -2266.1245,
    -2256.3809
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(19.5258, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.2472,
        0.4419,
        -0.1031,  ...,
        0.1127,
        -0.2886,
        0.4975
    ],
    [
        -0.9693,
        1.9252,
        -0.1774,  ...,
        0.8205,
        -1.3233,
        2.3005
    ],
    [
        -0.2462,
        0.4380,
        -0.1061,  ...,
        0.1115,
        -0.2879,
        0.4949
    ],
        ...,
    [
        -0.2479,
        0.4435,
        -0.1078,  ...,
        0.1134,
        -0.2927,
        0.5007
    ],
    [
        -0.2484,
        0.4412,
        -0.1068,  ...,
        0.1141,
        -0.2878,
        0.4966
    ],
    [
        -0.2472,
        0.4399,
        -0.1032,  ...,
        0.1121,
        -0.2915,
        0.4953
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.2186,
            0.3839,
            -0.0830,  ...,
            0.0924,
            -0.2432,
            0.4329
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.9311,
            1.8480,
            -0.1763,  ...,
            0.7819,
            -1.2721,
            2.2060
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.2170,
            0.3810,
            -0.0864,  ...,
            0.0909,
            -0.2421,
            0.4311
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.0199,
        0.0317,
        0.0085
    ],
    [
        0.3678,
        -0.5879,
        0.0611,  ...,
        0.0199,
        0.0317,
        0.0085
    ],
    [
        0.3678,
        -0.5879,
        0.0611,  ...,
        0.0199,
        0.0317,
        0.0085
    ],
        ...,
    [
        0.3678,
        -0.5879,
        0.0611,  ...,
        0.0199,
        0.0317,
        0.0085
    ],
    [
        0.3678,
        -0.5879,
        0.0611,  ...,
        0.0199,
        0.0317,
        0.0085
    ],
    [
        0.3678,
        -0.5879,
        0.0611,  ...,
        0.0199,
        0.0317,
        0.0085
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -2427.4912,
    -2330.1279,
    -2435.5874,
    -2332.9814,
    -2439.9954,
    -2342.4241,
    -2430.2524,
    -2439.3359,
    -2446.2559,
    -2388.9207,
    -2439.5107,
    -2390.6313,
    -2365.1670,
    -2429.3936,
    -2444.9688,
    -2436.5381
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -2427.4912,
    -2330.1282,
    -2435.5872,
    -2332.9812,
    -2439.9949,
    -2342.4238,
    -2430.2527,
    -2439.3359,
    -2446.2561,
    -2388.9207,
    -2439.5107,
    -2390.6311,
    -2365.1672,
    -2429.3936,
    -2444.9688,
    -2436.5381
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(21.2088, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.2747,
        0.5038,
        -0.1196,  ...,
        0.1368,
        -0.3385,
        0.5731
    ],
    [
        -1.0077,
        2.0016,
        -0.1785,  ...,
        0.8602,
        -1.3742,
        2.3958
    ],
    [
        -0.2743,
        0.5007,
        -0.1218,  ...,
        0.1351,
        -0.3382,
        0.5715
    ],
        ...,
    [
        -0.2768,
        0.5064,
        -0.1239,  ...,
        0.1373,
        -0.3424,
        0.5775
    ],
    [
        -0.2766,
        0.5028,
        -0.1231,  ...,
        0.1380,
        -0.3376,
        0.5734
    ],
    [
        -0.2757,
        0.5021,
        -0.1193,  ...,
        0.1356,
        -0.3418,
        0.5722
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.2472,
            0.4419,
            -0.1031,  ...,
            0.1127,
            -0.2886,
            0.4975
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.9693,
            1.9252,
            -0.1774,  ...,
            0.8205,
            -1.3233,
            2.3005
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.2462,
            0.4380,
            -0.1061,  ...,
            0.1115,
            -0.2879,
            0.4949
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.0434,
        -0.0186,
        0.0854
    ],
    [
        0.3403,
        -0.5260,
        0.0447,  ...,
        0.0434,
        -0.0186,
        0.0854
    ],
    [
        0.3403,
        -0.5260,
        0.0447,  ...,
        0.0434,
        -0.0186,
        0.0854
    ],
        ...,
    [
        0.3403,
        -0.5260,
        0.0447,  ...,
        0.0434,
        -0.0186,
        0.0854
    ],
    [
        0.3403,
        -0.5260,
        0.0447,  ...,
        0.0434,
        -0.0186,
        0.0854
    ],
    [
        0.3403,
        -0.5260,
        0.0447,  ...,
        0.0434,
        -0.0186,
        0.0854
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -2633.6357,
    -2510.7725,
    -2640.5645,
    -2513.8364,
    -2644.5688,
    -2524.0127,
    -2636.1233,
    -2643.8857,
    -2649.4463,
    -2573.8906,
    -2644.0684,
    -2575.8701,
    -2548.3579,
    -2635.3132,
    -2648.4316,
    -2641.4458
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -2633.6360,
    -2510.7720,
    -2640.5642,
    -2513.8364,
    -2644.5691,
    -2524.0125,
    -2636.1235,
    -2643.8855,
    -2649.4460,
    -2573.8909,
    -2644.0684,
    -2575.8699,
    -2548.3582,
    -2635.3130,
    -2648.4314,
    -2641.4458
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(23.1214, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.3015,
        0.5714,
        -0.1328,  ...,
        0.1658,
        -0.3904,
        0.6532
    ],
    [
        -1.0459,
        2.0786,
        -0.1793,  ...,
        0.8983,
        -1.4251,
        2.4900
    ],
    [
        -0.3010,
        0.5684,
        -0.1348,  ...,
        0.1639,
        -0.3908,
        0.6521
    ],
        ...,
    [
        -0.3048,
        0.5737,
        -0.1365,  ...,
        0.1661,
        -0.3940,
        0.6583
    ],
    [
        -0.3033,
        0.5704,
        -0.1353,  ...,
        0.1665,
        -0.3896,
        0.6544
    ],
    [
        -0.3031,
        0.5695,
        -0.1320,  ...,
        0.1647,
        -0.3933,
        0.6526
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.2747,
            0.5038,
            -0.1196,  ...,
            0.1368,
            -0.3385,
            0.5731
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -1.0077,
            2.0016,
            -0.1785,  ...,
            0.8602,
            -1.3742,
            2.3958
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.2743,
            0.5007,
            -0.1218,  ...,
            0.1351,
            -0.3382,
            0.5715
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.0726,
        -0.0701,
        0.1658
    ],
    [
        0.3135,
        -0.4585,
        0.0315,  ...,
        0.0726,
        -0.0701,
        0.1658
    ],
    [
        0.3135,
        -0.4585,
        0.0315,  ...,
        0.0726,
        -0.0701,
        0.1658
    ],
        ...,
    [
        0.3135,
        -0.4585,
        0.0315,  ...,
        0.0726,
        -0.0701,
        0.1658
    ],
    [
        0.3135,
        -0.4585,
        0.0315,  ...,
        0.0726,
        -0.0701,
        0.1658
    ],
    [
        0.3135,
        -0.4585,
        0.0315,  ...,
        0.0726,
        -0.0701,
        0.1658
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -2868.4819,
    -2719.3843,
    -2874.1748,
    -2722.5930,
    -2877.7864,
    -2733.5242,
    -2870.6929,
    -2877.0823,
    -2881.2505,
    -2786.7778,
    -2877.2688,
    -2789.0022,
    -2759.5020,
    -2869.9158,
    -2880.4854,
    -2875.0024
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -2868.4822,
    -2719.3843,
    -2874.1748,
    -2722.5933,
    -2877.7864,
    -2733.5237,
    -2870.6926,
    -2877.0823,
    -2881.2505,
    -2786.7778,
    -2877.2683,
    -2789.0022,
    -2759.5017,
    -2869.9158,
    -2880.4851,
    -2875.0024
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(25.3036, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [
        -0.3312,
        0.6390,
        -0.1415,  ...,
        0.1980,
        -0.4428,
        0.7370
    ],
    [
        -1.0841,
        2.1556,
        -0.1801,  ...,
        0.9379,
        -1.4763,
        2.5846
    ],
    [
        -0.3306,
        0.6363,
        -0.1433,  ...,
        0.1958,
        -0.4439,
        0.7354
    ],
        ...,
    [
        -0.3340,
        0.6419,
        -0.1450,  ...,
        0.1987,
        -0.4466,
        0.7425
    ],
    [
        -0.3322,
        0.6387,
        -0.1440,  ...,
        0.1978,
        -0.4430,
        0.7388
    ],
    [
        -0.3323,
        0.6376,
        -0.1407,  ...,
        0.1970,
        -0.4460,
        0.7371
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.3015,
            0.5714,
            -0.1328,  ...,
            0.1658,
            -0.3904,
            0.6532
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -1.0459,
            2.0786,
            -0.1793,  ...,
            0.8983,
            -1.4251,
            2.4900
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.3010,
            0.5684,
            -0.1348,  ...,
            0.1639,
            -0.3908,
            0.6521
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],

        ...,
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ],
    [
        [
            -0.6150,
            1.0298,
            -0.1643,  ...,
            0.3476,
            -0.7703,
            1.4797
        ],
        [
            -0.4745,
            0.8869,
            -0.2681,  ...,
            0.1573,
            -0.7183,
            1.2624
        ],
        [
            -0.5387,
            1.0496,
            -0.1888,  ...,
            0.2930,
            -0.7887,
            1.5436
        ],
         ...,
        [
            -0.3782,
            0.4209,
            -0.2584,  ...,
            0.2568,
            -0.4087,
            0.7012
        ],
        [
            -0.3963,
            0.4782,
            -0.1752,  ...,
            0.2636,
            -0.5403,
            0.5982
        ],
        [
            -0.2237,
            0.3462,
            -0.1328,  ...,
            0.0922,
            -0.3232,
            0.4868
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1048,
        -0.1229,
        0.2503
    ],
    [
        0.2839,
        -0.3908,
        0.0228,  ...,
        0.1048,
        -0.1229,
        0.2503
    ],
    [
        0.2839,
        -0.3908,
        0.0228,  ...,
        0.1048,
        -0.1229,
        0.2503
    ],
        ...,
    [
        0.2839,
        -0.3908,
        0.0228,  ...,
        0.1048,
        -0.1229,
        0.2503
    ],
    [
        0.2839,
        -0.3908,
        0.0228,  ...,
        0.1048,
        -0.1229,
        0.2503
    ],
    [
        0.2839,
        -0.3908,
        0.0228,  ...,
        0.1048,
        -0.1229,
        0.2503
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -3134.6365,
    -2958.7004,
    -3139.0449,
    -2962.1350,
    -3142.2490,
    -2973.8052,
    -3136.5579,
    -3141.5269,
    -3144.2632,
    -3030.4561,
    -3141.7053,
    -3032.9719,
    -3001.3989,
    -3135.7998,
    -3143.7388,
    -3139.8325
], device='cuda: 0',
       grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -3134.6365,
    -2958.7002,
    -3139.0449,
    -2962.1353,
    -3142.2490,
    -2973.8049,
    -3136.5581,
    -3141.5266,
    -3144.2632,
    -3030.4558,
    -3141.7056,
    -3032.9722,
    -3001.3992,
    -3135.7996,
    -3143.7388,
    -3139.8328
], device='cuda: 0',
       grad_fn=<NegBackward0>)
Energy tensor(27.7827, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [
                -20.4864,
                -19.9164,
                -19.7728,  ...,
                -20.1080,
                -19.8430,
                -19.6496
            ],
            [
                -20.5392,
                -20.6004,
                -20.0531,  ...,
                -19.7596,
                -19.3748,
                -20.0916
            ],
            [
                -20.8456,
                -19.9448,
                -19.5656,  ...,
                -20.7248,
                -20.1571,
                -19.8308
            ],
          ...,
            [
                -20.8094,
                -20.8512,
                -19.7087,  ...,
                -19.3790,
                -20.6142,
                -19.6551
            ],
            [
                -20.8231,
                -20.6509,
                -21.0132,  ...,
                -19.3187,
                -19.9359,
                -19.5951
            ],
            [
                -19.5416,
                -19.5563,
                -19.3248,  ...,
                -19.5737,
                -20.5227,
                -19.8703
            ]
        ],
        [
            [
                -19.9839,
                -19.2148,
                -20.5399,  ...,
                -19.4797,
                -19.9086,
                -20.7089
            ],
            [
                -19.8470,
                -20.5837,
                -19.6416,  ...,
                -19.2362,
                -19.5849,
                -20.5742
            ],
            [
                -20.5555,
                -19.7768,
                -19.2302,  ...,
                -20.5406,
                -19.9098,
                -20.8566
            ],
          ...,
            [
                -19.5744,
                -20.7592,
                -19.1528,  ...,
                -19.9868,
                -20.8851,
                -20.7815
            ],
            [
                -19.9765,
                -20.3491,
                -20.7796,  ...,
                -19.4653,
                -19.9347,
                -20.0123
            ],
            [
                -19.2565,
                -20.7516,
                -20.1306,  ...,
                -20.9859,
                -19.1480,
                -20.9249
            ]
        ],
        [
            [
                -19.9651,
                -21.0222,
                -19.1354,  ...,
                -19.4043,
                -19.3720,
                -20.6738
            ],
            [
                -20.1227,
                -19.7956,
                -20.4876,  ...,
                -20.6892,
                -19.9185,
                -19.2914
            ],
            [
                -19.7553,
                -20.8620,
                -19.2400,  ...,
                -19.5818,
                -20.7462,
                -19.3466
            ],
          ...,
            [
                -19.5374,
                -19.6501,
                -21.0120,  ...,
                -19.6904,
                -19.4878,
                -19.2775
            ],
            [
                -20.4165,
                -19.8637,
                -19.9607,  ...,
                -19.0829,
                -20.8118,
                -20.9407
            ],
            [
                -19.6912,
                -20.7118,
                -20.3889,  ...,
                -20.6334,
                -19.9437,
                -19.6990
            ]
        ]
    ],
    [
        [
            [
                -39.5556,
                -39.8823,
                -40.9095,  ...,
                -40.4831,
                -40.2291,
                -40.0757
            ],
            [
                -40.2866,
                -40.2789,
                -39.2454,  ...,
                -40.5635,
                -39.9770,
                -40.3439
            ],
            [
                -40.3705,
                -39.0229,
                -40.2769,  ...,
                -39.0371,
                -39.7401,
                -39.5523
            ],
          ...,
            [
                -39.1899,
                -39.9468,
                -40.6031,  ...,
                -39.6164,
                -40.9959,
                -40.3369
            ],
            [
                -39.1856,
                -40.1227,
                -39.8527,  ...,
                -40.5415,
                -40.3738,
                -40.7501
            ],
            [
                -39.3315,
                -39.2928,
                -39.6494,  ...,
                -39.2256,
                -39.0419,
                -39.3646
            ]
        ],
        [
            [
                -39.1218,
                -40.7824,
                -40.7800,  ...,
                -40.2750,
                -40.7782,
                -39.6459
            ],
            [
                -40.9827,
                -40.4024,
                -39.5710,  ...,
                -40.7958,
                -40.5405,
                -39.1174
            ],
            [
                -39.9808,
                -40.9110,
                -40.6558,  ...,
                -40.4931,
                -39.4725,
                -40.2773
            ],
          ...,
            [
                -39.3619,
                -40.1811,
                -39.9589,  ...,
                -39.6198,
                -39.2688,
                -39.9158
            ],
            [
                -40.5954,
                -40.8584,
                -40.9691,  ...,
                -39.8013,
                -40.8296,
                -39.1393
            ],
            [
                -39.1327,
                -40.2956,
                -40.7998,  ...,
                -39.7908,
                -39.6843,
                -40.6323
            ]
        ],
        [
            [
                -40.6354,
                -39.8576,
                -40.0635,  ...,
                -39.5783,
                -39.2399,
                -40.6566
            ],
            [
                -39.6740,
                -39.0115,
                -39.9034,  ...,
                -39.6458,
                -40.0545,
                -39.3990
            ],
            [
                -40.8028,
                -39.5660,
                -39.9013,  ...,
                -39.7753,
                -39.5693,
                -39.0674
            ],
          ...,
            [
                -41.0495,
                -38.9879,
                -40.9630,  ...,
                -39.5019,
                -40.0023,
                -39.8149
            ],
            [
                -40.3341,
                -40.5336,
                -39.3196,  ...,
                -40.4451,
                -39.1325,
                -40.6618
            ],
            [
                -39.1955,
                -39.0118,
                -40.1282,  ...,
                -39.6324,
                -39.9134,
                -39.6201
            ]
        ]
    ],
    [
        [
            [
                -19.5727,
                -21.0219,
                -20.5429,  ...,
                -20.7841,
                -20.5712,
                -19.8004
            ],
            [
                -19.3371,
                -19.4116,
                -19.5559,  ...,
                -19.7586,
                -19.1124,
                -19.1841
            ],
            [
                -19.4078,
                -19.2625,
                -19.9662,  ...,
                -19.1852,
                -19.3465,
                -20.8165
            ],
          ...,
            [
                -20.6081,
                -20.9363,
                -20.1121,  ...,
                -20.3801,
                -19.6485,
                -19.3469
            ],
            [
                -20.1373,
                -19.1767,
                -19.0018,  ...,
                -20.9882,
                -19.0042,
                -19.5392
            ],
            [
                -19.5927,
                -19.7039,
                -20.2391,  ...,
                -19.4993,
                -19.3194,
                -19.9919
            ]
        ],
        [
            [
                -20.8625,
                -19.2055,
                -20.7391,  ...,
                -19.0096,
                -20.5238,
                -20.8977
            ],
            [
                -19.2225,
                -19.7943,
                -20.0497,  ...,
                -20.7295,
                -19.9047,
                -20.0615
            ],
            [
                -19.9778,
                -19.1519,
                -19.8986,  ...,
                -19.9280,
                -19.0972,
                -20.6627
            ],
          ...,
            [
                -19.5505,
                -20.4502,
                -20.1608,  ...,
                -19.6123,
                -19.1911,
                -20.2487
            ],
            [
                -19.6859,
                -20.6192,
                -20.6604,  ...,
                -19.7638,
                -20.7298,
                -20.8567
            ],
            [
                -19.7837,
                -19.2596,
                -19.9385,  ...,
                -19.0728,
                -20.8623,
                -20.5287
            ]
        ],
        [
            [
                -19.0437,
                -20.8410,
                -19.0571,  ...,
                -19.5980,
                -19.2762,
                -19.0129
            ],
            [
                -19.8166,
                -20.2565,
                -19.2942,  ...,
                -20.1494,
                -19.0825,
                -19.6383
            ],
            [
                -19.8250,
                -20.5795,
                -20.2032,  ...,
                -19.7296,
                -19.4636,
                -20.9510
            ],
          ...,
            [
                -19.5223,
                -19.6156,
                -20.4006,  ...,
                -20.8626,
                -20.5870,
                -20.6677
            ],
            [
                -19.8620,
                -20.9993,
                -19.2675,  ...,
                -20.9988,
                -19.7349,
                -19.7572
            ],
            [
                -20.4741,
                -19.7660,
                -20.1107,  ...,
                -20.3890,
                -20.2881,
                -19.4349
            ]
        ]
    ],


        ...,
    [
        [
            [
                -19.2199,
                -19.8415,
                -20.2116,  ...,
                -20.9168,
                -19.1356,
                -20.8788
            ],
            [
                -20.5671,
                -19.9082,
                -20.7047,  ...,
                -20.3971,
                -19.9082,
                -19.2221
            ],
            [
                -19.2122,
                -19.0509,
                -20.8037,  ...,
                -20.1786,
                -19.4415,
                -20.5048
            ],
          ...,
            [
                -19.7762,
                -20.7110,
                -21.0019,  ...,
                -19.6831,
                -20.8573,
                -19.6573
            ],
            [
                -19.6693,
                -19.7825,
                -19.7374,  ...,
                -19.5499,
                -20.6268,
                -20.1596
            ],
            [
                -20.6443,
                -20.0274,
                -19.9723,  ...,
                -19.4377,
                -19.0614,
                -20.4681
            ]
        ],
        [
            [
                -20.9625,
                -20.0748,
                -20.2737,  ...,
                -20.8382,
                -19.1751,
                -19.5895
            ],
            [
                -19.5042,
                -19.5889,
                -19.1740,  ...,
                -19.9673,
                -19.5414,
                -20.1713
            ],
            [
                -19.4038,
                -20.6682,
                -19.7682,  ...,
                -20.5043,
                -20.1315,
                -20.9325
            ],
          ...,
            [
                -20.6774,
                -20.3847,
                -20.2425,  ...,
                -20.7000,
                -20.7911,
                -20.7182
            ],
            [
                -20.4943,
                -19.2593,
                -20.1063,  ...,
                -19.5293,
                -20.3777,
                -19.2363
            ],
            [
                -19.0377,
                -20.4614,
                -20.2872,  ...,
                -20.2353,
                -20.0957,
                -19.3229
            ]
        ],
        [
            [
                -19.8808,
                -19.5295,
                -20.7524,  ...,
                -19.5311,
                -20.5258,
                -20.5463
            ],
            [
                -19.3390,
                -20.5148,
                -20.1447,  ...,
                -19.7779,
                -19.3117,
                -20.1432
            ],
            [
                -20.7508,
                -20.4306,
                -20.7560,  ...,
                -19.1510,
                -18.9981,
                -20.7794
            ],
          ...,
            [
                -20.7258,
                -20.4137,
                -20.6061,  ...,
                -20.9331,
                -20.4555,
                -20.8554
            ],
            [
                -19.6807,
                -19.0626,
                -20.1690,  ...,
                -19.7076,
                -20.0812,
                -20.4099
            ],
            [
                -20.4470,
                -19.0389,
                -20.3053,  ...,
                -19.1366,
                -20.8773,
                -20.8412
            ]
        ]
    ],
    [
        [
            [
                -19.9552,
                -19.1387,
                -19.0711,  ...,
                -19.7041,
                -20.1840,
                -20.4195
            ],
            [
                -20.0116,
                -19.3794,
                -19.6978,  ...,
                -20.4463,
                -19.3634,
                -20.9157
            ],
            [
                -20.6645,
                -20.0927,
                -19.7732,  ...,
                -20.9491,
                -20.5414,
                -20.5884
            ],
          ...,
            [
                -20.9879,
                -20.7241,
                -20.0648,  ...,
                -19.4920,
                -21.0113,
                -19.2130
            ],
            [
                -20.8249,
                -19.0496,
                -20.5701,  ...,
                -20.5960,
                -19.7417,
                -19.9117
            ],
            [
                -19.5192,
                -20.4132,
                -20.8735,  ...,
                -19.4847,
                -19.7691,
                -19.7579
            ]
        ],
        [
            [
                -20.9029,
                -19.3071,
                -20.7281,  ...,
                -19.1424,
                -20.9096,
                -19.4824
            ],
            [
                -19.1375,
                -19.3217,
                -19.8311,  ...,
                -20.3609,
                -20.9558,
                -20.4915
            ],
            [
                -19.4500,
                -20.9424,
                -20.4466,  ...,
                -19.6058,
                -20.2973,
                -20.0138
            ],
          ...,
            [
                -19.6140,
                -20.0316,
                -19.4786,  ...,
                -18.9484,
                -20.4951,
                -19.9483
            ],
            [
                -20.0070,
                -20.4973,
                -20.2818,  ...,
                -20.0136,
                -19.2176,
                -20.9866
            ],
            [
                -19.4911,
                -20.5567,
                -20.4295,  ...,
                -19.7099,
                -20.5543,
                -19.1760
            ]
        ],
        [
            [
                -19.1136,
                -19.8877,
                -19.4749,  ...,
                -20.1682,
                -20.9674,
                -19.9921
            ],
            [
                -20.9960,
                -19.3117,
                -19.6868,  ...,
                -19.5203,
                -20.4934,
                -19.2112
            ],
            [
                -19.1956,
                -20.8795,
                -20.1261,  ...,
                -20.9667,
                -20.7352,
                -19.3727
            ],
          ...,
            [
                -20.2521,
                -20.1131,
                -19.0309,  ...,
                -19.2368,
                -20.1435,
                -19.0056
            ],
            [
                -20.5703,
                -20.4682,
                -19.4925,  ...,
                -19.3046,
                -19.1291,
                -19.2350
            ],
            [
                -20.6840,
                -19.4590,
                -20.2583,  ...,
                -19.1555,
                -20.4792,
                -20.6022
            ]
        ]
    ],
    [
        [
            [
                -19.7981,
                -20.2205,
                -19.7584,  ...,
                -19.8928,
                -20.3504,
                -20.2654
            ],
            [
                -19.1606,
                -19.3936,
                -20.4849,  ...,
                -20.7629,
                -20.7209,
                -19.0877
            ],
            [
                -19.6148,
                -20.0476,
                -19.4253,  ...,
                -19.4336,
                -20.9757,
                -19.6617
            ],
          ...,
            [
                -19.5309,
                -20.6079,
                -19.8729,  ...,
                -19.2705,
                -19.3580,
                -20.4653
            ],
            [
                -19.4480,
                -19.0184,
                -19.6219,  ...,
                -19.7169,
                -19.8289,
                -20.7495
            ],
            [
                -19.5604,
                -19.8936,
                -20.2797,  ...,
                -20.9123,
                -20.0626,
                -20.9234
            ]
        ],
        [
            [
                -19.2723,
                -18.9681,
                -19.6550,  ...,
                -19.1398,
                -20.8265,
                -19.6833
            ],
            [
                -19.2145,
                -20.6776,
                -19.1469,  ...,
                -20.6822,
                -21.0031,
                -19.1315
            ],
            [
                -19.3718,
                -20.8931,
                -19.9906,  ...,
                -19.3137,
                -19.2538,
                -21.0046
            ],
          ...,
            [
                -20.5642,
                -19.5130,
                -20.0860,  ...,
                -19.8380,
                -19.5830,
                -19.2136
            ],
            [
                -20.1727,
                -19.3895,
                -20.7294,  ...,
                -19.0240,
                -19.1943,
                -19.5153
            ],
            [
                -19.4204,
                -20.3940,
                -19.7973,  ...,
                -19.9114,
                -19.3263,
                -20.1098
            ]
        ],
        [
            [
                -19.3636,
                -19.9092,
                -19.2112,  ...,
                -20.0776,
                -20.5654,
                -19.5735
            ],
            [
                -20.0159,
                -21.0351,
                -20.7085,  ...,
                -19.8606,
                -19.8804,
                -20.6333
            ],
            [
                -20.5682,
                -19.1611,
                -20.4454,  ...,
                -20.8760,
                -20.3845,
                -19.8280
            ],
          ...,
            [
                -19.8321,
                -19.7329,
                -19.9931,  ...,
                -20.4167,
                -19.4031,
                -20.1033
            ],
            [
                -20.4808,
                -20.5045,
                -19.6768,  ...,
                -19.3062,
                -20.0187,
                -19.9593
            ],
            [
                -20.1948,
                -20.0357,
                -20.3871,  ...,
                -20.6035,
                -19.1341,
                -20.9826
            ]
        ]
    ]
],
       device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1715,
        -0.4800,
        1.0339
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1715,
        -0.4800,
        1.0339
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1715,
        -0.4800,
        1.0339
    ],
        ...,
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1715,
        -0.4800,
        1.0339
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1715,
        -0.4800,
        1.0339
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        0.1715,
        -0.4800,
        1.0339
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
tensor([
    [
        -0.5573,
        0.9242,
        -0.1644,  ...,
        0.2810,
        -0.8022,
        1.3913
    ],
    [
        -0.5016,
        0.8962,
        -0.1441,  ...,
        0.2720,
        -0.7667,
        1.3927
    ],
    [
        -0.5895,
        0.8876,
        -0.1689,  ...,
        0.2802,
        -0.8156,
        1.4602
    ],
        ...,
    [
        -0.5315,
        0.8845,
        -0.2477,  ...,
        0.2856,
        -0.6995,
        1.3750
    ],
    [
        -0.5872,
        0.8735,
        -0.2267,  ...,
        0.2385,
        -0.8051,
        1.3295
    ],
    [
        -0.6222,
        0.9173,
        -0.2553,  ...,
        0.2415,
        -0.8216,
        1.4545
    ]
],
       device='cuda: 0', grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [
        0.0000e+00,
        0.0000e+00,
        0.0000e+00,  ...,
        1.4934e-01,
        -4.9841e-01,
        9.6772e-01
    ],
    [
        5.7695e-02,
        -1.0566e-01,
        -1.6610e-04,  ...,
        1.4934e-01,
        -4.9841e-01,
        9.6772e-01
    ],
    [
        5.7695e-02,
        -1.0566e-01,
        -1.6610e-04,  ...,
        1.4934e-01,
        -4.9841e-01,
        9.6772e-01
    ],
        ...,
    [
        5.7695e-02,
        -1.0566e-01,
        -1.6610e-04,  ...,
        1.4934e-01,
        -4.9841e-01,
        9.6772e-01
    ],
    [
        5.7695e-02,
        -1.0566e-01,
        -1.6610e-04,  ...,
        1.4934e-01,
        -4.9841e-01,
        9.6772e-01
    ],
    [
        5.7695e-02,
        -1.0566e-01,
        -1.6610e-04,  ...,
        1.4934e-01,
        -4.9841e-01,
        9.6772e-01
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(3.4382, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(0.0711, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 5/3125 [
    00: 28<4: 56: 14,
    5.70s/it, loss=2.78, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [
        -1.0977,
        5.0218,
        0.1941,  ...,
        2.2272,
        -2.2568,
        6.8283
    ],
    [
        -0.0300,
        0.6270,
        -0.1827,  ...,
        0.2006,
        -0.2773,
        0.6661
    ],
    [
        -0.0325,
        0.6237,
        -0.1845,  ...,
        0.2026,
        -0.2772,
        0.6661
    ],
        ...,
    [
        -0.3376,
        1.4834,
        -0.0456,  ...,
        0.5611,
        -0.6801,
        1.9542
    ],
    [
        -0.3387,
        1.4837,
        -0.0451,  ...,
        0.5636,
        -0.6819,
        1.9581
    ],
    [
        -0.0313,
        0.6203,
        -0.1837,  ...,
        0.2003,
        -0.2762,
        0.6664
    ]
],
       device='cuda: 0', grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.0959,
        0.2864,
        -0.0166
    ],
    [
        -0.8288,
        3.8535,
        0.4319,  ...,
        -0.0959,
        0.2864,
        -0.0166
    ],
    [
        -0.8288,
        3.8535,
        0.4319,  ...,
        -0.0959,
        0.2864,
        -0.0166
    ],
        ...,
    [
        -0.8288,
        3.8535,
        0.4319,  ...,
        -0.0959,
        0.2864,
        -0.0166
    ],
    [
        -0.8288,
        3.8535,
        0.4319,  ...,
        -0.0959,
        0.2864,
        -0.0166
    ],
    [
        -0.8288,
        3.8535,
        0.4319,  ...,
        -0.0959,
        0.2864,
        -0.0166
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([
    -12535.5156,
    -14307.2852,
    -14317.6455,
    -14318.2881,
    -12543.5400,
    -14301.8066,
    -14366.6270,
    -14372.1035,
    -14311.5938,
    -14348.7637,
    -12537.5596,
    -14335.2168,
    -14317.1768,
    -14344.9531,
    -14359.0898,
    -14340.3145
], device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([
    -12535.5166,
    -14307.2861,
    -14317.6436,
    -14318.2861,
    -12543.5400,
    -14301.8076,
    -14366.6260,
    -14372.1025,
    -14311.5938,
    -14348.7637,
    -12537.5596,
    -14335.2168,
    -14317.1768,
    -14344.9521,
    -14359.0908,
    -14340.3145
], device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(inf, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [
            -1.0977,
            5.0218,
            0.1941,  ...,
            2.2272,
            -2.2568,
            6.8283
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.0300,
            0.6270,
            -0.1827,  ...,
            0.2006,
            -0.2773,
            0.6661
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.0325,
            0.6237,
            -0.1845,  ...,
            0.2026,
            -0.2772,
            0.6661
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [    nan,     nan,     nan,  ...,     nan,     nan,     nan
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],

        ...,
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ],
    [
        [
            -0.2689,
            1.1683,
            -0.2378,  ...,
            0.1063,
            -0.8310,
            1.6496
        ],
        [
            -0.3744,
            1.4566,
            -0.1499,  ...,
            0.2708,
            -0.7947,
            2.1000
        ],
        [
            -0.3283,
            1.3799,
            -0.2094,  ...,
            0.2603,
            -0.7975,
            1.9808
        ],
         ...,
        [
            -0.3225,
            0.4642,
            -0.1732,  ...,
            0.1550,
            -0.4124,
            0.7121
        ],
        [
            -0.3922,
            0.3950,
            -0.2047,  ...,
            0.2072,
            -0.5101,
            0.7138
        ],
        [
            -0.4704,
            0.4520,
            -0.1620,  ...,
            0.2962,
            -0.5626,
            0.6829
        ]
    ]
],
       device='cuda: 0', grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],


        ...,
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ]
], device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2185,
        -0.3264,
        1.0751
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2185,
        -0.3264,
        1.0751
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2185,
        -0.3264,
        1.0751
    ],
        ...,
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2185,
        -0.3264,
        1.0751
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2185,
        -0.3264,
        1.0751
    ],
    [
        0.0000,
        0.0000,
        0.0000,  ...,
        -0.2185,
        -0.3264,
        1.0751
    ]
],
       device='cuda: 0', grad_fn=<ReshapeAliasBackward0>)
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(3.0818, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(nan, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 6/3125 [
    00: 30<4: 24: 42,
    5.09s/it, loss=nan, v_num=0
] ----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],


        ...,
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ]
], device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(nan, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(nan, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 7/3125 [
    00: 32<4: 01: 02,
    4.64s/it, loss=nan, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],


        ...,
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ]
], device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(nan, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(nan, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 8/3125 [
    00: 34<3: 43: 25,
    4.30s/it, loss=nan, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
tensor([
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],


        ...,
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ],
    [
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ],
        [
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
          ...,
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ],
            [nan, nan, nan,  ..., nan, nan, nan
            ]
        ]
    ]
], device='cuda: 0')
torch.Size([
    32,
    128
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<CatBackward0>)
---------------Fake----------------------
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
Contrastive tensor(nan, device='cuda: 0', grad_fn=<NllLossBackward0>)
Energy Loss tensor(nan, device='cuda: 0', grad_fn=<MeanBackward0>)
Epoch 0: 0%|          | 9/3125 [
    00: 36<3: 29: 59,
    4.04s/it, loss=nan, v_num=0
]----------------------------
torch.Size([
    16,
    32,
    128
])
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CloneBackward0>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
===========V=============
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<AddmmBackward0>)
===========Y=============
tensor([
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],

        ...,
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ],
    [
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
         ...,
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ],
        [nan, nan, nan,  ..., nan, nan, nan
        ]
    ]
], device='cuda: 0',
       grad_fn=<CopySlices>)
===========Fake Logits=============
torch.Size([
    16,
    4096
])
tensor([
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
        ...,
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ],
    [nan, nan, nan,  ..., nan, nan, nan
    ]
], device='cuda: 0',
       grad_fn=<ReshapeAliasBackward0>)
==============SQRT================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
==============NORM================
tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan
],
       device='cuda: 0', grad_fn=<NegBackward0>)
Energy tensor(nan, device='cuda: 0', grad_fn=<NegBackward0>)
